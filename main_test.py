# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content including 
#         documents, uploaded signals, and interview data to identify:
        
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         Pay special attention to interview insights which may reveal stakeholder perspectives, 
#         challenges, opportunities, and future visions not captured in documents.

#         COMPREHENSIVE CONTENT (Documents + Signals + Interview Data):
#         {document_text[:10000]}

#         Please provide 4-6 strong signals and 4-6 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description of the signal, include source context (document/interview)",
#                     "source": "Where this signal can be observed (specify if from interview insights)",
#                     "impact": "Potential impact description"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description of the signal, include source context (document/interview)",
#                     "source": "Source or context (specify if from interview insights)",
#                     "potential": "Future potential or implications"
#                 }}
#             ]
#         }}

#         IMPORTANT: 
#         - Include signals derived from interview insights where stakeholders mentioned challenges, opportunities, or visions
#         - Focus on signals that are relevant to the domain and could impact future scenarios
#         - Clearly indicate when signals come from interview data vs documents
#         - Synthesize multiple sources where patterns emerge across documents and interviews
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in signal detection and trend analysis for foresight studies. 
#                         You excel at synthesizing insights from multiple sources including stakeholder interviews, 
#                         documents, and trend data. Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,  # Increased for interview data
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context including interviews."""
        
#         # Extract and format signals better
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Handle different signal formats
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc}")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc}")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # Enhanced prompt with specific instructions including interview data
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         CONTEXT:
#         - Domain: {domain}
#         - Available Signals: {len(signal_descriptions)} signals identified
#         - Full Context Available: {'Yes' if document_text else 'No'}

#         SIGNALS TO ANALYZE:
#         {chr(10).join(signal_descriptions[:15])}

#         FULL CONTEXT (including documents, uploaded signals, and interview data):
#         {document_text[:10000] if document_text else "No context provided"}

#         TASK: Analyze ALL available information including interview insights and provide 3-5 relevant factors for EACH STEEPV category. 
#         Pay special attention to interview data which may contain stakeholder perspectives, challenges, and future visions.

#         STEEPV FRAMEWORK DEFINITIONS:
#         - Social: Cultural trends, social movements, lifestyle changes, community behaviors, stakeholder perspectives from interviews
#         - Technological: Digital innovations, emerging tech, automation, AI, tech challenges mentioned in interviews
#         - Economic: Economic conditions, funding, costs, financial challenges and opportunities from interviews
#         - Environmental: Climate factors, sustainability, environmental concerns from stakeholder interviews
#         - Political: Government policies, political factors, governance challenges mentioned in interviews
#         - Values: Ethical considerations, cultural values, stakeholder values and beliefs from interviews

#         INSTRUCTIONS:
#         1. For each category, provide 3-5 specific, actionable factors
#         2. Base factors on signals, document content, interview insights, and logical domain analysis
#         3. Give priority to insights from interview data where available
#         4. Make factors specific to the "{domain}" domain
#         5. Ensure NO category is left empty
#         6. Focus on factors that could impact future development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1", "factor2", "factor3", "factor4"],
#             "Technological": ["factor1", "factor2", "factor3", "factor4"],
#             "Economic": ["factor1", "factor2", "factor3", "factor4"],
#             "Environmental": ["factor1", "factor2", "factor3", "factor4"],
#             "Political": ["factor1", "factor2", "factor3", "factor4"],
#             "Values": ["factor1", "factor2", "factor3", "factor4"]
#         }}

#         CRITICAL: Every category must contain at least 3 factors. Include interview insights where relevant.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in STEEPV methodology. 
#                         Your role is to provide comprehensive analysis across all dimensions, ensuring no category is left empty. 
#                         You excel at synthesizing multiple data sources including stakeholder interviews, documents, and signals.
#                         Always respond with valid, complete JSON containing factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased token limit for interview data
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Enhanced JSON parsing
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate and ensure all categories have content
#             steepv_categories = [
#                 "Social", "Technological", "Economic", "Environmental", "Political", "Values"
#             ]
            
#             # Fill empty categories with generic factors if needed
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     parsed_result[category] = [
#                         f"General {category.lower()} considerations for {domain}",
#                         f"Potential {category.lower()} impacts on sector development", 
#                         f"Future {category.lower()} trends affecting {domain}"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Return template with placeholder content instead of error
#             return {
#                 "Social": [f"Social factors affecting {domain}", "Community engagement patterns", "Cultural adoption trends"],
#                 "Technological": [f"Technology trends in {domain}", "Digital transformation impacts", "Innovation opportunities"],
#                 "Economic": [f"Economic factors in {domain}", "Funding availability", "Cost considerations"],
#                 "Environmental": [f"Environmental impact of {domain}", "Sustainability requirements", "Climate considerations"],
#                 "Political": [f"Political factors affecting {domain}", "Government support", "Policy implications"],
#                 "Values": [f"Value considerations in {domain}", "Ethical frameworks", "Cultural alignment factors"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate Futures Triangle analysis based on signals, STEEPV data, and interview context."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Format signals for prompt
#         strong_signals_text = "\n".join([f"- {signal.get('title', '')}: {signal.get('description', '')}" for signal in strong_signals])
#         weak_signals_text = "\n".join([f"- {signal.get('title', '')}: {signal.get('description', '')}" for signal in weak_signals])
        
#         # Format STEEPV for context
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:3])}"
        
#         # Add interview context to the prompt
#         interview_section = ""
#         if interview_context:
#             interview_section = f"""
            
#             INTERVIEW INSIGHTS:
#             {interview_context[:2000]}  # Limit to avoid token limits
#             """
        
#         prompt = f"""
#         As a strategic foresight analyst, create a Futures Triangle analysis for the domain "{domain}".

#         Based on the following analysis:

#         STRONG SIGNALS:
#         {strong_signals_text}

#         WEAK SIGNALS:
#         {weak_signals_text}

#         STEEPV ANALYSIS:
#         {steepv_text}
#         {interview_section}

#         Generate a Futures Triangle with three forces, each with subcategories:

#         1. WEIGHT OF THE PAST:
#         - Obstacles & Challenges: Historical constraints, legacy systems, resistance factors
#         - Values to Preserve: Valuable traditions, cultural practices, established successes

#         2. PUSH OF THE PRESENT:
#         - Current Trends: Ongoing developments and momentum
#         - Strong Drivers: Key forces propelling change forward

#         3. PULL OF THE FUTURE:
#         - Future Visions: Aspirational goals and desired outcomes
#         - Emerging Possibilities: New opportunities and innovations

#         Format your response as JSON:
#         {{
#             "weight_of_past": {{
#                 "obstacles_challenges": [
#                     "obstacle or challenge 1",
#                     "obstacle or challenge 2",
#                     "obstacle or challenge 3"
#                 ],
#                 "values_to_preserve": [
#                     "valuable tradition 1",
#                     "valuable tradition 2", 
#                     "valuable tradition 3"
#                 ]
#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1",
#                     "current trend 2",
#                     "current trend 3"
#                 ],
#                 "strong_drivers": [
#                     "driving force 1",
#                     "driving force 2",
#                     "driving force 3"
#                 ]
#             }},
#             "pull_of_future": {{
#                 "future_visions": [
#                     "future vision 1",
#                     "future vision 2",
#                     "future vision 3"
#                 ],
#                 "emerging_possibilities": [
#                     "emerging possibility 1",
#                     "emerging possibility 2",
#                     "emerging possibility 3"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors relevant to {domain}.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in futures studies and the Futures Triangle methodology. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate futures triangle: {str(e)}"}
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}
        
        


# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)








#21-08-2025
#updated the strong ,week signal , steepv analysis, future triangle functions 
#added new function extract_comprehensive_text function for storing all the extracted text.

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. WEIGHT OF THE PAST (Historical Constraints & Assets):
#         - Obstacles & Challenges: Legacy constraints, historical barriers, resistance factors from all sources
#         - Values to Preserve: Cultural assets, successful traditions, institutional strengths from comprehensive analysis

#         2. PUSH OF THE PRESENT (Current Momentum):
#         - Current Trends: Ongoing developments from documents and interviews
#         - Strong Drivers: Key forces propelling change from integrated analysis

#         3. PULL OF THE FUTURE (Future Aspirations):
#         - Future Visions: Stakeholder aspirations and strategic goals from interviews and documents
#         - Emerging Possibilities: New opportunities and innovations from comprehensive review

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "weight_of_past": {{
#                 "obstacles_challenges": [
#                     "historical constraint 1 (source context)",
#                     "legacy barrier 2 (source context)",
#                     "resistance factor 3 (source context)",
#                     "institutional constraint 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "cultural asset 1 (source context)",
#                     "successful tradition 2 (source context)", 
#                     "institutional strength 3 (source context)",
#                     "valuable practice 4 (source context)"
#                 ]
#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "ongoing development 1 (source context)",
#                     "current momentum 2 (source context)",
#                     "active trend 3 (source context)",
#                     "present force 4 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "key driving force 1 (source context)",
#                     "change catalyst 2 (source context)",
#                     "momentum driver 3 (source context)",
#                     "propelling factor 4 (source context)"
#                 ]
#             }},
#             "pull_of_future": {{
#                 "future_visions": [
#                     "stakeholder aspiration 1 (source context)",
#                     "strategic goal 2 (source context)",
#                     "desired outcome 3 (source context)",
#                     "future vision 4 (source context)"
#                 ],
#                 "emerging_possibilities": [
#                     "new opportunity 1 (source context)",
#                     "innovation potential 2 (source context)",
#                     "emerging possibility 3 (source context)",
#                     "future capability 4 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 4-5 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive output
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}
        
        


# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)











#21-08-2025
#updated the generate_futures_triangle function for newly added Key Dynamics & Strategic Insights 
#also updated the  Pull of the Future, Push of the Present, Weight of History based on the prompt client was given .

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     # def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#     #     """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#     #     # Extract signals for context
#     #     strong_signals = signals_data.get('strong_signals', [])
#     #     weak_signals = signals_data.get('weak_signals', [])
        
#     #     # Enhanced signal formatting with source context
#     #     strong_signals_text = "\n".join([
#     #         f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#     #         for signal in strong_signals
#     #     ])
#     #     weak_signals_text = "\n".join([
#     #         f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#     #         for signal in weak_signals
#     #     ])
        
#     #     # Enhanced STEEPV formatting
#     #     steepv_text = ""
#     #     for category, factors in steepv_data.items():
#     #         if factors:
#     #             steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#     #     # UPDATED: Comprehensive interview and document integration
#     #     comprehensive_context = ""
#     #     if interview_context:
#     #         comprehensive_context = f"""
            
#     #         COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#     #         {interview_context[:8000]}  # Increased limit for full context
#     #         """
        
#     #     # UPDATED: Enhanced prompt for comprehensive analysis
#     #     prompt = f"""
#     #     As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#     #     INTEGRATED ANALYSIS BASE:

#     #     STRONG SIGNALS (from comprehensive analysis):
#     #     {strong_signals_text}

#     #     WEAK SIGNALS (from comprehensive analysis):
#     #     {weak_signals_text}

#     #     STEEPV ANALYSIS SUMMARY:
#     #     {steepv_text}
#     #     {comprehensive_context}

#     #     FUTURES TRIANGLE METHODOLOGY:
#     #     Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#     #     1. WEIGHT OF THE PAST (Historical Constraints & Assets):
#     #     - Obstacles & Challenges: Legacy constraints, historical barriers, resistance factors from all sources
#     #     - Values to Preserve: Cultural assets, successful traditions, institutional strengths from comprehensive analysis

#     #     2. PUSH OF THE PRESENT (Current Momentum):
#     #     - Current Trends: Ongoing developments from documents and interviews
#     #     - Strong Drivers: Key forces propelling change from integrated analysis

#     #     3. PULL OF THE FUTURE (Future Aspirations):
#     #     - Future Visions: Stakeholder aspirations and strategic goals from interviews and documents
#     #     - Emerging Possibilities: New opportunities and innovations from comprehensive review

#     #     COMPREHENSIVE INTEGRATION REQUIREMENTS:
#     #     - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#     #     - Ensure each force reflects evidence from multiple source types
#     #     - Include stakeholder perspectives prominently in future visions
#     #     - Ground all factors in the comprehensive materials provided
#     #     - Focus on domain-specific temporal dynamics

#     #     FORMAT YOUR RESPONSE AS JSON:
#     #     {{
#     #         "weight_of_past": {{
#     #             "obstacles_challenges": [
#     #                 "historical constraint 1 (source context)",
#     #                 "legacy barrier 2 (source context)",
#     #                 "resistance factor 3 (source context)",
#     #                 "institutional constraint 4 (source context)"
#     #             ],
#     #             "values_to_preserve": [
#     #                 "cultural asset 1 (source context)",
#     #                 "successful tradition 2 (source context)", 
#     #                 "institutional strength 3 (source context)",
#     #                 "valuable practice 4 (source context)"
#     #             ]
#     #         }},
#     #         "push_of_present": {{
#     #             "current_trends": [
#     #                 "ongoing development 1 (source context)",
#     #                 "current momentum 2 (source context)",
#     #                 "active trend 3 (source context)",
#     #                 "present force 4 (source context)"
#     #             ],
#     #             "strong_drivers": [
#     #                 "key driving force 1 (source context)",
#     #                 "change catalyst 2 (source context)",
#     #                 "momentum driver 3 (source context)",
#     #                 "propelling factor 4 (source context)"
#     #             ]
#     #         }},
#     #         "pull_of_future": {{
#     #             "future_visions": [
#     #                 "stakeholder aspiration 1 (source context)",
#     #                 "strategic goal 2 (source context)",
#     #                 "desired outcome 3 (source context)",
#     #                 "future vision 4 (source context)"
#     #             ],
#     #             "emerging_possibilities": [
#     #                 "new opportunity 1 (source context)",
#     #                 "innovation potential 2 (source context)",
#     #                 "emerging possibility 3 (source context)",
#     #                 "future capability 4 (source context)"
#     #             ]
#     #         }}
#     #     }}

#     #     Ensure each subcategory has 4-5 specific factors grounded in the comprehensive {domain} analysis.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system",
#     #                     "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#     #                     You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#     #                     Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics.
#     #                     Always respond with valid JSON format grounded in provided evidence."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2500,  # Increased for comprehensive output
#     #             temperature=0.7
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         return self._parse_json_response(response_text)
                
#     #     except Exception as e:
#     #         return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions: Images of preferred futures being articulated (concrete future scenarios)
#         - Aspirations: Goals and desires pulling society forward (abstract desires/objectives)

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers: Structures and systems resisting change (e.g., laws, infrastructure gaps, financial limits)
#         - Inertia: Tendency to continue current patterns or habits (e.g., institutional routines, cultural momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions": [
#                     "vision 1 (source context)",
#                     "vision 2 (source context)",
#                     "vision 3 (source context)"
#                 ],
#                 "aspirations": [
#                     "aspiration 1 (source context)",
#                     "aspiration 2 (source context)",
#                     "aspiration 3 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers": [
#                     "barrier 1 (source context)",
#                     "barrier 2 (source context)",
#                     "barrier 3 (source context)"
#                 ],
#                 "inertia": [
#                     "inertia 1 (source context)",
#                     "inertia 2 (source context)",
#                     "inertia 3 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}
        
        


# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)









#22-08-2025
#updated the future triangle prompt in phase 2 for barriers_and_inertia and visions_and_aspirations remaing same only.

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}
        
        


# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)








#25-08-2025
#added generate_futures_triangle_2_0 for phase 3

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)
                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}
    

# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)







#25-06-2025
#added generate_baseline_scenario function for phase 3

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)
                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}
    
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#             """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
            
#             # Extract key elements from Futures Triangle 2.0
#             drivers = triangle_2_0_data.get('drivers', [])
#             enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#             push_of_present = enhanced_triangle.get('push_of_present', {})
            
#             # Format drivers context - focus on high certainty/high impact
#             high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#             drivers_context = ""
#             for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#                 drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
            
#             # Format Push of Present context
#             trends = push_of_present.get('trends', [])
#             existing_drivers = push_of_present.get('drivers', [])
#             push_context = ""
#             if trends:
#                 push_context += "Current Trends: " + ", ".join(trends[:4])
#             if existing_drivers:
#                 push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
            
#             # Project context
#             project_name = phase1_data.get('project_name', domain) if phase1_data else domain
            
#             prompt = f"""
#             You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#             PROJECT CONTEXT:
#             Project: {project_name}
#             Domain: {domain}
            
#             BASELINE SCENARIO DEFINITION:
#             The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#             1. **Push of the Present**: Current trends and momentum
#             2. **Key Drivers**: High-certainty forces shaping the future
            
#             PUSH OF THE PRESENT (Current Momentum):
#             {push_context}
            
#             KEY DRIVERS (High Certainty Forces):
#             {drivers_context}
            
#             BASELINE SCENARIO REQUIREMENTS:
            
#             **Structure (3-4 paragraphs, 250-350 words total):**
            
#             **Paragraph 1 - Present Momentum (70-90 words):**
#             - Describe the current state and ongoing trends
#             - Establish the "Push of the Present" foundation
#             - Set the context for continuation rather than transformation
            
#             **Paragraph 2 - Primary Drivers (80-100 words):**
#             - Focus on the highest certainty, highest impact drivers
#             - Explain how these forces reinforce current trajectories
#             - Show momentum building from existing patterns
            
#             **Paragraph 3 - Secondary Drivers & Evolution (80-100 words):**
#             - Include additional drivers that support the baseline path
#             - Show how the domain evolves within existing frameworks
#             - Demonstrate gradual rather than revolutionary change
            
#             **Paragraph 4 - Baseline Future State (60-80 words):**
#             - Synthesize into a coherent "most likely" future
#             - Emphasize continuation and extension of current trends
#             - Position as the foundation before exploring alternatives
            
#             **Writing Style:**
#             - Narrative and story-like, but grounded in evidence
#             - Confident but not overly optimistic
#             - Focus on "what's most likely" rather than "what's possible"
#             - Use concrete details from the domain context
            
#             **Critical Focus:**
#             - This is NOT about transformation or disruption
#             - This IS about logical extension of current momentum
#             - Emphasize high-certainty, predictable developments
#             - Set up the contrast for later alternative scenarios
            
#             Format your response as JSON:
#             {{
#                 "scenario_title": "Descriptive title for the baseline scenario",
#                 "timeframe": "2025-2030" or appropriate timeframe,
#                 "scenario_text": "The complete 3-4 paragraph narrative text",
#                 "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#                 "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#                 "scenario_type": "Baseline/Continuation"
#             }}
            
#             Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                             You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                             high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                             and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=1500,
#                     temperature=0.6  # Lower temperature for more consistent baseline scenarios
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)
                
#                 # Validate required fields
#                 required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#                 for field in required_fields:
#                     if field not in parsed_result:
#                         parsed_result[field] = f"Generated {field} for {domain}"
                                
#                 # Ensure scenario_text exists and is reasonable length
#                 if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                     parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
        


# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)












#25-08-2025
#added  def generate_driver_outcomes for the phase 3


# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)
                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}
    
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#             """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
            
#             # Extract key elements from Futures Triangle 2.0
#             drivers = triangle_2_0_data.get('drivers', [])
#             enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#             push_of_present = enhanced_triangle.get('push_of_present', {})
            
#             # Format drivers context - focus on high certainty/high impact
#             high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#             drivers_context = ""
#             for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#                 drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
            
#             # Format Push of Present context
#             trends = push_of_present.get('trends', [])
#             existing_drivers = push_of_present.get('drivers', [])
#             push_context = ""
#             if trends:
#                 push_context += "Current Trends: " + ", ".join(trends[:4])
#             if existing_drivers:
#                 push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
            
#             # Project context
#             project_name = phase1_data.get('project_name', domain) if phase1_data else domain
            
#             prompt = f"""
#             You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#             PROJECT CONTEXT:
#             Project: {project_name}
#             Domain: {domain}
            
#             BASELINE SCENARIO DEFINITION:
#             The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#             1. **Push of the Present**: Current trends and momentum
#             2. **Key Drivers**: High-certainty forces shaping the future
            
#             PUSH OF THE PRESENT (Current Momentum):
#             {push_context}
            
#             KEY DRIVERS (High Certainty Forces):
#             {drivers_context}
            
#             BASELINE SCENARIO REQUIREMENTS:
            
#             **Structure (3-4 paragraphs, 250-350 words total):**
            
#             **Paragraph 1 - Present Momentum (70-90 words):**
#             - Describe the current state and ongoing trends
#             - Establish the "Push of the Present" foundation
#             - Set the context for continuation rather than transformation
            
#             **Paragraph 2 - Primary Drivers (80-100 words):**
#             - Focus on the highest certainty, highest impact drivers
#             - Explain how these forces reinforce current trajectories
#             - Show momentum building from existing patterns
            
#             **Paragraph 3 - Secondary Drivers & Evolution (80-100 words):**
#             - Include additional drivers that support the baseline path
#             - Show how the domain evolves within existing frameworks
#             - Demonstrate gradual rather than revolutionary change
            
#             **Paragraph 4 - Baseline Future State (60-80 words):**
#             - Synthesize into a coherent "most likely" future
#             - Emphasize continuation and extension of current trends
#             - Position as the foundation before exploring alternatives
            
#             **Writing Style:**
#             - Narrative and story-like, but grounded in evidence
#             - Confident but not overly optimistic
#             - Focus on "what's most likely" rather than "what's possible"
#             - Use concrete details from the domain context
            
#             **Critical Focus:**
#             - This is NOT about transformation or disruption
#             - This IS about logical extension of current momentum
#             - Emphasize high-certainty, predictable developments
#             - Set up the contrast for later alternative scenarios
            
#             Format your response as JSON:
#             {{
#                 "scenario_title": "Descriptive title for the baseline scenario",
#                 "timeframe": "2025-2030" or appropriate timeframe,
#                 "scenario_text": "The complete 3-4 paragraph narrative text",
#                 "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#                 "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#                 "scenario_type": "Baseline/Continuation"
#             }}
            
#             Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                             You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                             high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                             and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=1500,
#                     temperature=0.6  # Lower temperature for more consistent baseline scenarios
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)
                
#                 # Validate required fields
#                 required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#                 for field in required_fields:
#                     if field not in parsed_result:
#                         parsed_result[field] = f"Generated {field} for {domain}"
                                
#                 # Ensure scenario_text exists and is reasonable length
#                 if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                     parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)













# #26-08-2025
# #added generate_alternative_scenarios and _generate_single_scenario and _generate_simple_scenario function for Alternative Scenarios in phase 3


# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks
#                 json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(1))
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group(0))
                    
#             except Exception as e:
#                 pass
#                 # print(f"JSON parsing error: {e}")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)
                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}
    
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#             """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
            
#             # Extract key elements from Futures Triangle 2.0
#             drivers = triangle_2_0_data.get('drivers', [])
#             enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#             push_of_present = enhanced_triangle.get('push_of_present', {})
            
#             # Format drivers context - focus on high certainty/high impact
#             high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#             drivers_context = ""
#             for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#                 drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
            
#             # Format Push of Present context
#             trends = push_of_present.get('trends', [])
#             existing_drivers = push_of_present.get('drivers', [])
#             push_context = ""
#             if trends:
#                 push_context += "Current Trends: " + ", ".join(trends[:4])
#             if existing_drivers:
#                 push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
            
#             # Project context
#             project_name = phase1_data.get('project_name', domain) if phase1_data else domain
            
#             prompt = f"""
#             You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#             PROJECT CONTEXT:
#             Project: {project_name}
#             Domain: {domain}
            
#             BASELINE SCENARIO DEFINITION:
#             The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#             1. **Push of the Present**: Current trends and momentum
#             2. **Key Drivers**: High-certainty forces shaping the future
            
#             PUSH OF THE PRESENT (Current Momentum):
#             {push_context}
            
#             KEY DRIVERS (High Certainty Forces):
#             {drivers_context}
            
#             BASELINE SCENARIO REQUIREMENTS:
            
#             **Structure (3-4 paragraphs, 250-350 words total):**
            
#             **Paragraph 1 - Present Momentum (70-90 words):**
#             - Describe the current state and ongoing trends
#             - Establish the "Push of the Present" foundation
#             - Set the context for continuation rather than transformation
            
#             **Paragraph 2 - Primary Drivers (80-100 words):**
#             - Focus on the highest certainty, highest impact drivers
#             - Explain how these forces reinforce current trajectories
#             - Show momentum building from existing patterns
            
#             **Paragraph 3 - Secondary Drivers & Evolution (80-100 words):**
#             - Include additional drivers that support the baseline path
#             - Show how the domain evolves within existing frameworks
#             - Demonstrate gradual rather than revolutionary change
            
#             **Paragraph 4 - Baseline Future State (60-80 words):**
#             - Synthesize into a coherent "most likely" future
#             - Emphasize continuation and extension of current trends
#             - Position as the foundation before exploring alternatives
            
#             **Writing Style:**
#             - Narrative and story-like, but grounded in evidence
#             - Confident but not overly optimistic
#             - Focus on "what's most likely" rather than "what's possible"
#             - Use concrete details from the domain context
            
#             **Critical Focus:**
#             - This is NOT about transformation or disruption
#             - This IS about logical extension of current momentum
#             - Emphasize high-certainty, predictable developments
#             - Set up the contrast for later alternative scenarios
            
#             Format your response as JSON:
#             {{
#                 "scenario_title": "Descriptive title for the baseline scenario",
#                 "timeframe": "2025-2030" or appropriate timeframe,
#                 "scenario_text": "The complete 3-4 paragraph narrative text",
#                 "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#                 "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#                 "scenario_type": "Baseline/Continuation"
#             }}
            
#             Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                             You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                             high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                             and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=1500,
#                     temperature=0.6  # Lower temperature for more consistent baseline scenarios
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)
                
#                 # Validate required fields
#                 required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#                 for field in required_fields:
#                     if field not in parsed_result:
#                         parsed_result[field] = f"Generated {field} for {domain}"
                                
#                 # Ensure scenario_text exists and is reasonable length
#                 if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                     parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         # Add this new dictionary for unique driver emphasis after focus_areas:

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Update the prompt section to include unique driver emphasis:

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (4 detailed paragraphs):
#         1. Initial conditions specific to {selected_focus} (2025-2026)
#         2. Key developments driven by {unique_drivers} (2027-2028) 
#         3. Full manifestation of {selected_focus} (2029-2030)
#         4. Final system state shaped by {selected_focus} (2030)

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four detailed paragraphs focusing exclusively on {selected_focus} and {unique_drivers}...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, and indicators scenario-specific."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,
#                 temperature=0.8,  # Higher temperature for more creativity
#                 response_format={"type": "json_object"}
#             )
            
#             response_text = response.choices[0].message.content.strip()
#             parsed_result = json.loads(response_text)
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Ensure unique titles by adding scenario number if needed
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }





# #much better--solved Stronger Diversity Across Scenarios
#     # def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#     #     """Generate alternative scenarios based on selected archetypes."""
        
#     #     # Archetype definitions
#     #     archetype_definitions = {
#     #         "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#     #         "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#     #         "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#     #     }
        
#     #     scenarios = []
        
#     #     for archetype, count in selected_archetypes.items():
#     #         if count > 0:
#     #             for i in range(count):
#     #                 scenario = self._generate_single_scenario(
#     #                     domain=domain,
#     #                     archetype=archetype, 
#     #                     archetype_definition=archetype_definitions.get(archetype, ""),
#     #                     baseline_data=baseline_data,
#     #                     driver_outcomes=driver_outcomes,
#     #                     triangle_2_0_data=triangle_2_0_data,
#     #                     scenario_number=i+1
#     #                 )
#     #                 scenarios.append(scenario)
        
#     #     return {"scenarios": scenarios}

#     # def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#     #                             baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#     #                             scenario_number: int = 1) -> Dict:
#     #     """Generate a single scenario narrative with improved diversity."""
        
#     #     # Extract key context
#     #     baseline_text = baseline_data.get('scenario_text', '')
#     #     baseline_title = baseline_data.get('scenario_title', '')
        
#     #     # Get driver outcomes for this archetype
#     #     relevant_outcomes = []
#     #     for driver in driver_outcomes.get('driver_outcomes', []):
#     #         for outcome in driver.get('outcomes', []):
#     #             outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#     #             target_archetype = archetype.lower().replace(' ', '')
#     #             if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#     #     # If no relevant outcomes found, get first few driver outcomes
#     #     if not relevant_outcomes:
#     #         for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#     #             for outcome in driver.get('outcomes', [])[:1]:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#     #     # Create scenario-specific focus areas to ensure diversity
#     #     focus_areas = {
#     #         "Collapse": [
#     #             "financial system breakdown and economic collapse",
#     #             "institutional failure and governance breakdown", 
#     #             "technological obsolescence and infrastructure decay",
#     #             "social fragmentation and cultural alienation"
#     #         ],
#     #         "New Equilibrium": [
#     #             "sustainable development and environmental stewardship",
#     #             "inclusive governance and democratic reforms",
#     #             "regional cooperation and diplomatic balance",
#     #             "tradition preservation with selective innovation"
#     #         ],
#     #         "Transformation": [
#     #             "breakthrough technological revolution and digitization",
#     #             "global democratization and grassroots expansion",
#     #             "radical business model innovation and new economics",
#     #             "social impact revolution and cultural transformation"
#     #         ]
#     #     }

#     #     # Add this new dictionary for unique driver emphasis after focus_areas:

#     #     unique_drivers_per_scenario = {
#     #         "Collapse": [
#     #             "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#     #             "regulatory conflicts, visa restrictions, political tensions between nations",
#     #             "aging infrastructure, resistance to new technology, equipment failures",
#     #             "generational disconnect, competing entertainment, loss of cultural relevance"
#     #         ],
#     #         "New Equilibrium": [
#     #             "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#     #             "stakeholder representation, transparent governance, democratic decision-making",
#     #             "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#     #             "heritage conservation, selective tech integration, cultural preservation"
#     #         ],
#     #         "Transformation": [
#     #             "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#     #             "non-traditional markets, grassroots accessibility, global talent mobility",
#     #             "subscription models, fan ownership, cryptocurrency integration, direct investment",
#     #             "gender equality initiatives, community development, social change catalyst"
#     #         ]
#     #     }

#     #     # Update the prompt section to include unique driver emphasis:

#     #     # Select focus and unique drivers based on scenario number
#     #     focus_list = focus_areas.get(archetype, ["general system changes"])
#     #     selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#     #     drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#     #     unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#     #     prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#     #     ARCHETYPE: {archetype} - {archetype_definition}
#     #     UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#     #     UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#     #     BASELINE CONTEXT:
#     #     {baseline_text[:400]}

#     #     REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#     #     {chr(10).join(relevant_outcomes[:4])}

#     #     CRITICAL DIVERSITY REQUIREMENTS:
#     #     - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#     #     - Focus ONLY on {selected_focus} - do not mix with other focus areas
#     #     - Emphasize these unique drivers: {unique_drivers}
#     #     - Create a unique storyline with different triggers, progression, and outcomes
#     #     - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#     #     - Probability assessment must vary and be justified
#     #     - All factors, assumptions, and indicators must be unique to this specific focus

#     #     STRUCTURE (4 detailed paragraphs):
#     #     1. Initial conditions specific to {selected_focus} (2025-2026)
#     #     2. Key developments driven by {unique_drivers} (2027-2028) 
#     #     3. Full manifestation of {selected_focus} (2029-2030)
#     #     4. Final system state shaped by {selected_focus} (2030)

#     #     Return ONLY valid JSON:
#     #     {{
#     #         "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#     #         "archetype": "{archetype}",
#     #         "timeframe": "2025-2030", 
#     #         "scenario_text": "Four detailed paragraphs focusing exclusively on {selected_focus} and {unique_drivers}...",
#     #         "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#     #         "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#     #         "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#     #         "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#     #     }}

#     #     ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#     #     try:
#     #         response = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": f"You are creating scenario #{scenario_number} for {archetype}. Make it unique and focused on {selected_focus}. Explicitly integrate the provided driver outcomes into the narrative. Vary titles, assumptions, and probability assessments to create distinct scenarios."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2000,
#     #             temperature=0.8,  # Higher temperature for more creativity
#     #             response_format={"type": "json_object"}
#     #         )
            
#     #         response_text = response.choices[0].message.content.strip()
#     #         parsed_result = json.loads(response_text)
            
#     #         # Validate and ensure required fields
#     #         if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#     #             raise ValueError("Scenario text too short or missing")
            
#     #         # Ensure unique titles by adding scenario number if needed
#     #         title = parsed_result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#     #         if scenario_number > 1 and not any(char.isdigit() for char in title):
#     #             title = f"{title} #{scenario_number}"
#     #         parsed_result['scenario_title'] = title
                
#     #         # Set proper defaults
#     #         parsed_result.setdefault('archetype', archetype)
#     #         parsed_result.setdefault('timeframe', '2025-2030')
#     #         parsed_result.setdefault('key_factors', [])
#     #         parsed_result.setdefault('critical_assumptions', [])
#     #         parsed_result.setdefault('probability_assessment', 'Medium')
#     #         parsed_result.setdefault('key_indicators', [])
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         print(f"Scenario generation error: {str(e)}")
#     #         return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     # def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#     #     """Fallback simple scenario generation with focus area."""
        
#     #     simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     # Focus on: {focus_area or archetype.lower()}

#     # Write 3 paragraphs showing progression over time.

#     # Return JSON:
#     # {{
#     #     "scenario_title": "Unique title for scenario #{scenario_number}",
#     #     "archetype": "{archetype}",
#     #     "timeframe": "2025-2030",
#     #     "scenario_text": "3 paragraph narrative...",
#     #     "key_factors": ["factor1", "factor2", "factor3"],
#     #     "critical_assumptions": ["assumption1", "assumption2"], 
#     #     "probability_assessment": "Low/Medium/High",
#     #     "key_indicators": ["indicator1", "indicator2"]
#     # }}"""
        
#     #     try:
#     #         response = self.client.chat.completions.create(
#     #             messages=[
#     #                 {"role": "system", "content": f"Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. Emphasize these unique drivers: {unique_drivers}. This must be entirely different from other {archetype} scenarios. Vary the probability assessment and justify it based on the unique drivers."},
#     #                 {"role": "user", "content": simple_prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.9,
#     #             response_format={"type": "json_object"}
#     #         )
            
#     #         result = json.loads(response.choices[0].message.content.strip())
            
#     #         # Ensure unique title
#     #         title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#     #         if scenario_number > 1:
#     #             title = f"{title} #{scenario_number}"
#     #         result['scenario_title'] = title
            
#     #         return result
            
#     #     except Exception as e:
#     #         print(f"Simple scenario generation failed: {str(e)}")
#     #         return {
#     #             "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#     #             "archetype": archetype,
#     #             "timeframe": "2025-2030",
#     #             "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#     #             "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#     #             "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#     #             "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#     #             "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#     #         }


# #little bit ok
#     # def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#     #     """Generate alternative scenarios based on selected archetypes."""
        
#     #     # Archetype definitions
#     #     archetype_definitions = {
#     #         "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#     #         "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#     #         "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#     #     }
        
#     #     scenarios = []
        
#     #     for archetype, count in selected_archetypes.items():
#     #         if count > 0:
#     #             for i in range(count):
#     #                 scenario = self._generate_single_scenario(
#     #                     domain=domain,
#     #                     archetype=archetype, 
#     #                     archetype_definition=archetype_definitions.get(archetype, ""),
#     #                     baseline_data=baseline_data,
#     #                     driver_outcomes=driver_outcomes,
#     #                     triangle_2_0_data=triangle_2_0_data,
#     #                     scenario_number=i+1
#     #                 )
#     #                 scenarios.append(scenario)
        
#     #     return {"scenarios": scenarios}

#     # def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#     #                             baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#     #                             scenario_number: int = 1) -> Dict:
#     #     """Generate a single scenario narrative with improved diversity."""
        
#     #     # Extract key context
#     #     baseline_text = baseline_data.get('scenario_text', '')
#     #     baseline_title = baseline_data.get('scenario_title', '')
        
#     #     # Get driver outcomes for this archetype
#     #     relevant_outcomes = []
#     #     for driver in driver_outcomes.get('driver_outcomes', []):
#     #         for outcome in driver.get('outcomes', []):
#     #             outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#     #             target_archetype = archetype.lower().replace(' ', '')
#     #             if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#     #     # If no relevant outcomes found, get first few driver outcomes
#     #     if not relevant_outcomes:
#     #         for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#     #             for outcome in driver.get('outcomes', [])[:1]:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#     #     # Create scenario-specific focus areas to ensure diversity
#     #     focus_areas = {
#     #         "Collapse": [
#     #             "financial system breakdown and resource scarcity",
#     #             "institutional failure and governance collapse", 
#     #             "technology failures and infrastructure decay",
#     #             "social fragmentation and trust erosion"
#     #         ],
#     #         "New Equilibrium": [
#     #             "adaptive governance and reformed institutions",
#     #             "balanced resource management and sustainable practices",
#     #             "incremental innovation and gradual improvement",
#     #             "stakeholder compromise and collaborative solutions"
#     #         ],
#     #         "Transformation": [
#     #             "breakthrough technological revolution",
#     #             "fundamental paradigm shift in operations",
#     #             "exponential growth and global expansion", 
#     #             "radical innovation and system redesign"
#     #         ]
#     #     }
        
#     #     # Select focus based on scenario number to ensure diversity
#     #     focus_list = focus_areas.get(archetype, ["general system changes"])
#     #     selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#     #     prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#     # ARCHETYPE: {archetype} - {archetype_definition}
#     # SCENARIO FOCUS: This scenario should emphasize {selected_focus}

#     # BASELINE CONTEXT:
#     # {baseline_text[:400]}

#     # REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#     # {chr(10).join(relevant_outcomes[:4])}

#     # CRITICAL INSTRUCTIONS:
#     # - This is scenario #{scenario_number} for {archetype}. It must be DISTINCT from all other scenarios in this archetype (no repetition of the same drivers or storyline).
#     # - Use the focus area "{selected_focus}" as the unique lens to build the scenario.
#     # - Write 34 fully developed paragraphs (minimum 56 sentences each) covering:
#     # 1. Early conditions and signals (20252026)
#     # 2. Escalating dynamics and turning points (20272028)
#     # 3. Full manifestation of the archetypes logic (20292030)
#     # 4. The final system state by 2030
#     # - Explicitly weave in the listed driver outcomes into the narrative (not as bullets, but naturally integrated).
#     # - The scenario title must be creative, vivid, and archetype-specific (avoid numbering like Scenario 2).
#     # - Probability assessment must be justified in context.
#     # - Ensure that "key_factors", "critical_assumptions", and "key_indicators" are unique to THIS scenario, not generic boilerplate.


#     # STRUCTURE (3-4 paragraphs):
#     # 1. Initial conditions and early indicators (2025-2026)
#     # 2. Key developments and turning points (2027-2028) 
#     # 3. Full manifestation of {selected_focus} (2029-2030)
#     # 4. Final system state by 2030

#     # Return ONLY valid JSON:
#     # {{
#     #     "scenario_title": "Unique creative title reflecting {selected_focus}",
#     #     "archetype": "{archetype}",
#     #     "timeframe": "2025-2030", 
#     #     "scenario_text": "Detailed narrative explicitly incorporating the driver outcomes...",
#     #     "key_factors": ["unique factor 1", "unique factor 2", "unique factor 3", "unique factor 4", "unique factor 5"],
#     #     "critical_assumptions": ["specific assumption 1", "specific assumption 2", "specific assumption 3"],
#     #     "probability_assessment": "Low/Medium/High based on scenario plausibility",
#     #     "key_indicators": ["specific early warning 1", "specific early warning 2", "specific early warning 3"]
#     # }}

#     # ENSURE: Each field reflects the unique focus on {selected_focus} and integrates the specific driver outcomes."""

#     #     try:
#     #         response = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": f"You are creating scenario #{scenario_number} for {archetype}. Make it unique and focused on {selected_focus}. Explicitly integrate the provided driver outcomes into the narrative. Vary titles, assumptions, and probability assessments to create distinct scenarios."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2000,
#     #             temperature=0.8,  # Higher temperature for more creativity
#     #             response_format={"type": "json_object"}
#     #         )
            
#     #         response_text = response.choices[0].message.content.strip()
#     #         parsed_result = json.loads(response_text)
            
#     #         # Validate and ensure required fields
#     #         if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#     #             raise ValueError("Scenario text too short or missing")
            
#     #         # Ensure unique titles by adding scenario number if needed
#     #         title = parsed_result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#     #         if scenario_number > 1 and not any(char.isdigit() for char in title):
#     #             title = f"{title} #{scenario_number}"
#     #         parsed_result['scenario_title'] = title
                
#     #         # Set proper defaults
#     #         parsed_result.setdefault('archetype', archetype)
#     #         parsed_result.setdefault('timeframe', '2025-2030')
#     #         parsed_result.setdefault('key_factors', [])
#     #         parsed_result.setdefault('critical_assumptions', [])
#     #         parsed_result.setdefault('probability_assessment', 'Medium')
#     #         parsed_result.setdefault('key_indicators', [])
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         print(f"Scenario generation error: {str(e)}")
#     #         return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     # def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#     #     """Fallback simple scenario generation with focus area."""
        
#     #     simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     # Focus on: {focus_area or archetype.lower()}

#     # Write 3 paragraphs showing progression over time.

#     # Return JSON:
#     # {{
#     #     "scenario_title": "Unique title for scenario #{scenario_number}",
#     #     "archetype": "{archetype}",
#     #     "timeframe": "2025-2030",
#     #     "scenario_text": "3 paragraph narrative...",
#     #     "key_factors": ["factor1", "factor2", "factor3"],
#     #     "critical_assumptions": ["assumption1", "assumption2"], 
#     #     "probability_assessment": "Low/Medium/High",
#     #     "key_indicators": ["indicator1", "indicator2"]
#     # }}"""
        
#     #     try:
#     #         response = self.client.chat.completions.create(
#     #             messages=[
#     #                 {"role": "system", "content": f"Create unique scenario #{scenario_number} focusing on {focus_area}. Ensure distinct title and content."},
#     #                 {"role": "user", "content": simple_prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.7,
#     #             response_format={"type": "json_object"}
#     #         )
            
#     #         result = json.loads(response.choices[0].message.content.strip())
            
#     #         # Ensure unique title
#     #         title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#     #         if scenario_number > 1:
#     #             title = f"{title} #{scenario_number}"
#     #         result['scenario_title'] = title
            
#     #         return result
            
#     #     except Exception as e:
#     #         print(f"Simple scenario generation failed: {str(e)}")
#     #         return {
#     #             "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#     #             "archetype": archetype,
#     #             "timeframe": "2025-2030",
#     #             "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#     #             "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#     #             "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#     #             "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#     #             "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#     #         }

# #ok    
#     # def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#     #     """Generate alternative scenarios based on selected archetypes."""
        
#     #     # Archetype definitions
#     #     archetype_definitions = {
#     #         "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#     #         "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#     #         "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#     #     }
        
#     #     scenarios = []
        
#     #     for archetype, count in selected_archetypes.items():
#     #         if count > 0:
#     #             for i in range(count):
#     #                 scenario = self._generate_single_scenario(
#     #                     domain=domain,
#     #                     archetype=archetype, 
#     #                     archetype_definition=archetype_definitions.get(archetype, ""),
#     #                     baseline_data=baseline_data,
#     #                     driver_outcomes=driver_outcomes,
#     #                     triangle_2_0_data=triangle_2_0_data,
#     #                     scenario_number=i+1
#     #                 )
#     #                 scenarios.append(scenario)
        
#     #     return {"scenarios": scenarios}

#     # def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#     #                             baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#     #                             scenario_number: int = 1) -> Dict:
#     #     """Generate a single scenario narrative with improved diversity."""
        
#     #     # Extract key context
#     #     baseline_text = baseline_data.get('scenario_text', '')
#     #     baseline_title = baseline_data.get('scenario_title', '')
        
#     #     # Get driver outcomes for this archetype
#     #     relevant_outcomes = []
#     #     for driver in driver_outcomes.get('driver_outcomes', []):
#     #         for outcome in driver.get('outcomes', []):
#     #             outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#     #             target_archetype = archetype.lower().replace(' ', '')
#     #             if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#     #     # If no relevant outcomes found, get first few driver outcomes
#     #     if not relevant_outcomes:
#     #         for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#     #             for outcome in driver.get('outcomes', [])[:1]:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#     #     # Create scenario-specific focus areas to ensure diversity
#     #     focus_areas = {
#     #         "Collapse": [
#     #             "financial system breakdown and resource scarcity",
#     #             "institutional failure and governance collapse", 
#     #             "technology failures and infrastructure decay",
#     #             "social fragmentation and trust erosion"
#     #         ],
#     #         "New Equilibrium": [
#     #             "adaptive governance and reformed institutions",
#     #             "balanced resource management and sustainable practices",
#     #             "incremental innovation and gradual improvement",
#     #             "stakeholder compromise and collaborative solutions"
#     #         ],
#     #         "Transformation": [
#     #             "breakthrough technological revolution",
#     #             "fundamental paradigm shift in operations",
#     #             "exponential growth and global expansion", 
#     #             "radical innovation and system redesign"
#     #         ]
#     #     }
        
#     #     # Select focus based on scenario number to ensure diversity
#     #     focus_list = focus_areas.get(archetype, ["general system changes"])
#     #     selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#     #     prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#     # ARCHETYPE: {archetype} - {archetype_definition}
#     # SCENARIO FOCUS: This scenario should emphasize {selected_focus}

#     # BASELINE CONTEXT:
#     # {baseline_text[:400]}

#     # REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#     # {chr(10).join(relevant_outcomes[:4])}

#     # CRITICAL INSTRUCTIONS:
#     # - This is scenario #{scenario_number} for {archetype} - make it DISTINCT from other {archetype} scenarios
#     # - Focus specifically on {selected_focus} as the primary mechanism
#     # - Explicitly reference and build upon the driver outcomes listed above
#     # - Create a unique, compelling title (not generic)
#     # - Vary the probability assessment based on plausibility (Low/Medium/High)

#     # STRUCTURE (3-4 paragraphs):
#     # 1. Initial conditions and early indicators (2025-2026)
#     # 2. Key developments and turning points (2027-2028) 
#     # 3. Full manifestation of {selected_focus} (2029-2030)
#     # 4. Final system state by 2030

#     # Return ONLY valid JSON:
#     # {{
#     #     "scenario_title": "Unique creative title reflecting {selected_focus}",
#     #     "archetype": "{archetype}",
#     #     "timeframe": "2025-2030", 
#     #     "scenario_text": "Detailed narrative explicitly incorporating the driver outcomes...",
#     #     "key_factors": ["unique factor 1", "unique factor 2", "unique factor 3", "unique factor 4", "unique factor 5"],
#     #     "critical_assumptions": ["specific assumption 1", "specific assumption 2", "specific assumption 3"],
#     #     "probability_assessment": "Low/Medium/High based on scenario plausibility",
#     #     "key_indicators": ["specific early warning 1", "specific early warning 2", "specific early warning 3"]
#     # }}

#     # ENSURE: Each field reflects the unique focus on {selected_focus} and integrates the specific driver outcomes."""

#     #     try:
#     #         response = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": f"You are creating scenario #{scenario_number} for {archetype}. Make it unique and focused on {selected_focus}. Explicitly integrate the provided driver outcomes into the narrative. Vary titles, assumptions, and probability assessments to create distinct scenarios."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2000,
#     #             temperature=0.8,  # Higher temperature for more creativity
#     #             response_format={"type": "json_object"}
#     #         )
            
#     #         response_text = response.choices[0].message.content.strip()
#     #         parsed_result = json.loads(response_text)
            
#     #         # Validate and ensure required fields
#     #         if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#     #             raise ValueError("Scenario text too short or missing")
            
#     #         # Ensure unique titles by adding scenario number if needed
#     #         title = parsed_result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#     #         if scenario_number > 1 and not any(char.isdigit() for char in title):
#     #             title = f"{title} #{scenario_number}"
#     #         parsed_result['scenario_title'] = title
                
#     #         # Set proper defaults
#     #         parsed_result.setdefault('archetype', archetype)
#     #         parsed_result.setdefault('timeframe', '2025-2030')
#     #         parsed_result.setdefault('key_factors', [])
#     #         parsed_result.setdefault('critical_assumptions', [])
#     #         parsed_result.setdefault('probability_assessment', 'Medium')
#     #         parsed_result.setdefault('key_indicators', [])
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         print(f"Scenario generation error: {str(e)}")
#     #         return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     # def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#     #     """Fallback simple scenario generation with focus area."""
        
#     #     simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     # Focus on: {focus_area or archetype.lower()}

#     # Write 3 paragraphs showing progression over time.

#     # Return JSON:
#     # {{
#     #     "scenario_title": "Unique title for scenario #{scenario_number}",
#     #     "archetype": "{archetype}",
#     #     "timeframe": "2025-2030",
#     #     "scenario_text": "3 paragraph narrative...",
#     #     "key_factors": ["factor1", "factor2", "factor3"],
#     #     "critical_assumptions": ["assumption1", "assumption2"], 
#     #     "probability_assessment": "Low/Medium/High",
#     #     "key_indicators": ["indicator1", "indicator2"]
#     # }}"""
        
#     #     try:
#     #         response = self.client.chat.completions.create(
#     #             messages=[
#     #                 {"role": "system", "content": f"Create unique scenario #{scenario_number} focusing on {focus_area}. Ensure distinct title and content."},
#     #                 {"role": "user", "content": simple_prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.7,
#     #             response_format={"type": "json_object"}
#     #         )
            
#     #         result = json.loads(response.choices[0].message.content.strip())
            
#     #         # Ensure unique title
#     #         title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#     #         if scenario_number > 1:
#     #             title = f"{title} #{scenario_number}"
#     #         result['scenario_title'] = title
            
#     #         return result
            
#     #     except Exception as e:
#     #         print(f"Simple scenario generation failed: {str(e)}")
#     #         return {
#     #             "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#     #             "archetype": archetype,
#     #             "timeframe": "2025-2030",
#     #             "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#     #             "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#     #             "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#     #             "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#     #             "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#     #         }


# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)














#28-08-2025
#updated the  def generate_baseline_scenario function because we not get the output some times
#updated the  def _parse_json_response

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
    
#     def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
#         """Parse JSON from AI response, handling markdown code blocks."""
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except json.JSONDecodeError:
#             # Try to extract JSON from markdown code blocks
#             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#             if json_match:
#                 try:
#                     return json.loads(json_match.group(1))
#                 except json.JSONDecodeError:
#                     pass
            
#             # If no valid JSON found, return raw response for debugging
#             return {
#                 "error": "Failed to parse JSON response",
#                 "raw_response": response_text
#             }
    
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     # def _parse_json_response(self, response_text: str) -> Dict:
#     #     """Enhanced JSON parsing with better error handling."""
#     #     import json
#     #     import re
        
#     #     try:
#     #         # First try direct JSON parsing
#     #         return json.loads(response_text)
#     #     except:
#     #         try:
#     #             # Look for JSON in code blocks
#     #             json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', response_text, re.DOTALL)
#     #             if json_match:
#     #                 return json.loads(json_match.group(1))
                
#     #             # Look for JSON-like structure without code blocks
#     #             json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#     #             if json_match:
#     #                 return json.loads(json_match.group(0))
                    
#     #         except Exception as e:
#     #             pass
#     #             # print(f"JSON parsing error: {e}")
                
#     #         # Return empty dict if all parsing fails
#     #         return {}

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings (but preserve paragraph structure)
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)
#             return json_str
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 # ADD THESE DEBUG LINES HERE:
#                 # print("=== FUTURES TRIANGLE 2.0 RAW AI RESPONSE ===")
#                 # print(response_text)
#                 # print("=== END RAW RESPONSE ===")
#                 parsed_result = self._parse_json_response(response_text)
#                 # print("=== PARSED RESULT ===")
#                 # print(parsed_result)
#                 # print("=== END PARSED ===")
                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 250-350 words total):**
        
#         **Paragraph 1 - Present Momentum (70-90 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (80-100 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (80-100 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (60-80 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             # ADD THESE DEBUG LINES:
#             print("=== RAW AI RESPONSE ===")
#             print(response_text)
#             print("=== END RAW RESPONSE ===")
#             parsed_result = self._parse_json_response(response_text)
#             print("=== PARSED RESULT ===")
#             print(parsed_result)
#             print("=== END PARSED ===")
            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}

# #old    
#     # def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#     #         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
            
#     #         # Extract key elements from Futures Triangle 2.0
#     #         drivers = triangle_2_0_data.get('drivers', [])
#     #         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#     #         push_of_present = enhanced_triangle.get('push_of_present', {})
            
#     #         # Format drivers context - focus on high certainty/high impact
#     #         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#     #         drivers_context = ""
#     #         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#     #             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
            
#     #         # Format Push of Present context
#     #         trends = push_of_present.get('trends', [])
#     #         existing_drivers = push_of_present.get('drivers', [])
#     #         push_context = ""
#     #         if trends:
#     #             push_context += "Current Trends: " + ", ".join(trends[:4])
#     #         if existing_drivers:
#     #             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
            
#     #         # Project context
#     #         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
            
#     #         prompt = f"""
#     #         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#     #         PROJECT CONTEXT:
#     #         Project: {project_name}
#     #         Domain: {domain}
            
#     #         BASELINE SCENARIO DEFINITION:
#     #         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#     #         1. **Push of the Present**: Current trends and momentum
#     #         2. **Key Drivers**: High-certainty forces shaping the future
            
#     #         PUSH OF THE PRESENT (Current Momentum):
#     #         {push_context}
            
#     #         KEY DRIVERS (High Certainty Forces):
#     #         {drivers_context}
            
#     #         BASELINE SCENARIO REQUIREMENTS:
            
#     #         **Structure (3-4 paragraphs, 250-350 words total):**
            
#     #         **Paragraph 1 - Present Momentum (70-90 words):**
#     #         - Describe the current state and ongoing trends
#     #         - Establish the "Push of the Present" foundation
#     #         - Set the context for continuation rather than transformation
            
#     #         **Paragraph 2 - Primary Drivers (80-100 words):**
#     #         - Focus on the highest certainty, highest impact drivers
#     #         - Explain how these forces reinforce current trajectories
#     #         - Show momentum building from existing patterns
            
#     #         **Paragraph 3 - Secondary Drivers & Evolution (80-100 words):**
#     #         - Include additional drivers that support the baseline path
#     #         - Show how the domain evolves within existing frameworks
#     #         - Demonstrate gradual rather than revolutionary change
            
#     #         **Paragraph 4 - Baseline Future State (60-80 words):**
#     #         - Synthesize into a coherent "most likely" future
#     #         - Emphasize continuation and extension of current trends
#     #         - Position as the foundation before exploring alternatives
            
#     #         **Writing Style:**
#     #         - Narrative and story-like, but grounded in evidence
#     #         - Confident but not overly optimistic
#     #         - Focus on "what's most likely" rather than "what's possible"
#     #         - Use concrete details from the domain context
            
#     #         **Critical Focus:**
#     #         - This is NOT about transformation or disruption
#     #         - This IS about logical extension of current momentum
#     #         - Emphasize high-certainty, predictable developments
#     #         - Set up the contrast for later alternative scenarios
            
#     #         Format your response as JSON:
#     #         {{
#     #             "scenario_title": "Descriptive title for the baseline scenario",
#     #             "timeframe": "2025-2030" or appropriate timeframe,
#     #             "scenario_text": "The complete 3-4 paragraph narrative text",
#     #             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#     #             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#     #             "scenario_type": "Baseline/Continuation"
#     #         }}
            
#     #         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#     #         """
            
#     #         try:
#     #             chat_completion = self.client.chat.completions.create(
#     #                 messages=[
#     #                     {
#     #                         "role": "system",
#     #                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#     #                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#     #                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#     #                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#     #                     },
#     #                     {"role": "user", "content": prompt}
#     #                 ],
#     #                 model=self.model,
#     #                 max_tokens=1500,
#     #                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#     #             )
                
#     #             response_text = chat_completion.choices[0].message.content
#     #             # ADD THESE DEBUG LINES:
#     #             print("=== RAW AI RESPONSE ===")
#     #             print(response_text)
#     #             print("=== END RAW RESPONSE ===")
#     #             parsed_result = self._parse_json_response(response_text)
#     #             print("=== PARSED RESULT ===")
#     #             print(parsed_result)
#     #             print("=== END PARSED ===")
                
#     #             # Validate required fields
#     #             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#     #             for field in required_fields:
#     #                 if field not in parsed_result:
#     #                     parsed_result[field] = f"Generated {field} for {domain}"
                                
#     #             # Ensure scenario_text exists and is reasonable length
#     #             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#     #                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
                
#     #             return parsed_result
                    
#     #         except Exception as e:
#     #             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         # Add this new dictionary for unique driver emphasis after focus_areas:

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Update the prompt section to include unique driver emphasis:

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (4 detailed paragraphs):
#         1. Initial conditions specific to {selected_focus} (2025-2026)
#         2. Key developments driven by {unique_drivers} (2027-2028) 
#         3. Full manifestation of {selected_focus} (2029-2030)
#         4. Final system state shaped by {selected_focus} (2030)

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four detailed paragraphs focusing exclusively on {selected_focus} and {unique_drivers}...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, and indicators scenario-specific."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,
#                 temperature=0.8,  # Higher temperature for more creativity
#                 response_format={"type": "json_object"}
#             )
            
#             response_text = response.choices[0].message.content.strip()
#             parsed_result = json.loads(response_text)
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Ensure unique titles by adding scenario number if needed
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }

# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)











#28-08-2025
#updated the def _generate_single_scenario function for alternative_scenarios output
#updated the generate_driver_outcomes function increase the max_token=4000 because im not getting output in first click

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
        
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings (but preserve paragraph structure)
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)
#             return json_str
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 # ADD THESE DEBUG LINES HERE:
#                 # print("=== FUTURES TRIANGLE 2.0 RAW AI RESPONSE ===")
#                 # print(response_text)
#                 # print("=== END RAW RESPONSE ===")
#                 parsed_result = self._parse_json_response(response_text)
#                 # print("=== PARSED RESULT ===")
#                 # print(parsed_result)
#                 # print("=== END PARSED ===")
                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             # # ADD THESE DEBUG LINES:
#             # print("=== RAW AI RESPONSE ===")
#             # print(response_text)
#             # print("=== END RAW RESPONSE ===")
#             parsed_result = self._parse_json_response(response_text)
#             # print("=== PARSED RESULT ===")
#             # print(parsed_result)
#             # print("=== END PARSED ===")
            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}

#     # def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#     #     """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
#     #     # ADD: Log incoming data
#     #     print(f"=== GENERATE DRIVER OUTCOMES DEBUG ===")
#     #     print(f"Domain: {domain}")
#     #     print(f"Drivers count: {len(triangle_2_0_data.get('drivers', []))}")
#     #     print(f"Uncertainties count: {len(triangle_2_0_data.get('uncertainties', []))}")
#     #     print(f"Narratives count: {len(triangle_2_0_data.get('narratives', []))}")
#     #     print(f"Baseline data keys: {list(baseline_data.keys()) if baseline_data else 'None'}")
        
#     #     # Extract elements from Futures Triangle 2.0
#     #     drivers = triangle_2_0_data.get('drivers', [])
#     #     uncertainties = triangle_2_0_data.get('uncertainties', [])
#     #     narratives = triangle_2_0_data.get('narratives', [])
        
#     #     # Project context
#     #     project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#     #     # Format baseline context
#     #     baseline_context = f"""
#     #     BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#     #     Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#     #     Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#     #     """
        
#     #     prompt = f"""
#     #     You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#     #     PROJECT CONTEXT:
#     #     Project: {project_name}
#     #     Domain: {domain}
        
#     #     {baseline_context}
        
#     #     DRIVER OUTCOMES METHODOLOGY:
#     #     Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#     #     1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#     #     2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#     #     3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#     #     ELEMENTS TO BEND:
        
#     #     DRIVERS (Major Forces):
#     #     {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#     #     UNCERTAINTIES (Pivot Points):
#     #     {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#     #     NARRATIVES (Stories):
#     #     {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#     #     ARCHETYPE DEFINITIONS:
        
#     #     **COLLAPSE/DECLINE:**
#     #     - Systems fail, break down, or regress
#     #     - Negative feedback loops dominate
#     #     - Resources become scarce, trust erodes
#     #     - Institutions lose effectiveness
#     #     - Focus: "What goes wrong?"
        
#     #     **NEW EQUILIBRIUM:**
#     #     - Adaptive responses create stability
#     #     - Systems reform and find balance
#     #     - Gradual improvement within existing frameworks
#     #     - Incremental innovation and adjustment
#     #     - Focus: "How do we adapt?"
        
#     #     **TRANSFORMATION:**
#     #     - Breakthrough innovations emerge
#     #     - Fundamental paradigm shifts occur
#     #     - New systems replace old ones
#     #     - Exponential positive change
#     #     - Focus: "What becomes possible?"
        
#     #     OUTCOME REQUIREMENTS:
#     #     - Each element gets 3 outcomes (one per archetype)
#     #     - Outcomes should be 2-3 sentences each
#     #     - Stay grounded in the domain context
#     #     - Show how the same force creates different futures
#     #     - Make outcomes specific and plausible within each archetype
        
#     #     Format as JSON:
#     #     {{
#     #         "driver_outcomes": [
#     #             {{
#     #                 "driver_id": "D1",
#     #                 "driver_name": "Driver name from Triangle 2.0",
#     #                 "baseline_trajectory": "How this plays out in baseline",
#     #                 "outcomes": [
#     #                     {{
#     #                         "archetype": "Collapse/Decline",
#     #                         "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#     #                         "key_impacts": ["impact 1", "impact 2", "impact 3"]
#     #                     }},
#     #                     {{
#     #                         "archetype": "New Equilibrium", 
#     #                         "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#     #                         "key_impacts": ["impact 1", "impact 2", "impact 3"]
#     #                     }},
#     #                     {{
#     #                         "archetype": "Transformation",
#     #                         "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#     #                         "key_impacts": ["impact 1", "impact 2", "impact 3"]
#     #                     }}
#     #                 ]
#     #             }}
#     #         ],
#     #         "uncertainty_outcomes": [
#     #             {{
#     #                 "uncertainty_id": "U1",
#     #                 "uncertainty_name": "Uncertainty name from Triangle 2.0",
#     #                 "key_variables": ["var1", "var2"],
#     #                 "outcomes": [
#     #                     {{
#     #                         "archetype": "Collapse/Decline",
#     #                         "outcome_text": "How this uncertainty resolves in a collapse scenario",
#     #                         "resolution_direction": "Which way the uncertainty tips"
#     #                     }},
#     #                     {{
#     #                         "archetype": "New Equilibrium",
#     #                         "outcome_text": "How this uncertainty resolves in adaptive change",
#     #                         "resolution_direction": "Which way the uncertainty tips"
#     #                     }},
#     #                     {{
#     #                         "archetype": "Transformation", 
#     #                         "outcome_text": "How this uncertainty resolves in transformation",
#     #                         "resolution_direction": "Which way the uncertainty tips"
#     #                     }}
#     #                 ]
#     #             }}
#     #         ],
#     #         "narrative_outcomes": [
#     #             {{
#     #                 "narrative_id": "N1",
#     #                 "narrative_name": "Narrative name from Triangle 2.0",
#     #                 "narrative_type": "Dominant/Emerging/Alternative",
#     #                 "outcomes": [
#     #                     {{
#     #                         "archetype": "Collapse/Decline",
#     #                         "outcome_text": "How this narrative evolves in collapse",
#     #                         "narrative_shift": "What story dominates"
#     #                     }},
#     #                     {{
#     #                         "archetype": "New Equilibrium",
#     #                         "outcome_text": "How this narrative evolves in adaptation", 
#     #                         "narrative_shift": "What story dominates"
#     #                     }},
#     #                     {{
#     #                         "archetype": "Transformation",
#     #                         "outcome_text": "How this narrative evolves in transformation",
#     #                         "narrative_shift": "What story dominates"
#     #                     }}
#     #                 ]
#     #             }}
#     #         ],
#     #         "cross_archetype_insights": {{
#     #             "collapse_patterns": ["Common themes across collapse outcomes"],
#     #             "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#     #             "transformation_patterns": ["Common themes across transformation outcomes"],
#     #             "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#     #         }}
#     #     }}
        
#     #     CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#     #     """
        
#     #     try:
#     #         print("Making OpenAI API call...")
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#     #                     You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#     #                     differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#     #                     specific outcomes that demonstrate how the same forces can lead to very different futures. 
#     #                     Always respond with valid, complete JSON."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=4000,
#     #             temperature=0.7
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content

#     #         # ADD: Log raw AI response
#     #         print(f"Raw AI response length: {len(response_text)}")
#     #         print(f"Raw AI response preview: {response_text[:200]}...")
            
#     #         # Clean response - remove any markdown code blocks
#     #         response_text = response_text.strip()
#     #         if response_text.startswith('```json'):
#     #             response_text = response_text.replace('```json', '').replace('```', '').strip()
#     #         elif response_text.startswith('```'):
#     #             response_text = response_text.replace('```', '').strip()
            
#     #         print(f"Cleaned response length: {len(response_text)}")
#     #         print(f"Starts with valid JSON: {response_text.startswith('{')}")
                
#     #         parsed_result = self._parse_json_response(response_text)
#     #         print(f"Parsed result keys: {list(parsed_result.keys()) if isinstance(parsed_result, dict) else 'Not a dict'}")
            
#     #         # Validate required sections exist
#     #         required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#     #         for section in required_sections:
#     #             if section not in parsed_result:
#     #                 parsed_result[section] = []
            
#     #         # Ensure we have cross-archetype insights
#     #         if 'cross_archetype_insights' not in parsed_result:
#     #             parsed_result['cross_archetype_insights'] = {
#     #                 'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#     #                 'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#     #                 'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#     #                 'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#     #             }
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         # ADD: More detailed error logging
#     #         import traceback
#     #         print(f"ERROR in generate_driver_outcomes: {str(e)}")
#     #         print(f"Error type: {type(e)}")
#     #         print(f"Traceback: {traceback.format_exc()}")
#     #         return {"error": f"Failed to generate driver outcomes: {str(e)}"}

            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     # def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#     #                             baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#     #                             scenario_number: int = 1) -> Dict:
#     #     """Generate a single scenario narrative with improved diversity."""
        
#     #     # Extract key context
#     #     baseline_text = baseline_data.get('scenario_text', '')
#     #     baseline_title = baseline_data.get('scenario_title', '')
        
#     #     # Get driver outcomes for this archetype
#     #     relevant_outcomes = []
#     #     for driver in driver_outcomes.get('driver_outcomes', []):
#     #         for outcome in driver.get('outcomes', []):
#     #             outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#     #             target_archetype = archetype.lower().replace(' ', '')
#     #             if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#     #     # If no relevant outcomes found, get first few driver outcomes
#     #     if not relevant_outcomes:
#     #         for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#     #             for outcome in driver.get('outcomes', [])[:1]:
#     #                 relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#     #     # Create scenario-specific focus areas to ensure diversity
#     #     focus_areas = {
#     #         "Collapse": [
#     #             "financial system breakdown and economic collapse",
#     #             "institutional failure and governance breakdown", 
#     #             "technological obsolescence and infrastructure decay",
#     #             "social fragmentation and cultural alienation"
#     #         ],
#     #         "New Equilibrium": [
#     #             "sustainable development and environmental stewardship",
#     #             "inclusive governance and democratic reforms",
#     #             "regional cooperation and diplomatic balance",
#     #             "tradition preservation with selective innovation"
#     #         ],
#     #         "Transformation": [
#     #             "breakthrough technological revolution and digitization",
#     #             "global democratization and grassroots expansion",
#     #             "radical business model innovation and new economics",
#     #             "social impact revolution and cultural transformation"
#     #         ]
#     #     }

#     #     # Add this new dictionary for unique driver emphasis after focus_areas:

#     #     unique_drivers_per_scenario = {
#     #         "Collapse": [
#     #             "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#     #             "regulatory conflicts, visa restrictions, political tensions between nations",
#     #             "aging infrastructure, resistance to new technology, equipment failures",
#     #             "generational disconnect, competing entertainment, loss of cultural relevance"
#     #         ],
#     #         "New Equilibrium": [
#     #             "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#     #             "stakeholder representation, transparent governance, democratic decision-making",
#     #             "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#     #             "heritage conservation, selective tech integration, cultural preservation"
#     #         ],
#     #         "Transformation": [
#     #             "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#     #             "non-traditional markets, grassroots accessibility, global talent mobility",
#     #             "subscription models, fan ownership, cryptocurrency integration, direct investment",
#     #             "gender equality initiatives, community development, social change catalyst"
#     #         ]
#     #     }

#     #     # Update the prompt section to include unique driver emphasis:

#     #     # Select focus and unique drivers based on scenario number
#     #     focus_list = focus_areas.get(archetype, ["general system changes"])
#     #     selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#     #     drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#     #     unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#     #     prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#     #     ARCHETYPE: {archetype} - {archetype_definition}
#     #     UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#     #     UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#     #     BASELINE CONTEXT:
#     #     {baseline_text[:400]}

#     #     REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#     #     {chr(10).join(relevant_outcomes[:4])}

#     #     CRITICAL DIVERSITY REQUIREMENTS:
#     #     - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#     #     - Focus ONLY on {selected_focus} - do not mix with other focus areas
#     #     - Emphasize these unique drivers: {unique_drivers}
#     #     - Create a unique storyline with different triggers, progression, and outcomes
#     #     - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#     #     - Probability assessment must vary and be justified
#     #     - All factors, assumptions, and indicators must be unique to this specific focus

#     #     STRUCTURE (4 detailed paragraphs):
#     #     1. Initial conditions specific to {selected_focus} (2025-2026)
#     #     2. Key developments driven by {unique_drivers} (2027-2028) 
#     #     3. Full manifestation of {selected_focus} (2029-2030)
#     #     4. Final system state shaped by {selected_focus} (2030)

#     #     Return ONLY valid JSON:
#     #     {{
#     #         "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#     #         "archetype": "{archetype}",
#     #         "timeframe": "2025-2030", 
#     #         "scenario_text": "Four detailed paragraphs focusing exclusively on {selected_focus} and {unique_drivers}...",
#     #         "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#     #         "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#     #         "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#     #         "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#     #     }}

#     #     ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#     #     try:
#     #         response = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": f"Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, and indicators scenario-specific."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2000,
#     #             temperature=0.8,  # Higher temperature for more creativity
#     #             response_format={"type": "json_object"}
#     #         )
            
#     #         response_text = response.choices[0].message.content.strip()
#     #         parsed_result = json.loads(response_text)
            
#     #         # Validate and ensure required fields
#     #         if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#     #             raise ValueError("Scenario text too short or missing")
            
#     #         # Ensure unique titles by adding scenario number if needed
#     #         # Keep the AI-generated title as-is (no numbering fallback)
#     #         title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#     #         parsed_result['scenario_title'] = title
                
#     #         # Set proper defaults
#     #         parsed_result.setdefault('archetype', archetype)
#     #         parsed_result.setdefault('timeframe', '2025-2030')
#     #         parsed_result.setdefault('key_factors', [])
#     #         parsed_result.setdefault('critical_assumptions', [])
#     #         parsed_result.setdefault('probability_assessment', 'Medium')
#     #         parsed_result.setdefault('key_indicators', [])
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         print(f"Scenario generation error: {str(e)}")
#     #         return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }

# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)















#29-08-2025
#removed the # for all

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"
        
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         prompt = f"""
#         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#         analyze the following document content and create a comprehensive domain map.

#         Document Content:
#         {document_text[:3000]}  # Limit content to avoid token limits

#         Please generate a domain map with the following structure:
#         1. Central Domain (main focus area)
#         2. 5-7 key sub-domains or themes
#         3. Brief description for each sub-domain
#         4. Interconnections between domains

#         Format your response as a JSON object with this structure:
#         {{
#             "central_domain": "Main focus area title",
#             "description": "Brief description of the central domain",
#             "sub_domains": [
#                 {{
#                     "name": "Sub-domain name",
#                     "description": "Description of this sub-domain",
#                     "relevance": "High/Medium/Low"
#                 }}
#             ],
#             "interconnections": ["Brief description of how domains connect"]
#         }}

#         Keep the response focused and practical for foresight analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings (but preserve paragraph structure)
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)
#             return json_str
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }

# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)












#29-08-2025
#updated the domain map function

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"

#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         # Check if we have substantial document content
#         has_document_content = document_text and len(document_text.strip()) > 100
        
#         if has_document_content:
#             # Prioritize document content when available
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#             analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#             should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.
            

#             Document Content:
#             {document_text[:3000]}

#             Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#             For each sub-domain:
#             1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#             2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#             3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area based on document content",
#                 "description": "Detailed description derived from the document content (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name from document themes",
#                         "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 from document context",
#                             "Specific issue area 2 from document context",
#                             "Specific issue area 3 from document context",
#                             "Specific issue area 4 from document context",
#                             "Specific issue area 5 from document context",
#                             "Specific issue area 6 from document context",
#                             "Specific issue area 7 from document context",
#                             "Specific issue area 8 from document context"
#                         ]
#                     }}
#                 ]
#             }}

#             Focus on what the document actually discusses in detail rather than providing generic overviews.
#             """

#         else:
#             # Fall back to domain-based generation when no substantial document content
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#             create a comprehensive and detailed domain map for this specific focus area.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#             Generate detailed analysis with:
#             1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#             2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#             3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area title",
#                 "description": "Detailed description of the central domain (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name",
#                         "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 with clear focus",
#                             "Specific issue area 2 with clear focus",
#                             "Specific issue area 3 with clear focus",
#                             "Specific issue area 4 with clear focus",
#                             "Specific issue area 5 with clear focus",
#                             "Specific issue area 6 with clear focus",
#                             "Specific issue area 7 with clear focus",
#                             "Specific issue area 8 with clear focus"
#                         ]
#                     }}
#                 ]
#             }}

#             Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#             """
                
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}


# # new --but the description was answer was small

#     # def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#     #     """Generate domain map based on the selected domain and document content."""
        
#     #     # Check if we have substantial document content
#     #     has_document_content = document_text and len(document_text.strip()) > 100
        
#     #     if has_document_content:
#     #         # Prioritize document content when available
#     #         prompt = f"""
#     #         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#     #         analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#     #         should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.

#     #         Document Content:
#     #         {document_text[:3000]}

#     #         Please analyze the document content and generate a domain map that reflects the actual themes and topics discussed in the document.
#     #         If the document content differs from the selected domain "{domain}", prioritize the document content while noting the connection to the selected domain.

#     #         Format your response as a JSON object with this structure:
#     #         {{
#     #             "central_domain": "Main focus area based on document content",
#     #             "description": "Brief description derived from the document content",
#     #             "sub_domains": [
#     #                 {{
#     #                     "name": "Sub-domain name from document themes",
#     #                     "description": "Description based on document content",
#     #                     "relevance": "High/Medium/Low"
#     #                 }}
#     #             ],
#     #             "interconnections": ["Brief description of how domains connect based on document analysis"]
#     #         }}

#     #         Focus on what the document actually discusses rather than generic knowledge about "{domain}".
#     #         """
#     #     else:
#     #         # Fall back to domain-based generation when no substantial document content
#     #         prompt = f"""
#     #         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#     #         create a comprehensive domain map for this specific focus area.

#     #         Please generate a domain map with the following structure:
#     #         1. Central Domain (main focus area)
#     #         2. 5-7 key sub-domains or themes
#     #         3. Brief description for each sub-domain
#     #         4. Interconnections between domains

#     #         Format your response as a JSON object with this structure:
#     #         {{
#     #             "central_domain": "Main focus area title",
#     #             "description": "Brief description of the central domain",
#     #             "sub_domains": [
#     #                 {{
#     #                     "name": "Sub-domain name",
#     #                     "description": "Description of this sub-domain",
#     #                     "relevance": "High/Medium/Low"
#     #                 }}
#     #             ],
#     #             "interconnections": ["Brief description of how domains connect"]
#     #         }}

#     #         Keep the response focused and practical for foresight analysis of "{domain}".
#     #         """
                
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.7
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         return self._parse_json_response(response_text)
                
#     #     except Exception as e:
#     #         return {"error": f"Failed to generate domain map: {str(e)}"}

# #old
#     # def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#     #     """Generate domain map based on the selected domain and document content."""
        
#     #     prompt = f"""
#     #     You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#     #     analyze the following document content and create a comprehensive domain map.

#     #     Document Content:
#     #     {document_text[:3000]}  # Limit content to avoid token limits

#     #     Please generate a domain map with the following structure:
#     #     1. Central Domain (main focus area)
#     #     2. 5-7 key sub-domains or themes
#     #     3. Brief description for each sub-domain
#     #     4. Interconnections between domains

#     #     Format your response as a JSON object with this structure:
#     #     {{
#     #         "central_domain": "Main focus area title",
#     #         "description": "Brief description of the central domain",
#     #         "sub_domains": [
#     #             {{
#     #                 "name": "Sub-domain name",
#     #                 "description": "Description of this sub-domain",
#     #                 "relevance": "High/Medium/Low"
#     #             }}
#     #         ],
#     #         "interconnections": ["Brief description of how domains connect"]
#     #     }}

#     #     Keep the response focused and practical for foresight analysis.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.7
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         return self._parse_json_response(response_text)
                
#     #     except Exception as e:
#     #         return {"error": f"Failed to generate domain map: {str(e)}"}
    
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings (but preserve paragraph structure)
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)
#             return json_str
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }

# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)










#29-08-2025
#this code was put in server

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-maverick-17b-128e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"

#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         # Check if we have substantial document content
#         has_document_content = document_text and len(document_text.strip()) > 100
        
#         if has_document_content:
#             # Prioritize document content when available
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#             analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#             should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.
            

#             Document Content:
#             {document_text[:3000]}

#             Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#             For each sub-domain:
#             1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#             2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#             3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area based on document content",
#                 "description": "Detailed description derived from the document content (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name from document themes",
#                         "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 from document context",
#                             "Specific issue area 2 from document context",
#                             "Specific issue area 3 from document context",
#                             "Specific issue area 4 from document context",
#                             "Specific issue area 5 from document context",
#                             "Specific issue area 6 from document context",
#                             "Specific issue area 7 from document context",
#                             "Specific issue area 8 from document context"
#                         ]
#                     }}
#                 ]
#             }}

#             Focus on what the document actually discusses in detail rather than providing generic overviews.
#             """

#         else:
#             # Fall back to domain-based generation when no substantial document content
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#             create a comprehensive and detailed domain map for this specific focus area.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#             Generate detailed analysis with:
#             1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#             2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#             3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area title",
#                 "description": "Detailed description of the central domain (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name",
#                         "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 with clear focus",
#                             "Specific issue area 2 with clear focus",
#                             "Specific issue area 3 with clear focus",
#                             "Specific issue area 4 with clear focus",
#                             "Specific issue area 5 with clear focus",
#                             "Specific issue area 6 with clear focus",
#                             "Specific issue area 7 with clear focus",
#                             "Specific issue area 8 with clear focus"
#                         ]
#                     }}
#                 ]
#             }}

#             Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#             """
                
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
   
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings (but preserve paragraph structure)
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)
#             return json_str
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }

# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)

















##########################################################
#16-09-2025
#testing for language translation
#added def translate_to_lao(self, content), def translate_to_english(self, content)
#added one line code in def __init__(self, groq_api_key: str)
#updated the def generate_domain_map function for language detection and auto-translation

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document
# from translation_service import TranslationManager

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
#         self.translation_manager = TranslationManager(service_type="free")
    
#     # Add these simple methods to your class
#     def translate_to_lao(self, content):
#         """Translate content to Lao"""
#         return self.translation_manager.translate_to_lao(content)
    
#     def translate_to_english(self, content):
#         """Translate content to English"""
#         return self.translation_manager.translate_to_english(content)
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"

# # old without language detection and auto-translation

#     # def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#     #     """Generate domain map based on the selected domain and document content."""
        
#     #     # Check if we have substantial document content
#     #     has_document_content = document_text and len(document_text.strip()) > 100
        
#     #     if has_document_content:
#     #         # Prioritize document content when available
#     #         prompt = f"""
#     #         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#     #         analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#     #         should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#     #         Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.
            

#     #         Document Content:
#     #         {document_text[:3000]}

#     #         Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#     #         For each sub-domain:
#     #         1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#     #         2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#     #         3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#     #         Format your response as a JSON object with this structure:
#     #         {{
#     #             "central_domain": "Main focus area based on document content",
#     #             "description": "Detailed description derived from the document content (2-3 sentences)",
#     #             "sub_domains": [
#     #                 {{
#     #                     "name": "Sub-domain name from document themes",
#     #                     "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#     #                     "relevance": "High/Medium/Low",
#     #                     "issue_areas": [
#     #                         "Specific issue area 1 from document context",
#     #                         "Specific issue area 2 from document context",
#     #                         "Specific issue area 3 from document context",
#     #                         "Specific issue area 4 from document context",
#     #                         "Specific issue area 5 from document context",
#     #                         "Specific issue area 6 from document context",
#     #                         "Specific issue area 7 from document context",
#     #                         "Specific issue area 8 from document context"
#     #                     ]
#     #                 }}
#     #             ]
#     #         }}

#     #         Focus on what the document actually discusses in detail rather than providing generic overviews.
#     #         """

#     #     else:
#     #         # Fall back to domain-based generation when no substantial document content
#     #         prompt = f"""
#     #         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#     #         create a comprehensive and detailed domain map for this specific focus area.
#     #         Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#     #         Generate detailed analysis with:
#     #         1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#     #         2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#     #         3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#     #         Format your response as a JSON object with this structure:
#     #         {{
#     #             "central_domain": "Main focus area title",
#     #             "description": "Detailed description of the central domain (2-3 sentences)",
#     #             "sub_domains": [
#     #                 {{
#     #                     "name": "Sub-domain name",
#     #                     "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#     #                     "relevance": "High/Medium/Low",
#     #                     "issue_areas": [
#     #                         "Specific issue area 1 with clear focus",
#     #                         "Specific issue area 2 with clear focus",
#     #                         "Specific issue area 3 with clear focus",
#     #                         "Specific issue area 4 with clear focus",
#     #                         "Specific issue area 5 with clear focus",
#     #                         "Specific issue area 6 with clear focus",
#     #                         "Specific issue area 7 with clear focus",
#     #                         "Specific issue area 8 with clear focus"
#     #                     ]
#     #                 }}
#     #             ]
#     #         }}

#     #         Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#     #         """
                
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.7
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         return self._parse_json_response(response_text)
                
#     #     except Exception as e:
#     #         return {"error": f"Failed to generate domain map: {str(e)}"}

# # English PDF uploaded  English domain map generated  Manual translation available
# # Lao PDF uploaded  English analysis  Auto-translated to Lao  User sees Lao results immediately
# # Mixed language PDF  Detected as dominant language  Handled accordingly
# # new with language detection and auto-translation
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         # Add language detection
#         def detect_document_language(text: str) -> str:
#             """Detect if document is primarily in Lao or English"""
#             if not text:
#                 return "en"
            
#             import re
#             # Count Lao characters (Lao Unicode range: U+0E80U+0EFF)
#             lao_chars = len(re.findall(r'[\u0E80-\u0EFF]', text))
#             # Count English/Latin characters
#             latin_chars = len(re.findall(r'[A-Za-z]', text))
            
#             # If more than 20% of characters are Lao, consider it a Lao document
#             total_chars = lao_chars + latin_chars
#             if total_chars > 0 and (lao_chars / total_chars) > 0.2:
#                 return "lo"
#             return "en"
        
#         # Detect source document language
#         source_language = detect_document_language(document_text) if document_text else "en"
        
#         # Check if we have substantial document content
#         has_document_content = document_text and len(document_text.strip()) > 100
        
#         if has_document_content:
#             # Add language note to prompt if document is in Lao
#             language_note = ""
#             if source_language == "lo":
#                 language_note = "\n\nNote: The uploaded document contains Lao language content. Please analyze the content and provide the domain map in English format, as it will be handled appropriately for the user interface."
            
#             # Prioritize document content when available
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#             analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#             should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.{language_note}
            

#             Document Content:
#             {document_text[:3000]}

#             Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#             For each sub-domain:
#             1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#             2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#             3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area based on document content",
#                 "description": "Detailed description derived from the document content (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name from document themes",
#                         "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 from document context",
#                             "Specific issue area 2 from document context",
#                             "Specific issue area 3 from document context",
#                             "Specific issue area 4 from document context",
#                             "Specific issue area 5 from document context",
#                             "Specific issue area 6 from document context",
#                             "Specific issue area 7 from document context",
#                             "Specific issue area 8 from document context"
#                         ]
#                     }}
#                 ]
#             }}

#             Focus on what the document actually discusses in detail rather than providing generic overviews.
#             """

#         else:
#             # Fall back to domain-based generation when no substantial document content
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#             create a comprehensive and detailed domain map for this specific focus area.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#             Generate detailed analysis with:
#             1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#             2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#             3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area title",
#                 "description": "Detailed description of the central domain (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name",
#                         "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 with clear focus",
#                             "Specific issue area 2 with clear focus",
#                             "Specific issue area 3 with clear focus",
#                             "Specific issue area 4 with clear focus",
#                             "Specific issue area 5 with clear focus",
#                             "Specific issue area 6 with clear focus",
#                             "Specific issue area 7 with clear focus",
#                             "Specific issue area 8 with clear focus"
#                         ]
#                     }}
#                 ]
#             }}

#             Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#             """
                
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             result = self._parse_json_response(response_text)
            
#             # If source document was in Lao, auto-translate the result
#             if source_language == "lo" and not result.get("error"):
#                 try:
#                     translated_result = self.translate_to_lao(result)
#                     return {
#                         "domain_map": translated_result,
#                         "source_language": "lo",
#                         "auto_translated": True,
#                         "original_result": result  # Keep original for reference
#                     }
#                 except Exception as e:
#                     return {
#                         "domain_map": result,
#                         "source_language": "lo",
#                         "auto_translated": False,
#                         "translation_error": str(e),
#                         "note": "Auto-translation failed, showing English version. Use translate button to convert manually."
#                     }
            
#             # Return English result with metadata
#             return {
#                 "domain_map": result,
#                 "source_language": source_language,
#                 "auto_translated": False
#             }
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
   
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings (but preserve paragraph structure)
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)
#             return json_str
        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }

# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)











#23-09-2025
#added  run_wind_tunnel_analysis, _analyze_policy_against_scenario, _generate_cross_scenario_insights for phase 4 visioning


# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"

#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         # Check if we have substantial document content
#         has_document_content = document_text and len(document_text.strip()) > 100
        
#         if has_document_content:
#             # Prioritize document content when available
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#             analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#             should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.
            

#             Document Content:
#             {document_text[:3000]}

#             Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#             For each sub-domain:
#             1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#             2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#             3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area based on document content",
#                 "description": "Detailed description derived from the document content (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name from document themes",
#                         "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 from document context",
#                             "Specific issue area 2 from document context",
#                             "Specific issue area 3 from document context",
#                             "Specific issue area 4 from document context",
#                             "Specific issue area 5 from document context",
#                             "Specific issue area 6 from document context",
#                             "Specific issue area 7 from document context",
#                             "Specific issue area 8 from document context"
#                         ]
#                     }}
#                 ]
#             }}

#             Focus on what the document actually discusses in detail rather than providing generic overviews.
#             """

#         else:
#             # Fall back to domain-based generation when no substantial document content
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#             create a comprehensive and detailed domain map for this specific focus area.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#             Generate detailed analysis with:
#             1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#             2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#             3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area title",
#                 "description": "Detailed description of the central domain (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name",
#                         "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 with clear focus",
#                             "Specific issue area 2 with clear focus",
#                             "Specific issue area 3 with clear focus",
#                             "Specific issue area 4 with clear focus",
#                             "Specific issue area 5 with clear focus",
#                             "Specific issue area 6 with clear focus",
#                             "Specific issue area 7 with clear focus",
#                             "Specific issue area 8 with clear focus"
#                         ]
#                     }}
#                 ]
#             }}

#             Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#             """
                
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
   
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         # def clean_json_string(json_str):
#         #     """Clean up common JSON formatting issues"""
#         #     # Fix newlines immediately after opening quotes
#         #     json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#         #     # Fix multiple newlines within strings
#         #     json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#         #     # Fix single newlines within strings (but preserve paragraph structure)
#         #     json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#         #     # Remove markdown fences
#         #     json_str = re.sub(r"```(?:json)?", "", json_str)
#         #     json_str = json_str.replace("```", "")

#         #     # Remove trailing commas before } or ]
#         #     json_str = re.sub(r",\s*([\]}])", r"\1", json_str)

#         #     # Normalize multiple spaces/newlines
#         #     json_str = re.sub(r"\s+\n", " ", json_str)
#         #     json_str = re.sub(r"\n+", " ", json_str)

#         #     # return json_str
#         #     return json_str.strip()

#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#             # Remove markdown fences
#             json_str = re.sub(r"```(?:json)?", "", json_str)
#             json_str = json_str.replace("```", "")

#             # Fix missing commas between objects
#             json_str = re.sub(r'\}\s*\{', '}, {', json_str)

#             # Remove dangling/trailing commas
#             json_str = re.sub(r",\s*([\]}])", r"\1", json_str)
#             json_str = re.sub(r',\s*,+', ',', json_str)

#             # Escape unescaped quotes inside values
#             json_str = re.sub(
#                 r'(?<=:\s")([^"]*?)"(?=\s*[,}])',
#                 lambda m: m.group(1).replace('"', '\\"'),
#                 json_str
#             )

#             # Normalize multiple spaces/newlines
#             json_str = re.sub(r"\s+\n", " ", json_str)
#             json_str = re.sub(r"\n+", " ", json_str)

#             return json_str.strip()

        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }



#     # Add this method to your DRIForesightProcessor class in main.py

#     def run_wind_tunnel_analysis(self, domain: str, policy_text: str, phase3_scenarios: Dict, project_name: str = "") -> Dict[str, Any]:
#         """
#         Run Wind Tunnel analysis - stress test policy against all Phase 3 scenarios.
        
#         Args:
#             domain: The project domain
#             policy_text: Extracted text from uploaded policy documents
#             phase3_scenarios: Dict containing baseline and alternative scenarios from Phase 3
#             project_name: Optional project name for context
        
#         Returns:
#             Dict with analysis for each scenario and cross-scenario insights
#         """
        
#         # Extract scenarios from Phase 3 data
#         baseline_scenario = phase3_scenarios.get('baseline_scenario', {})
#         alternative_scenarios = phase3_scenarios.get('alternative_scenarios', {}).get('scenarios', [])
        
#         # Organize scenarios by archetype
#         scenarios_to_analyze = {
#             'baseline': {
#                 'title': baseline_scenario.get('scenario_title', 'Baseline Scenario'),
#                 'text': baseline_scenario.get('scenario_text', ''),
#                 'type': 'Baseline'
#             }
#         }
        
#         # Add alternative scenarios
#         for scenario in alternative_scenarios:
#             archetype = scenario.get('archetype', '').lower().replace(' ', '_')
#             if archetype == 'collapse':
#                 scenarios_to_analyze['collapse'] = scenario
#             elif archetype == 'new_equilibrium':
#                 scenarios_to_analyze['equilibrium'] = scenario
#             elif archetype == 'transformation':
#                 scenarios_to_analyze['transformation'] = scenario
        
#         # Analyze each scenario
#         scenario_analyses = {}
        
#         for scenario_key, scenario_data in scenarios_to_analyze.items():
#             analysis = self._analyze_policy_against_scenario(
#                 domain=domain,
#                 policy_text=policy_text,
#                 scenario_data=scenario_data,
#                 project_name=project_name
#             )
#             scenario_analyses[scenario_key] = analysis
        
#         # Generate cross-scenario insights
#         cross_scenario_analysis = self._generate_cross_scenario_insights(
#             domain=domain,
#             policy_text=policy_text,
#             scenario_analyses=scenario_analyses,
#             project_name=project_name
#         )
        
#         return {
#             "scenarios": scenario_analyses,
#             "cross_scenario": cross_scenario_analysis
#         }

#     def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
#         """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
#         scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
#         scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
#         scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
#         prompt = f"""
#         You are a senior policy analyst conducting a Wind Tunnel stress test analysis for "{project_name}" in the "{domain}" domain.

#         POLICY TO ANALYZE:
#         {policy_text[:4000]}  # Limit for token management

#         FUTURE SCENARIO TO TEST AGAINST:
#         Title: {scenario_title}
#         Type: {scenario_type}
#         Description: {scenario_text[:2000]}

#         WIND TUNNEL EVALUATION FRAMEWORK:
#         Conduct a comprehensive policy stress test using these four dimensions:

#         1. VIABILITY (Does the policy achieve its objectives?)
#         - Will the policy meet its stated goals in this future scenario?
#         - What aspects succeed or fail and why?
#         - Are underlying assumptions still valid?
#         - What unintended consequences emerge?

#         2. PROCESS (How does implementation change?)
#         - How do implementation timelines and milestones change?
#         - What new stakeholders or power dynamics emerge?
#         - What governance or decision-making challenges arise?
#         - How do approval and coordination processes adapt?

#         3. CAPABILITIES (Do we have what we need?)
#         - Are required human resources available and adequate?
#         - Are necessary technologies and infrastructure accessible?
#         - Is organizational culture helpful or problematic?
#         - What new competencies would be required?

#         4. ADAPTATIONS NEEDED (How should policy be modified?)
#         - What specific modifications would improve effectiveness?
#         - What contingencies or flexibility should be built in?
#         - What early warning indicators should be monitored?
#         - What alternative approaches might work better?

#         ANALYSIS REQUIREMENTS:
#         - Be specific and concrete rather than general
#         - Ground analysis in the scenario details
#         - Focus on actionable insights
#         - Consider both opportunities and risks
#         - Address the {scenario_type} scenario dynamics specifically

#         Format your response as JSON:
#         {{
#             "viability": "Detailed analysis of policy effectiveness in this scenario (4-6 sentences with specific examples)",
#             "process": "Analysis of implementation challenges and changes (4-6 sentences with specific examples)", 
#             "capabilities": "Assessment of resource and capability requirements (4-6 sentences with specific examples)",
#             "adaptations_needed": "Specific recommendations for policy modifications (4-6 sentences with concrete suggestions)"
#         }}

#         Focus on the unique challenges and opportunities this {scenario_type} scenario creates for the policy.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
#                         You excel at evaluating policy robustness across different future scenarios using the 
#                         VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework. You provide concrete, actionable insights 
#                         grounded in scenario specifics. Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "viability": f"Error analyzing viability: {str(e)}",
#                 "process": f"Error analyzing process: {str(e)}",
#                 "capabilities": f"Error analyzing capabilities: {str(e)}",
#                 "adaptations_needed": f"Error generating adaptations: {str(e)}"
#             }

#     def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
#         """Generate cross-scenario insights and policy robustness analysis."""
        
#         # Format scenario analyses for prompt
#         analyses_text = ""
#         for scenario_name, analysis in scenario_analyses.items():
#             analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
#             analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
#             analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
#             analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
#             analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
#             analyses_text += "---\n"
        
#         prompt = f"""
#         You are conducting cross-scenario analysis for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

#         POLICY ANALYZED:
#         {policy_text[:2000]}

#         INDIVIDUAL SCENARIO ANALYSES:
#         {analyses_text[:6000]}

#         CROSS-SCENARIO SYNTHESIS TASK:
#         Analyze the patterns across all scenario analyses to identify:

#         1. ROBUST ELEMENTS - Which policy aspects work well across ALL scenarios?
#         2. SCENARIO-SPECIFIC ELEMENTS - Which aspects only work in certain futures?
#         3. CRITICAL VULNERABILITIES - What are the biggest failure points and risks?
#         4. MONITORING INDICATORS - What early warning signs should be tracked?

#         SYNTHESIS REQUIREMENTS:
#         - Identify patterns and commonalities across scenarios
#         - Highlight the most critical insights for policy resilience
#         - Focus on actionable recommendations
#         - Be specific rather than generic

#         Format as JSON:
#         {{
#             "robust_elements": "Policy aspects that work across all scenarios (3-4 specific examples)",
#             "scenario_specific": "Elements that only work in certain scenarios (3-4 specific examples with scenario context)",
#             "critical_vulnerabilities": "Major failure points and risks (3-4 specific vulnerabilities with impact assessment)",
#             "monitoring_indicators": "Key early warning indicators to track (4-5 specific, measurable indicators)"
#         }}

#         Focus on the most strategically important insights for policy adaptation and resilience.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
#                         and policy resilience assessment. You excel at identifying patterns across different future 
#                         scenarios and translating them into actionable policy insights. Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field}"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
#                 "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
#                 "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
#                 "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
#             }




# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)










#23-09-2025
#working on visioning --phase 4
#updated the def _analyze_policy_against_scenario and  _generate_cross_scenario_insights for visioning for better result
#as of now final - deploy in server

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"

#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         # Check if we have substantial document content
#         has_document_content = document_text and len(document_text.strip()) > 100
        
#         if has_document_content:
#             # Prioritize document content when available
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#             analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#             should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.
            

#             Document Content:
#             {document_text[:3000]}

#             Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#             For each sub-domain:
#             1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#             2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#             3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area based on document content",
#                 "description": "Detailed description derived from the document content (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name from document themes",
#                         "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 from document context",
#                             "Specific issue area 2 from document context",
#                             "Specific issue area 3 from document context",
#                             "Specific issue area 4 from document context",
#                             "Specific issue area 5 from document context",
#                             "Specific issue area 6 from document context",
#                             "Specific issue area 7 from document context",
#                             "Specific issue area 8 from document context"
#                         ]
#                     }}
#                 ]
#             }}

#             Focus on what the document actually discusses in detail rather than providing generic overviews.
#             """

#         else:
#             # Fall back to domain-based generation when no substantial document content
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#             create a comprehensive and detailed domain map for this specific focus area.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#             Generate detailed analysis with:
#             1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#             2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#             3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area title",
#                 "description": "Detailed description of the central domain (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name",
#                         "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 with clear focus",
#                             "Specific issue area 2 with clear focus",
#                             "Specific issue area 3 with clear focus",
#                             "Specific issue area 4 with clear focus",
#                             "Specific issue area 5 with clear focus",
#                             "Specific issue area 6 with clear focus",
#                             "Specific issue area 7 with clear focus",
#                             "Specific issue area 8 with clear focus"
#                         ]
#                     }}
#                 ]
#             }}

#             Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#             """
                
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
   
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         # def clean_json_string(json_str):
#         #     """Clean up common JSON formatting issues"""
#         #     # Fix newlines immediately after opening quotes
#         #     json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#         #     # Fix multiple newlines within strings
#         #     json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#         #     # Fix single newlines within strings (but preserve paragraph structure)
#         #     json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#         #     # Remove markdown fences
#         #     json_str = re.sub(r"```(?:json)?", "", json_str)
#         #     json_str = json_str.replace("```", "")

#         #     # Remove trailing commas before } or ]
#         #     json_str = re.sub(r",\s*([\]}])", r"\1", json_str)

#         #     # Normalize multiple spaces/newlines
#         #     json_str = re.sub(r"\s+\n", " ", json_str)
#         #     json_str = re.sub(r"\n+", " ", json_str)

#         #     # return json_str
#         #     return json_str.strip()

#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#             # Remove markdown fences
#             json_str = re.sub(r"```(?:json)?", "", json_str)
#             json_str = json_str.replace("```", "")

#             # Fix missing commas between objects
#             json_str = re.sub(r'\}\s*\{', '}, {', json_str)

#             # Remove dangling/trailing commas
#             json_str = re.sub(r",\s*([\]}])", r"\1", json_str)
#             json_str = re.sub(r',\s*,+', ',', json_str)

#             # Escape unescaped quotes inside values
#             json_str = re.sub(
#                 r'(?<=:\s")([^"]*?)"(?=\s*[,}])',
#                 lambda m: m.group(1).replace('"', '\\"'),
#                 json_str
#             )

#             # Normalize multiple spaces/newlines
#             json_str = re.sub(r"\s+\n", " ", json_str)
#             json_str = re.sub(r"\n+", " ", json_str)

#             return json_str.strip()

        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }



#     # Add this method to your DRIForesightProcessor class in main.py

#     def run_wind_tunnel_analysis(self, domain: str, policy_text: str, phase3_scenarios: Dict, project_name: str = "") -> Dict[str, Any]:
#         """
#         Run Wind Tunnel analysis - stress test policy against all Phase 3 scenarios.
        
#         Args:
#             domain: The project domain
#             policy_text: Extracted text from uploaded policy documents
#             phase3_scenarios: Dict containing baseline and alternative scenarios from Phase 3
#             project_name: Optional project name for context
        
#         Returns:
#             Dict with analysis for each scenario and cross-scenario insights
#         """
        
#         # Extract scenarios from Phase 3 data
#         baseline_scenario = phase3_scenarios.get('baseline_scenario', {})
#         alternative_scenarios = phase3_scenarios.get('alternative_scenarios', {}).get('scenarios', [])
        
#         # Organize scenarios by archetype
#         scenarios_to_analyze = {
#             'baseline': {
#                 'title': baseline_scenario.get('scenario_title', 'Baseline Scenario'),
#                 'text': baseline_scenario.get('scenario_text', ''),
#                 'type': 'Baseline'
#             }
#         }
        
#         # Add alternative scenarios
#         for scenario in alternative_scenarios:
#             archetype = scenario.get('archetype', '').lower().replace(' ', '_')
#             if archetype == 'collapse':
#                 scenarios_to_analyze['collapse'] = scenario
#             elif archetype == 'new_equilibrium':
#                 scenarios_to_analyze['equilibrium'] = scenario
#             elif archetype == 'transformation':
#                 scenarios_to_analyze['transformation'] = scenario
        
#         # Analyze each scenario
#         scenario_analyses = {}
        
#         for scenario_key, scenario_data in scenarios_to_analyze.items():
#             analysis = self._analyze_policy_against_scenario(
#                 domain=domain,
#                 policy_text=policy_text,
#                 scenario_data=scenario_data,
#                 project_name=project_name
#             )
#             scenario_analyses[scenario_key] = analysis
        
#         # Generate cross-scenario insights
#         cross_scenario_analysis = self._generate_cross_scenario_insights(
#             domain=domain,
#             policy_text=policy_text,
#             scenario_analyses=scenario_analyses,
#             project_name=project_name
#         )
        
#         return {
#             "scenarios": scenario_analyses,
#             "cross_scenario": cross_scenario_analysis
#         }

#     # def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
#     #     """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
#     #     scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
#     #     scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
#     #     scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
#     #     prompt = f"""
#     #     You are a senior policy analyst conducting a Wind Tunnel stress test analysis for "{project_name}" in the "{domain}" domain.

#     #     POLICY TO ANALYZE:
#     #     {policy_text[:4000]}  # Limit for token management

#     #     FUTURE SCENARIO TO TEST AGAINST:
#     #     Title: {scenario_title}
#     #     Type: {scenario_type}
#     #     Description: {scenario_text[:2000]}

#     #     WIND TUNNEL EVALUATION FRAMEWORK:
#     #     Conduct a comprehensive policy stress test using these four dimensions:

#     #     1. VIABILITY (Does the policy achieve its objectives?)
#     #     - Will the policy meet its stated goals in this future scenario?
#     #     - What aspects succeed or fail and why?
#     #     - Are underlying assumptions still valid?
#     #     - What unintended consequences emerge?

#     #     2. PROCESS (How does implementation change?)
#     #     - How do implementation timelines and milestones change?
#     #     - What new stakeholders or power dynamics emerge?
#     #     - What governance or decision-making challenges arise?
#     #     - How do approval and coordination processes adapt?

#     #     3. CAPABILITIES (Do we have what we need?)
#     #     - Are required human resources available and adequate?
#     #     - Are necessary technologies and infrastructure accessible?
#     #     - Is organizational culture helpful or problematic?
#     #     - What new competencies would be required?

#     #     4. ADAPTATIONS NEEDED (How should policy be modified?)
#     #     - What specific modifications would improve effectiveness?
#     #     - What contingencies or flexibility should be built in?
#     #     - What early warning indicators should be monitored?
#     #     - What alternative approaches might work better?

#     #     ANALYSIS REQUIREMENTS:
#     #     - Be specific and concrete rather than general
#     #     - Ground analysis in the scenario details
#     #     - Focus on actionable insights
#     #     - Consider both opportunities and risks
#     #     - Address the {scenario_type} scenario dynamics specifically

#     #     Format your response as JSON:
#     #     {{
#     #         "viability": "Detailed analysis of policy effectiveness in this scenario (4-6 sentences with specific examples)",
#     #         "process": "Analysis of implementation challenges and changes (4-6 sentences with specific examples)", 
#     #         "capabilities": "Assessment of resource and capability requirements (4-6 sentences with specific examples)",
#     #         "adaptations_needed": "Specific recommendations for policy modifications (4-6 sentences with concrete suggestions)"
#     #     }}

#     #     Focus on the unique challenges and opportunities this {scenario_type} scenario creates for the policy.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system",
#     #                     "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
#     #                     You excel at evaluating policy robustness across different future scenarios using the 
#     #                     VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework. You provide concrete, actionable insights 
#     #                     grounded in scenario specifics. Always respond with valid JSON format."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2000,
#     #             temperature=0.6
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         parsed_result = self._parse_json_response(response_text)
            
#     #         # Validate required fields exist
#     #         required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
#     #         for field in required_fields:
#     #             if field not in parsed_result:
#     #                 parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         return {
#     #             "viability": f"Error analyzing viability: {str(e)}",
#     #             "process": f"Error analyzing process: {str(e)}",
#     #             "capabilities": f"Error analyzing capabilities: {str(e)}",
#     #             "adaptations_needed": f"Error generating adaptations: {str(e)}"
#     #         }

#     # def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
#     #     """Generate cross-scenario insights and policy robustness analysis."""
        
#     #     # Format scenario analyses for prompt
#     #     analyses_text = ""
#     #     for scenario_name, analysis in scenario_analyses.items():
#     #         analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
#     #         analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
#     #         analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
#     #         analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
#     #         analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
#     #         analyses_text += "---\n"
        
#     #     prompt = f"""
#     #     You are conducting cross-scenario analysis for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

#     #     POLICY ANALYZED:
#     #     {policy_text[:2000]}

#     #     INDIVIDUAL SCENARIO ANALYSES:
#     #     {analyses_text[:6000]}

#     #     CROSS-SCENARIO SYNTHESIS TASK:
#     #     Analyze the patterns across all scenario analyses to identify:

#     #     1. ROBUST ELEMENTS - Which policy aspects work well across ALL scenarios?
#     #     2. SCENARIO-SPECIFIC ELEMENTS - Which aspects only work in certain futures?
#     #     3. CRITICAL VULNERABILITIES - What are the biggest failure points and risks?
#     #     4. MONITORING INDICATORS - What early warning signs should be tracked?

#     #     SYNTHESIS REQUIREMENTS:
#     #     - Identify patterns and commonalities across scenarios
#     #     - Highlight the most critical insights for policy resilience
#     #     - Focus on actionable recommendations
#     #     - Be specific rather than generic

#     #     Format as JSON:
#     #     {{
#     #         "robust_elements": "Policy aspects that work across all scenarios (3-4 specific examples)",
#     #         "scenario_specific": "Elements that only work in certain scenarios (3-4 specific examples with scenario context)",
#     #         "critical_vulnerabilities": "Major failure points and risks (3-4 specific vulnerabilities with impact assessment)",
#     #         "monitoring_indicators": "Key early warning indicators to track (4-5 specific, measurable indicators)"
#     #     }}

#     #     Focus on the most strategically important insights for policy adaptation and resilience.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system",
#     #                     "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
#     #                     and policy resilience assessment. You excel at identifying patterns across different future 
#     #                     scenarios and translating them into actionable policy insights. Always respond with valid JSON format."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.6
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         parsed_result = self._parse_json_response(response_text)
            
#     #         # Validate required fields exist
#     #         required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
#     #         for field in required_fields:
#     #             if field not in parsed_result:
#     #                 parsed_result[field] = f"Analysis pending for {field}"
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         return {
#     #             "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
#     #             "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
#     #             "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
#     #             "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
#     #         }

#     def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
#         """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
#         scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
#         scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
#         scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
#         prompt = f"""
#         You are performing a **Wind Tunnel stress test** of the policy document for "{project_name}" in the "{domain}" domain.
        
#         POLICY TO ANALYZE:
#         {policy_text[:4000]}

#         FUTURE SCENARIO TO TEST AGAINST:
#         Title: {scenario_title}
#         Type: {scenario_type}
#         Description: {scenario_text[:2000]}

#         WIND TUNNEL EVALUATION FRAMEWORK:
#         Systematically evaluate this policy against the given scenario using four dimensions:

#         ### **1. VIABILITY** (Does the policy achieve its objectives?)
#         - Does the policy achieve its stated objectives in this future scenario?
#         - What aspects of the policy succeed or fail and why?
#         - Are the underlying assumptions still valid?
#         - What unintended consequences emerge?

#         ### **2. PROCESS** (How does implementation change?)
#         - How does the implementation process change in this scenario?
#         - What new stakeholders or power dynamics emerge?
#         - Are the planned timelines and milestones still realistic?
#         - What governance or decision-making challenges arise?

#         ### **3. CAPABILITIES** (Do we have what we need?)
#         - Do we have the necessary human resources in this future?
#         - Are required technologies and infrastructure available?
#         - Is organizational culture an asset or liability?
#         - What new competencies would be needed?

#         ### **4. ADAPTATIONS NEEDED** (How should policy be modified?)
#         - How should the policy be modified to remain effective?
#         - What contingencies or flexibility should be built in?
#         - What early warning indicators should be monitored?
#         - What alternative approaches might work better?

#         ANALYSIS REQUIREMENTS:
#         - Be specific and concrete with examples rather than general statements
#         - Ground analysis in the scenario details and policy specifics
#         - Focus on actionable insights for policy resilience
#         - Consider both opportunities and risks in the {scenario_type} scenario
#         - Each dimension should be 80-120 words of substantive analysis

#         Format your response as JSON:
#         {{
#             "viability": "Comprehensive analysis of policy effectiveness in this {scenario_type} scenario. Address objective achievement, success/failure factors, assumption validity, and unintended consequences with specific examples from the scenario context.",
#             "process": "Detailed analysis of implementation changes in this {scenario_type} scenario. Cover process modifications, stakeholder dynamics, timeline realism, and governance challenges with concrete examples.", 
#             "capabilities": "Thorough assessment of resource and capability requirements in this {scenario_type} scenario. Evaluate human resources, technology/infrastructure, organizational culture, and new competencies with specific details.",
#             "adaptations_needed": "Specific recommendations for policy modifications in this {scenario_type} scenario. Include effectiveness improvements, contingencies, monitoring indicators, and alternative approaches with actionable suggestions."
#         }}

#         Focus on how the unique characteristics of this {scenario_type} scenario create specific challenges and opportunities for the policy.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
#                         You excel at evaluating policy robustness across different future scenarios using concrete, specific analysis 
#                         grounded in scenario details. You provide actionable insights with examples rather than generic assessments. 
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for more detailed responses
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "viability": f"Error analyzing viability: {str(e)}",
#                 "process": f"Error analyzing process: {str(e)}",
#                 "capabilities": f"Error analyzing capabilities: {str(e)}",
#                 "adaptations_needed": f"Error generating adaptations: {str(e)}"
#             }

#     def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
#         """Generate cross-scenario insights and policy robustness analysis."""
        
#         # Format scenario analyses for prompt
#         analyses_text = ""
#         for scenario_name, analysis in scenario_analyses.items():
#             analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
#             analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
#             analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
#             analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
#             analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
#             analyses_text += "---\n"
        
#         prompt = f"""
#         You are conducting **cross-scenario synthesis** for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

#         POLICY ANALYZED:
#         {policy_text[:2000]}

#         INDIVIDUAL SCENARIO ANALYSES:
#         {analyses_text[:6000]}

#         CROSS-SCENARIO SYNTHESIS TASK:
#         Compare across ALL scenarios together (not individually) to extract strategic insights:

#         ### **Task 1: ROBUST ELEMENTS**
#         Identify which elements of the policy are robust and work well across ALL scenarios.
#         Focus on specific policy components, mechanisms, or approaches that remain effective regardless of future conditions.

#         ### **Task 2: SCENARIO-SPECIFIC ELEMENTS** 
#         Note which aspects of the policy only work in specific futures or require different approaches in different scenarios.
#         Be specific about which elements work in which scenarios and why.

#         ### **Task 3: CRITICAL VULNERABILITIES**
#         Highlight the biggest failure points, risks, and vulnerabilities that emerge across scenarios.
#         Focus on systemic weaknesses that could undermine policy effectiveness.

#         ### **Task 4: MONITORING INDICATORS**
#         Suggest specific, measurable early warning indicators that should be tracked to anticipate which scenario is emerging.
#         Focus on concrete metrics that would signal the need for policy adaptation.

#         SYNTHESIS REQUIREMENTS:
#         - Compare patterns and commonalities across all scenario analyses
#         - Be concrete and specific with examples rather than generic statements  
#         - Focus on actionable recommendations for policy resilience
#         - Each response should be 80-120 words of substantive analysis
#         - Ground insights in the specific policy and scenario details provided

#         Format as JSON:
#         {{
#             "robust_elements": "Specific policy aspects and mechanisms that demonstrate effectiveness across all scenarios, with concrete examples of why these elements remain viable regardless of future conditions.",
#             "scenario_specific": "Detailed identification of policy elements that only work in certain scenarios, specifying which elements work in which futures and the underlying reasons for scenario dependency.",
#             "critical_vulnerabilities": "Major systemic failure points and risks identified across scenarios, with specific assessment of how these vulnerabilities could undermine policy effectiveness and their potential impact.",
#             "monitoring_indicators": "Concrete, measurable early warning indicators and metrics that should be tracked to anticipate scenario emergence and signal the need for policy adaptation, with specific measurement approaches."
#         }}

#         Focus on the most strategically important cross-scenario insights for policy adaptation and long-term resilience.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
#                         and policy resilience assessment. You excel at identifying concrete patterns across different future 
#                         scenarios and translating them into specific, actionable policy insights with examples and evidence. 
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,  # Increased for more detailed responses
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field}"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
#                 "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
#                 "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
#                 "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
#             }




# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)

















#24-09-2025
#added old translation process in this code it was working for the domain map

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document
# from translation_service import TranslationManager

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
#         # self.translation_manager = TranslationManager(service_type="free")
#         self.translation_manager = TranslationManager(
#             service_type="google_cloud", 
#             credentials_path="C:\\viswajith\\Projects\\laos dummy 1\\KEY.json"
#         )
            
#     # Add these simple methods to your class
#     def translate_to_lao(self, content):
#         """Translate content to Lao"""
#         return self.translation_manager.translate_to_lao(content)
    
#     def translate_to_english(self, content):
#         """Translate content to English"""
#         return self.translation_manager.translate_to_english(content)
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"

# # # old without language detection and auto-translation
#     # def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#     #     """Generate domain map based on the selected domain and document content."""
        
#     #     # Check if we have substantial document content
#     #     has_document_content = document_text and len(document_text.strip()) > 100
        
#     #     if has_document_content:
#     #         # Prioritize document content when available
#     #         prompt = f"""
#     #         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#     #         analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#     #         should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#     #         Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.
            

#     #         Document Content:
#     #         {document_text[:3000]}

#     #         Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#     #         For each sub-domain:
#     #         1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#     #         2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#     #         3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#     #         Format your response as a JSON object with this structure:
#     #         {{
#     #             "central_domain": "Main focus area based on document content",
#     #             "description": "Detailed description derived from the document content (2-3 sentences)",
#     #             "sub_domains": [
#     #                 {{
#     #                     "name": "Sub-domain name from document themes",
#     #                     "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#     #                     "relevance": "High/Medium/Low",
#     #                     "issue_areas": [
#     #                         "Specific issue area 1 from document context",
#     #                         "Specific issue area 2 from document context",
#     #                         "Specific issue area 3 from document context",
#     #                         "Specific issue area 4 from document context",
#     #                         "Specific issue area 5 from document context",
#     #                         "Specific issue area 6 from document context",
#     #                         "Specific issue area 7 from document context",
#     #                         "Specific issue area 8 from document context"
#     #                     ]
#     #                 }}
#     #             ]
#     #         }}

#     #         Focus on what the document actually discusses in detail rather than providing generic overviews.
#     #         """

#     #     else:
#     #         # Fall back to domain-based generation when no substantial document content
#     #         prompt = f"""
#     #         You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#     #         create a comprehensive and detailed domain map for this specific focus area.
#     #         Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#     #         Generate detailed analysis with:
#     #         1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#     #         2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#     #         3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#     #         Format your response as a JSON object with this structure:
#     #         {{
#     #             "central_domain": "Main focus area title",
#     #             "description": "Detailed description of the central domain (2-3 sentences)",
#     #             "sub_domains": [
#     #                 {{
#     #                     "name": "Sub-domain name",
#     #                     "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#     #                     "relevance": "High/Medium/Low",
#     #                     "issue_areas": [
#     #                         "Specific issue area 1 with clear focus",
#     #                         "Specific issue area 2 with clear focus",
#     #                         "Specific issue area 3 with clear focus",
#     #                         "Specific issue area 4 with clear focus",
#     #                         "Specific issue area 5 with clear focus",
#     #                         "Specific issue area 6 with clear focus",
#     #                         "Specific issue area 7 with clear focus",
#     #                         "Specific issue area 8 with clear focus"
#     #                     ]
#     #                 }}
#     #             ]
#     #         }}

#     #         Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#     #         """
                
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system", 
#     #                     "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.7
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         return self._parse_json_response(response_text)
                
#     #     except Exception as e:
#     #         return {"error": f"Failed to generate domain map: {str(e)}"}
   

# # English PDF uploaded  English domain map generated  Manual translation available
# # Lao PDF uploaded  English analysis  Auto-translated to Lao  User sees Lao results immediately
# # Mixed language PDF  Detected as dominant language  Handled accordingly
# # new with language detection and auto-translation
#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         # Add language detection
#         def detect_document_language(text: str) -> str:
#             """Detect if document is primarily in Lao or English"""
#             if not text:
#                 return "en"
            
#             import re
#             # Count Lao characters (Lao Unicode range: U+0E80U+0EFF)
#             lao_chars = len(re.findall(r'[\u0E80-\u0EFF]', text))
#             # Count English/Latin characters
#             latin_chars = len(re.findall(r'[A-Za-z]', text))
            
#             # If more than 20% of characters are Lao, consider it a Lao document
#             total_chars = lao_chars + latin_chars
#             if total_chars > 0 and (lao_chars / total_chars) > 0.2:
#                 return "lo"
#             return "en"
        
#         # Detect source document language
#         source_language = detect_document_language(document_text) if document_text else "en"
        
#         # Check if we have substantial document content
#         has_document_content = document_text and len(document_text.strip()) > 100
        
#         if has_document_content:
#             # Add language note to prompt if document is in Lao
#             language_note = ""
#             if source_language == "lo":
#                 language_note = "\n\nNote: The uploaded document contains Lao language content. Please analyze the content and provide the domain map in English format, as it will be handled appropriately for the user interface."
            
#             # Prioritize document content when available
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
#             analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#             should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.{language_note}
            

#             Document Content:
#             {document_text[:3000]}

#             Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

#             For each sub-domain:
#             1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
#             2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#             3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area based on document content",
#                 "description": "Detailed description derived from the document content (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name from document themes",
#                         "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 from document context",
#                             "Specific issue area 2 from document context",
#                             "Specific issue area 3 from document context",
#                             "Specific issue area 4 from document context",
#                             "Specific issue area 5 from document context",
#                             "Specific issue area 6 from document context",
#                             "Specific issue area 7 from document context",
#                             "Specific issue area 8 from document context"
#                         ]
#                     }}
#                 ]
#             }}

#             Focus on what the document actually discusses in detail rather than providing generic overviews.
#             """

#         else:
#             # Fall back to domain-based generation when no substantial document content
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#             create a comprehensive and detailed domain map for this specific focus area.
#             Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

#             Generate detailed analysis with:
#             1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
#             2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#             3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area title",
#                 "description": "Detailed description of the central domain (2-3 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name",
#                         "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 with clear focus",
#                             "Specific issue area 2 with clear focus",
#                             "Specific issue area 3 with clear focus",
#                             "Specific issue area 4 with clear focus",
#                             "Specific issue area 5 with clear focus",
#                             "Specific issue area 6 with clear focus",
#                             "Specific issue area 7 with clear focus",
#                             "Specific issue area 8 with clear focus"
#                         ]
#                     }}
#                 ]
#             }}

#             Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#             """
                
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             result = self._parse_json_response(response_text)
            
#             # If source document was in Lao, auto-translate the result
#             if source_language == "lo" and not result.get("error"):
#                 try:
#                     translated_result = self.translate_to_lao(result)
#                     return {
#                         "domain_map": translated_result,
#                         "source_language": "lo",
#                         "auto_translated": True,
#                         "original_result": result  # Keep original for reference
#                     }
#                 except Exception as e:
#                     return {
#                         "domain_map": result,
#                         "source_language": "lo",
#                         "auto_translated": False,
#                         "translation_error": str(e),
#                         "note": "Auto-translation failed, showing English version. Use translate button to convert manually."
#                     }
            
#             # Return English result with metadata
#             return {
#                 "domain_map": result,
#                 "source_language": source_language,
#                 "auto_translated": False
#             }
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
   

#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 4-6 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         # def clean_json_string(json_str):
#         #     """Clean up common JSON formatting issues"""
#         #     # Fix newlines immediately after opening quotes
#         #     json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#         #     # Fix multiple newlines within strings
#         #     json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#         #     # Fix single newlines within strings (but preserve paragraph structure)
#         #     json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#         #     # Remove markdown fences
#         #     json_str = re.sub(r"```(?:json)?", "", json_str)
#         #     json_str = json_str.replace("```", "")

#         #     # Remove trailing commas before } or ]
#         #     json_str = re.sub(r",\s*([\]}])", r"\1", json_str)

#         #     # Normalize multiple spaces/newlines
#         #     json_str = re.sub(r"\s+\n", " ", json_str)
#         #     json_str = re.sub(r"\n+", " ", json_str)

#         #     # return json_str
#         #     return json_str.strip()

#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#             # Remove markdown fences
#             json_str = re.sub(r"```(?:json)?", "", json_str)
#             json_str = json_str.replace("```", "")

#             # Fix missing commas between objects
#             json_str = re.sub(r'\}\s*\{', '}, {', json_str)

#             # Remove dangling/trailing commas
#             json_str = re.sub(r",\s*([\]}])", r"\1", json_str)
#             json_str = re.sub(r',\s*,+', ',', json_str)

#             # Escape unescaped quotes inside values
#             json_str = re.sub(
#                 r'(?<=:\s")([^"]*?)"(?=\s*[,}])',
#                 lambda m: m.group(1).replace('"', '\\"'),
#                 json_str
#             )

#             # Normalize multiple spaces/newlines
#             json_str = re.sub(r"\s+\n", " ", json_str)
#             json_str = re.sub(r"\n+", " ", json_str)

#             return json_str.strip()

        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 4-6 DRIVERS that will dominate the baseline scenario
#             - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (3-4 paragraphs, 400-450 words total):**
        
#         **Paragraph 1 - Present Momentum (100-150 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (100-140 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (100-120 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 3 outcomes (one per archetype)
#         - Outcomes should be 2-3 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
#         4. Final system state shaped by {selected_focus} (2030) - 75-100 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 300-400 words
#         - Each paragraph should be 75-100 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }



#     # Add this method to your DRIForesightProcessor class in main.py

#     def run_wind_tunnel_analysis(self, domain: str, policy_text: str, phase3_scenarios: Dict, project_name: str = "") -> Dict[str, Any]:
#         """
#         Run Wind Tunnel analysis - stress test policy against all Phase 3 scenarios.
        
#         Args:
#             domain: The project domain
#             policy_text: Extracted text from uploaded policy documents
#             phase3_scenarios: Dict containing baseline and alternative scenarios from Phase 3
#             project_name: Optional project name for context
        
#         Returns:
#             Dict with analysis for each scenario and cross-scenario insights
#         """
        
#         # Extract scenarios from Phase 3 data
#         baseline_scenario = phase3_scenarios.get('baseline_scenario', {})
#         alternative_scenarios = phase3_scenarios.get('alternative_scenarios', {}).get('scenarios', [])
        
#         # Organize scenarios by archetype
#         scenarios_to_analyze = {
#             'baseline': {
#                 'title': baseline_scenario.get('scenario_title', 'Baseline Scenario'),
#                 'text': baseline_scenario.get('scenario_text', ''),
#                 'type': 'Baseline'
#             }
#         }
        
#         # Add alternative scenarios
#         for scenario in alternative_scenarios:
#             archetype = scenario.get('archetype', '').lower().replace(' ', '_')
#             if archetype == 'collapse':
#                 scenarios_to_analyze['collapse'] = scenario
#             elif archetype == 'new_equilibrium':
#                 scenarios_to_analyze['equilibrium'] = scenario
#             elif archetype == 'transformation':
#                 scenarios_to_analyze['transformation'] = scenario
        
#         # Analyze each scenario
#         scenario_analyses = {}
        
#         for scenario_key, scenario_data in scenarios_to_analyze.items():
#             analysis = self._analyze_policy_against_scenario(
#                 domain=domain,
#                 policy_text=policy_text,
#                 scenario_data=scenario_data,
#                 project_name=project_name
#             )
#             scenario_analyses[scenario_key] = analysis
        
#         # Generate cross-scenario insights
#         cross_scenario_analysis = self._generate_cross_scenario_insights(
#             domain=domain,
#             policy_text=policy_text,
#             scenario_analyses=scenario_analyses,
#             project_name=project_name
#         )
        
#         return {
#             "scenarios": scenario_analyses,
#             "cross_scenario": cross_scenario_analysis
#         }

#     # def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
#     #     """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
#     #     scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
#     #     scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
#     #     scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
#     #     prompt = f"""
#     #     You are a senior policy analyst conducting a Wind Tunnel stress test analysis for "{project_name}" in the "{domain}" domain.

#     #     POLICY TO ANALYZE:
#     #     {policy_text[:4000]}  # Limit for token management

#     #     FUTURE SCENARIO TO TEST AGAINST:
#     #     Title: {scenario_title}
#     #     Type: {scenario_type}
#     #     Description: {scenario_text[:2000]}

#     #     WIND TUNNEL EVALUATION FRAMEWORK:
#     #     Conduct a comprehensive policy stress test using these four dimensions:

#     #     1. VIABILITY (Does the policy achieve its objectives?)
#     #     - Will the policy meet its stated goals in this future scenario?
#     #     - What aspects succeed or fail and why?
#     #     - Are underlying assumptions still valid?
#     #     - What unintended consequences emerge?

#     #     2. PROCESS (How does implementation change?)
#     #     - How do implementation timelines and milestones change?
#     #     - What new stakeholders or power dynamics emerge?
#     #     - What governance or decision-making challenges arise?
#     #     - How do approval and coordination processes adapt?

#     #     3. CAPABILITIES (Do we have what we need?)
#     #     - Are required human resources available and adequate?
#     #     - Are necessary technologies and infrastructure accessible?
#     #     - Is organizational culture helpful or problematic?
#     #     - What new competencies would be required?

#     #     4. ADAPTATIONS NEEDED (How should policy be modified?)
#     #     - What specific modifications would improve effectiveness?
#     #     - What contingencies or flexibility should be built in?
#     #     - What early warning indicators should be monitored?
#     #     - What alternative approaches might work better?

#     #     ANALYSIS REQUIREMENTS:
#     #     - Be specific and concrete rather than general
#     #     - Ground analysis in the scenario details
#     #     - Focus on actionable insights
#     #     - Consider both opportunities and risks
#     #     - Address the {scenario_type} scenario dynamics specifically

#     #     Format your response as JSON:
#     #     {{
#     #         "viability": "Detailed analysis of policy effectiveness in this scenario (4-6 sentences with specific examples)",
#     #         "process": "Analysis of implementation challenges and changes (4-6 sentences with specific examples)", 
#     #         "capabilities": "Assessment of resource and capability requirements (4-6 sentences with specific examples)",
#     #         "adaptations_needed": "Specific recommendations for policy modifications (4-6 sentences with concrete suggestions)"
#     #     }}

#     #     Focus on the unique challenges and opportunities this {scenario_type} scenario creates for the policy.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system",
#     #                     "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
#     #                     You excel at evaluating policy robustness across different future scenarios using the 
#     #                     VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework. You provide concrete, actionable insights 
#     #                     grounded in scenario specifics. Always respond with valid JSON format."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2000,
#     #             temperature=0.6
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         parsed_result = self._parse_json_response(response_text)
            
#     #         # Validate required fields exist
#     #         required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
#     #         for field in required_fields:
#     #             if field not in parsed_result:
#     #                 parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         return {
#     #             "viability": f"Error analyzing viability: {str(e)}",
#     #             "process": f"Error analyzing process: {str(e)}",
#     #             "capabilities": f"Error analyzing capabilities: {str(e)}",
#     #             "adaptations_needed": f"Error generating adaptations: {str(e)}"
#     #         }

#     # def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
#     #     """Generate cross-scenario insights and policy robustness analysis."""
        
#     #     # Format scenario analyses for prompt
#     #     analyses_text = ""
#     #     for scenario_name, analysis in scenario_analyses.items():
#     #         analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
#     #         analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
#     #         analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
#     #         analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
#     #         analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
#     #         analyses_text += "---\n"
        
#     #     prompt = f"""
#     #     You are conducting cross-scenario analysis for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

#     #     POLICY ANALYZED:
#     #     {policy_text[:2000]}

#     #     INDIVIDUAL SCENARIO ANALYSES:
#     #     {analyses_text[:6000]}

#     #     CROSS-SCENARIO SYNTHESIS TASK:
#     #     Analyze the patterns across all scenario analyses to identify:

#     #     1. ROBUST ELEMENTS - Which policy aspects work well across ALL scenarios?
#     #     2. SCENARIO-SPECIFIC ELEMENTS - Which aspects only work in certain futures?
#     #     3. CRITICAL VULNERABILITIES - What are the biggest failure points and risks?
#     #     4. MONITORING INDICATORS - What early warning signs should be tracked?

#     #     SYNTHESIS REQUIREMENTS:
#     #     - Identify patterns and commonalities across scenarios
#     #     - Highlight the most critical insights for policy resilience
#     #     - Focus on actionable recommendations
#     #     - Be specific rather than generic

#     #     Format as JSON:
#     #     {{
#     #         "robust_elements": "Policy aspects that work across all scenarios (3-4 specific examples)",
#     #         "scenario_specific": "Elements that only work in certain scenarios (3-4 specific examples with scenario context)",
#     #         "critical_vulnerabilities": "Major failure points and risks (3-4 specific vulnerabilities with impact assessment)",
#     #         "monitoring_indicators": "Key early warning indicators to track (4-5 specific, measurable indicators)"
#     #     }}

#     #     Focus on the most strategically important insights for policy adaptation and resilience.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system",
#     #                     "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
#     #                     and policy resilience assessment. You excel at identifying patterns across different future 
#     #                     scenarios and translating them into actionable policy insights. Always respond with valid JSON format."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.6
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         parsed_result = self._parse_json_response(response_text)
            
#     #         # Validate required fields exist
#     #         required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
#     #         for field in required_fields:
#     #             if field not in parsed_result:
#     #                 parsed_result[field] = f"Analysis pending for {field}"
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         return {
#     #             "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
#     #             "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
#     #             "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
#     #             "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
#     #         }

#     def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
#         """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
#         scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
#         scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
#         scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
#         prompt = f"""
#         You are performing a **Wind Tunnel stress test** of the policy document for "{project_name}" in the "{domain}" domain.
        
#         POLICY TO ANALYZE:
#         {policy_text[:4000]}

#         FUTURE SCENARIO TO TEST AGAINST:
#         Title: {scenario_title}
#         Type: {scenario_type}
#         Description: {scenario_text[:2000]}

#         WIND TUNNEL EVALUATION FRAMEWORK:
#         Systematically evaluate this policy against the given scenario using four dimensions:

#         ### **1. VIABILITY** (Does the policy achieve its objectives?)
#         - Does the policy achieve its stated objectives in this future scenario?
#         - What aspects of the policy succeed or fail and why?
#         - Are the underlying assumptions still valid?
#         - What unintended consequences emerge?

#         ### **2. PROCESS** (How does implementation change?)
#         - How does the implementation process change in this scenario?
#         - What new stakeholders or power dynamics emerge?
#         - Are the planned timelines and milestones still realistic?
#         - What governance or decision-making challenges arise?

#         ### **3. CAPABILITIES** (Do we have what we need?)
#         - Do we have the necessary human resources in this future?
#         - Are required technologies and infrastructure available?
#         - Is organizational culture an asset or liability?
#         - What new competencies would be needed?

#         ### **4. ADAPTATIONS NEEDED** (How should policy be modified?)
#         - How should the policy be modified to remain effective?
#         - What contingencies or flexibility should be built in?
#         - What early warning indicators should be monitored?
#         - What alternative approaches might work better?

#         ANALYSIS REQUIREMENTS:
#         - Be specific and concrete with examples rather than general statements
#         - Ground analysis in the scenario details and policy specifics
#         - Focus on actionable insights for policy resilience
#         - Consider both opportunities and risks in the {scenario_type} scenario
#         - Each dimension should be 80-120 words of substantive analysis

#         Format your response as JSON:
#         {{
#             "viability": "Comprehensive analysis of policy effectiveness in this {scenario_type} scenario. Address objective achievement, success/failure factors, assumption validity, and unintended consequences with specific examples from the scenario context.",
#             "process": "Detailed analysis of implementation changes in this {scenario_type} scenario. Cover process modifications, stakeholder dynamics, timeline realism, and governance challenges with concrete examples.", 
#             "capabilities": "Thorough assessment of resource and capability requirements in this {scenario_type} scenario. Evaluate human resources, technology/infrastructure, organizational culture, and new competencies with specific details.",
#             "adaptations_needed": "Specific recommendations for policy modifications in this {scenario_type} scenario. Include effectiveness improvements, contingencies, monitoring indicators, and alternative approaches with actionable suggestions."
#         }}

#         Focus on how the unique characteristics of this {scenario_type} scenario create specific challenges and opportunities for the policy.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
#                         You excel at evaluating policy robustness across different future scenarios using concrete, specific analysis 
#                         grounded in scenario details. You provide actionable insights with examples rather than generic assessments. 
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for more detailed responses
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "viability": f"Error analyzing viability: {str(e)}",
#                 "process": f"Error analyzing process: {str(e)}",
#                 "capabilities": f"Error analyzing capabilities: {str(e)}",
#                 "adaptations_needed": f"Error generating adaptations: {str(e)}"
#             }

#     def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
#         """Generate cross-scenario insights and policy robustness analysis."""
        
#         # Format scenario analyses for prompt
#         analyses_text = ""
#         for scenario_name, analysis in scenario_analyses.items():
#             analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
#             analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
#             analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
#             analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
#             analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
#             analyses_text += "---\n"
        
#         prompt = f"""
#         You are conducting **cross-scenario synthesis** for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

#         POLICY ANALYZED:
#         {policy_text[:2000]}

#         INDIVIDUAL SCENARIO ANALYSES:
#         {analyses_text[:6000]}

#         CROSS-SCENARIO SYNTHESIS TASK:
#         Compare across ALL scenarios together (not individually) to extract strategic insights:

#         ### **Task 1: ROBUST ELEMENTS**
#         Identify which elements of the policy are robust and work well across ALL scenarios.
#         Focus on specific policy components, mechanisms, or approaches that remain effective regardless of future conditions.

#         ### **Task 2: SCENARIO-SPECIFIC ELEMENTS** 
#         Note which aspects of the policy only work in specific futures or require different approaches in different scenarios.
#         Be specific about which elements work in which scenarios and why.

#         ### **Task 3: CRITICAL VULNERABILITIES**
#         Highlight the biggest failure points, risks, and vulnerabilities that emerge across scenarios.
#         Focus on systemic weaknesses that could undermine policy effectiveness.

#         ### **Task 4: MONITORING INDICATORS**
#         Suggest specific, measurable early warning indicators that should be tracked to anticipate which scenario is emerging.
#         Focus on concrete metrics that would signal the need for policy adaptation.

#         SYNTHESIS REQUIREMENTS:
#         - Compare patterns and commonalities across all scenario analyses
#         - Be concrete and specific with examples rather than generic statements  
#         - Focus on actionable recommendations for policy resilience
#         - Each response should be 80-120 words of substantive analysis
#         - Ground insights in the specific policy and scenario details provided

#         Format as JSON:
#         {{
#             "robust_elements": "Specific policy aspects and mechanisms that demonstrate effectiveness across all scenarios, with concrete examples of why these elements remain viable regardless of future conditions.",
#             "scenario_specific": "Detailed identification of policy elements that only work in certain scenarios, specifying which elements work in which futures and the underlying reasons for scenario dependency.",
#             "critical_vulnerabilities": "Major systemic failure points and risks identified across scenarios, with specific assessment of how these vulnerabilities could undermine policy effectiveness and their potential impact.",
#             "monitoring_indicators": "Concrete, measurable early warning indicators and metrics that should be tracked to anticipate scenario emergence and signal the need for policy adaptation, with specific measurement approaches."
#         }}

#         Focus on the most strategically important cross-scenario insights for policy adaptation and long-term resilience.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
#                         and policy resilience assessment. You excel at identifying concrete patterns across different future 
#                         scenarios and translating them into specific, actionable policy insights with examples and evidence. 
#                         Always respond with valid JSON format."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,  # Increased for more detailed responses
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field}"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
#                 "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
#                 "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
#                 "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
#             }




# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)










#30-09-2025
#reduce the output generation also added lao language in prompt

# import json
# import os
# from groq import Groq
# import PyPDF2
# import io
# from typing import List, Dict, Any
# import re
# from PIL import Image
# import pytesseract
# from docx import Document

# class DRIForesightProcessor:
#     def __init__(self, groq_api_key: str):
#         """Initialize the DRI Foresight processor with Groq API."""
#         self.client = Groq(api_key=groq_api_key)
#         self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
#     def extract_text_from_pdf(self, pdf_file) -> str:
#         """Extract text content from uploaded PDF file."""
#         try:
#             pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
#             text = ""
#             for page in pdf_reader.pages:
#                 text += page.extract_text() + "\n"
#             return text.strip()
#         except Exception as e:
#             return f"Error extracting PDF text: {str(e)}"

#     def extract_text_from_file(self, file) -> str:
#         """Extract text content from uploaded file (supports multiple formats)."""
#         try:
#             file_extension = file.name.split('.')[-1].lower()
            
#             if file_extension == 'pdf':
#                 return self.extract_text_from_pdf(file)
#             elif file_extension in ['txt']:
#                 return file.read().decode('utf-8')
#             elif file_extension in ['csv']:
#                 # Prefer pandas if available; fallback to Python csv if not
#                 try:
#                     import pandas as pd  # type: ignore
#                     df = pd.read_csv(file)
#                     return df.to_string()
#                 except Exception:
#                     try:
#                         file.seek(0)
#                         import csv as _csv
#                         decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
#                         reader = _csv.reader(decoded_lines)
#                         rows = list(reader)
#                         return "\n".join([", ".join(row) for row in rows])
#                     except Exception as csv_err:
#                         return f"Could not read CSV file: {csv_err}"
#             #newly added from this 
#             elif file_extension in ['docx']:
#                 doc = Document(file)
#                 text = ""
#                 for paragraph in doc.paragraphs:
#                     text += paragraph.text + "\n"
#                 return text.strip()

#             elif file_extension in ['doc']:
#                 # For .doc files, you might need python-docx2txt
#                 try:
#                     import docx2txt
#                     return docx2txt.process(file)
#                 except ImportError:
#                     return "docx2txt library required for .doc files"

#             elif file_extension in ['pptx']:
#                 from pptx import Presentation
#                 prs = Presentation(file)
#                 text = ""
#                 for slide in prs.slides:
#                     for shape in slide.shapes:
#                         if hasattr(shape, "text"):
#                             text += shape.text + "\n"
#                 return text.strip()

#             elif file_extension in ['ppt']:
#                 # For .ppt files, you might need additional libraries like python-pptx or comtypes
#                 return "PowerPoint .ppt format requires additional processing"

#             elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
#                 # OCR for images
#                 image = Image.open(file)
#                 text = pytesseract.image_to_string(image)
#                 return text.strip()
#             #to this 
#             else:
#                 # For other formats, try to read as text
#                 try:
#                     return file.read().decode('utf-8')
#                 except:
#                     return f"Could not extract text from {file.name}"
#         except Exception as e:
#             return f"Error extracting text from {file.name}: {str(e)}"

#     def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
#         """Generate domain map based on the selected domain and document content."""
        
#         # Check if we have substantial document content
#         has_document_content = document_text and len(document_text.strip()) > 100
        
#         if has_document_content:
#             # Prioritize document content when available
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning.Based on the project "{project_name}", 
#             analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
#             should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
#             Please generate exactly 1 sub-domains to ensure comprehensive coverage of the domain.
            

#             Document Content:
#             {document_text[:3000]}

#             Please analyze the document content thoroughly and generate a detailed domain map with 1 sub-domain(s) that reflects the actual themes and topics discussed in the document.

#             For each sub-domain:
#             1. Provide a detailed description (1-2 sentences) that captures the specific aspects discussed in the document
#             2. Identify 3-4 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
#             3. Base the descriptions and issue areas on the actual content rather than generic knowledge

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area based on document content",
#                 "description": "Detailed description derived from the document content (1-2 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name from document themes",
#                         "description": "Comprehensive description based on specific document content (1-2 sentences explaining what the document reveals about this area)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 from document context",
#                             "Specific issue area 2 from document context",
#                             "Specific issue area 3 from document context",
#                             "Specific issue area 4 from document context"
#                         ]
#                     }}
#                 ]
#             }}

#             Focus on what the document actually discusses in detail rather than providing generic overviews. Ensure that the json's keys are in english and the values of the keys are only in Lao language.
#             """

#         else:
#             # Fall back to domain-based generation when no substantial document content
#             prompt = f"""
#             You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
#             create a comprehensive and detailed domain map for this specific focus area.
#             Please generate exactly 1 sub-domains to ensure comprehensive coverage of the domain.

#             Generate detailed analysis with:
#             1. 1 comprehensive sub-domains with detailed descriptions (1-2 sentences each)
#             2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
#             3. 3-4 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

#             Format your response as a JSON object with this structure:
#             {{
#                 "central_domain": "Main focus area title",
#                 "description": "Detailed description of the central domain (1-2 sentences)",
#                 "sub_domains": [
#                     {{
#                         "name": "Sub-domain name",
#                         "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (1-2 sentences)",
#                         "relevance": "High/Medium/Low",
#                         "issue_areas": [
#                             "Specific issue area 1 with clear focus",
#                             "Specific issue area 2 with clear focus",
#                             "Specific issue area 3 with clear focus",
#                             "Specific issue area 4 with clear focus"
#                         ]
#                     }}
#                 ]
#             }}

#             Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
#             """
                
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format.Ensure that the json's keys are in english and the values of the keys are only in Lao language."
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             # print(f"{response_text}")
#             return self._parse_json_response(response_text)
  
                
#         except Exception as e:
#             return {"error": f"Failed to generate domain map: {str(e)}"}
   
#     # UPDATE 1: In generate_signals method - around line 120
#     def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
#         """Generate strong and weak signals based on document analysis including interview insights."""
        
#         # UPDATED: Enhanced prompt to better handle comprehensive document context
#         prompt = f"""
#         As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
#         - Domain mapping documents and project materials
#         - Interview transcripts and stakeholder insights  
#         - External signals and trend data
#         - Any additional research materials
        
#         COMPREHENSIVE ANALYSIS TASK:
#         1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
#         2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

#         COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
#         {document_text[:12000]}  # Increased limit to capture more content

#         ANALYSIS INSTRUCTIONS:
#         - Synthesize insights across ALL uploaded content types
#         - Pay special attention to interview insights for stakeholder perspectives
#         - Look for patterns and convergence across different data sources
#         - Include signals that emerge from cross-referencing different document types
#         - Clearly indicate source context in descriptions

#         Please provide 2 strong signals and 2 weak signals in the following JSON format:
#         {{
#             "strong_signals": [
#                 {{
#                     "title": "Signal title",
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "impact": "Potential impact description",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ],
#             "weak_signals": [
#                 {{
#                     "title": "Signal title", 
#                     "description": "Detailed description synthesizing multiple sources where relevant",
#                     "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
#                     "potential": "Future potential or implications",
#                     "evidence_strength": "Evidence level from uploaded materials"
#                 }}
#             ]
#         }}

#         CRITICAL REQUIREMENTS:
#         - Every signal must be grounded in the provided content
#         - Prioritize signals that appear across multiple source types
#         - Include stakeholder perspectives from interviews where available
#         - Focus on domain-specific insights
#         - Ensure that the json's keys are in english and the values of the keys are only in Lao language.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
#                         You excel at synthesizing insights from multiple data sources including documents, interviews, 
#                         external signals, and research materials. You always identify patterns across different source types.
#                         Always respond with valid JSON format.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for comprehensive analysis
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate signals: {str(e)}"}


#     # UPDATE 2: In generate_steepv_analysis method - around line 180
#     def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
#         """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
#         # UPDATED: Better signal extraction and handling
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal processing
#         if isinstance(signals_data, dict) and 'raw_response' in signals_data:
#             try:
#                 import json
#                 import re
#                 raw_response = signals_data['raw_response']
#                 json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
#                 if json_match:
#                     parsed_signals = json.loads(json_match.group(1))
#                     strong_signals = parsed_signals.get('strong_signals', [])
#                     weak_signals = parsed_signals.get('weak_signals', [])
#             except:
#                 pass
        
#         # Create comprehensive signal descriptions
#         signal_descriptions = []
#         for signal in strong_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"STRONG: {signal}")
        
#         for signal in weak_signals:
#             if isinstance(signal, dict):
#                 title = signal.get('title', 'Unknown')
#                 desc = signal.get('description', '')
#                 source = signal.get('source', '')
#                 signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
#             else:
#                 signal_descriptions.append(f"WEAK: {signal}")
        
#         # UPDATED: Enhanced prompt with comprehensive context integration
#         prompt = f"""
#         You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

#         ANALYSIS CONTEXT:
#         - Domain Focus: {domain}
#         - Identified Signals: {len(signal_descriptions)} signals from multiple sources
#         - Comprehensive Context: Documents, interviews, external signals, research materials

#         SIGNALS TO CATEGORIZE:
#         {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

#         FULL INTEGRATED CONTEXT (All uploaded materials combined):
#         {document_text[:12000] if document_text else "No additional context provided"}

#         STEEPV ANALYSIS TASK:
#         Analyze ALL available information and provide 1-2 specific factors for EACH STEEPV category.
#         Synthesize insights from:
#         - Domain mapping documents
#         - Stakeholder interviews and perspectives  
#         - External signals and trends
#         - Research materials and data
#         - Cross-source patterns and themes

#         STEEPV FRAMEWORK (Enhanced Definitions):
#         - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
#         - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
#         - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
#         - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
#         - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
#         - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

#         COMPREHENSIVE ANALYSIS REQUIREMENTS:
#         1. Each category must contain 1-2 specific, actionable factors
#         2. Factors must be grounded in the provided materials (documents + interviews + signals)
#         3. Prioritize factors that appear across multiple source types
#         4. Include stakeholder perspectives from interviews where relevant
#         5. Make factors specific to the "{domain}" domain context
#         6. Ensure comprehensive coverage - NO category left empty
#         7. Focus on factors that will impact future scenario development

#         REQUIRED JSON FORMAT:
#         {{
#             "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
#             "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
#         }}

#         CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided. Respond only in Lao language.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
#                         You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
#                         Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
#                         Always respond with valid, complete JSON containing well-grounded factors for all categories."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive analysis
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Enhanced validation with domain-specific fallbacks
#             steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
#             for category in steepv_categories:
#                 if category not in parsed_result or not parsed_result[category]:
#                     # Domain-specific fallbacks based on comprehensive analysis
#                     parsed_result[category] = [
#                         f"{category} factors identified in {domain} domain analysis",
#                         f"{category} implications from stakeholder interviews", 
#                         f"{category} trends affecting {domain} development",
#                         f"{category} considerations from uploaded materials"
#                     ]
            
#             return parsed_result
                    
#         except Exception as e:
#             # Enhanced fallback with domain context
#             return {
#                 "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
#                 "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
#                 "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
#                 "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
#                 "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
#                 "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
#             }

#     def _parse_json_response(self, response_text: str) -> Dict:
#         """Enhanced JSON parsing with better error handling."""
#         import json
#         import re
        
#         # def clean_json_string(json_str):
#         #     """Clean up common JSON formatting issues"""
#         #     # Fix newlines immediately after opening quotes
#         #     json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#         #     # Fix multiple newlines within strings
#         #     json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#         #     # Fix single newlines within strings (but preserve paragraph structure)
#         #     json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#         #     # Remove markdown fences
#         #     json_str = re.sub(r"```(?:json)?", "", json_str)
#         #     json_str = json_str.replace("```", "")

#         #     # Remove trailing commas before } or ]
#         #     json_str = re.sub(r",\s*([\]}])", r"\1", json_str)

#         #     # Normalize multiple spaces/newlines
#         #     json_str = re.sub(r"\s+\n", " ", json_str)
#         #     json_str = re.sub(r"\n+", " ", json_str)

#         #     # return json_str
#         #     return json_str.strip()

#         def clean_json_string(json_str):
#             """Clean up common JSON formatting issues"""
#             # Fix newlines immediately after opening quotes
#             json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
#             # Fix multiple newlines within strings
#             json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
#             # Fix single newlines within strings
#             json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

#             # Remove markdown fences
#             json_str = re.sub(r"```(?:json)?", "", json_str)
#             json_str = json_str.replace("```", "")

#             # Fix missing commas between objects
#             json_str = re.sub(r'\}\s*\{', '}, {', json_str)

#             # Remove dangling/trailing commas
#             json_str = re.sub(r",\s*([\]}])", r"\1", json_str)
#             json_str = re.sub(r',\s*,+', ',', json_str)

#             # Escape unescaped quotes inside values
#             json_str = re.sub(
#                 r'(?<=:\s")([^"]*?)"(?=\s*[,}])',
#                 lambda m: m.group(1).replace('"', '\\"'),
#                 json_str
#             )

#             # Normalize multiple spaces/newlines
#             json_str = re.sub(r"\s+\n", " ", json_str)
#             json_str = re.sub(r"\n+", " ", json_str)

#             return json_str.strip()

        
#         try:
#             # First try direct JSON parsing
#             return json.loads(response_text)
#         except:
#             try:
#                 # Look for JSON in code blocks - more flexible pattern
#                 json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(1).strip()
#                     # Try to clean up formatting issues
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         # If cleaning didn't work, try original
#                         return json.loads(extracted_json)
                
#                 # Look for JSON-like structure without code blocks
#                 json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
#                 if json_match:
#                     extracted_json = json_match.group(0)
#                     cleaned_json = clean_json_string(extracted_json)
#                     try:
#                         return json.loads(cleaned_json)
#                     except:
#                         return json.loads(extracted_json)
                    
#             except Exception as e:
#                 print(f"JSON parsing error: {e}")
#                 print(f"Problematic JSON snippet: {response_text[:500]}...")
                
#             # Return empty dict if all parsing fails
#             return {}

#     def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
#         """Generate AI-powered suggestions for additional signals to consider."""
        
#         existing_signals = []
#         for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
#             existing_signals.append(signal.get('title', ''))
        
#         prompt = f"""
#         Given the domain "{domain}" and the following existing signals, suggest 1-2 additional signals 
#         that should be monitored for comprehensive foresight analysis.

#         Existing Signals:
#         {chr(10).join(existing_signals)}

#         Provide suggestions for signals that:
#         1. Are not already covered
#         2. Are relevant to the domain
#         3. Could significantly impact future scenarios
#         4. Come from different perspectives or sectors

#         Format as JSON:
#         {{
#             "suggestions": [
#                 {{
#                     "title": "Suggested signal title",
#                     "description": "Why this signal is important to monitor",
#                     "category": "Strong/Weak",
#                     "rationale": "Why this wasn't covered in existing signals"
#                 }}
#             ]
#         }}
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format.Ensure that the json's keys are in english and the values of the keys are only in Lao language"
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1000,
#                 temperature=0.8
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_response = self._parse_json_response(response_text)
            
#             if 'error' in parsed_response:
#                 return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
#             return parsed_response.get('suggestions', [])
                
#         except Exception as e:
#             return [{"error": f"Failed to generate suggestions: {str(e)}"}]

#     # UPDATE 3: In generate_futures_triangle method - around line 320
#     def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
#         """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
#         # Extract signals for context
#         strong_signals = signals_data.get('strong_signals', [])
#         weak_signals = signals_data.get('weak_signals', [])
        
#         # Enhanced signal formatting with source context
#         strong_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in strong_signals
#         ])
#         weak_signals_text = "\n".join([
#             f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
#             for signal in weak_signals
#         ])
        
#         # Enhanced STEEPV formatting
#         steepv_text = ""
#         for category, factors in steepv_data.items():
#             if factors:
#                 steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
#         # UPDATED: Comprehensive interview and document integration
#         comprehensive_context = ""
#         if interview_context:
#             comprehensive_context = f"""
            
#             COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
#             {interview_context[:8000]}  # Increased limit for full context
#             """
        
#         # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
#         prompt = f"""
#         As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

#         INTEGRATED ANALYSIS BASE:

#         STRONG SIGNALS (from comprehensive analysis):
#         {strong_signals_text}

#         WEAK SIGNALS (from comprehensive analysis):
#         {weak_signals_text}

#         STEEPV ANALYSIS SUMMARY:
#         {steepv_text}
#         {comprehensive_context}

#         FUTURES TRIANGLE METHODOLOGY:
#         Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

#         1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
#         - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
#         - Emerging Issues: New challenges or opportunities just becoming visible
#         - Visions & Aspirations: Images of preferred futures and goals pulling society forward

#         2. PUSH OF THE PRESENT (Current Momentum & Drivers):
#         - Current Trends: Observable patterns of change with clear direction
#         - Strong Drivers: Active forces creating pressure for change

#         3. WEIGHT OF HISTORY (Historical Constraints & Values):
#         - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
#         - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

#         4. KEY DYNAMICS & STRATEGIC INSIGHTS:
#         - Primary Tensions: Main conflicts between the three forces
#         - Alignment Opportunities: Where forces work together effectively
#         - Critical Uncertainties: What remains unknown or unpredictable

#         COMPREHENSIVE INTEGRATION REQUIREMENTS:
#         - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
#         - Ensure each force reflects evidence from multiple source types
#         - Include stakeholder perspectives prominently in future visions
#         - Ground all factors in the comprehensive materials provided
#         - Focus on domain-specific temporal dynamics

#         FORMAT YOUR RESPONSE AS JSON:
#         {{
#             "pull_of_future": {{
#                 "weak_signals": [
#                     "weak signal 1 (source context)",
#                     "weak signal 2 (source context)",
#                     "weak signal 3 (source context)"
#                 ],
#                 "emerging_issues": [
#                     "emerging issue 1 (source context)",
#                     "emerging issue 2 (source context)",
#                     "emerging issue 3 (source context)"
#                 ],
#                 "visions_and_aspirations": [
#                     "vision/aspiration 1 (source context)",
#                     "vision/aspiration 2 (source context)",
#                     "vision/aspiration 3 (source context)",
#                     "vision/aspiration 4 (source context)"
#                 ]

#             }},
#             "push_of_present": {{
#                 "current_trends": [
#                     "current trend 1 (source context)",
#                     "current trend 2 (source context)",
#                     "current trend 3 (source context)"
#                 ],
#                 "strong_drivers": [
#                     "strong driver 1 (source context)",
#                     "strong driver 2 (source context)",
#                     "strong driver 3 (source context)"
#                 ]
#             }},
#             "weight_of_history": {{
#                 "barriers_and_inertia": [
#                     "barrier/inertia 1 (source context)",
#                     "barrier/inertia 2 (source context)",
#                     "barrier/inertia 3 (source context)",
#                     "barrier/inertia 4 (source context)"
#                 ],
#                 "values_to_preserve": [
#                     "value to preserve 1 (source context)",
#                     "value to preserve 2 (source context)",
#                     "value to preserve 3 (source context)"
#                 ]
#             }},
#             "key_dynamics": {{
#                 "primary_tensions": [
#                     "primary tension 1 (source context)",
#                     "primary tension 2 (source context)",
#                     "primary tension 3 (source context)"
#                 ],
#                 "alignment_opportunities": [
#                     "alignment opportunity 1 (source context)",
#                     "alignment opportunity 2 (source context)",
#                     "alignment opportunity 3 (source context)"
#                 ],
#                 "critical_uncertainties": [
#                     "critical uncertainty 1 (source context)",
#                     "critical uncertainty 2 (source context)",
#                     "critical uncertainty 3 (source context)"
#                 ]
#             }}
#         }}

#         Ensure each subcategory has 1 specific factors grounded in the comprehensive {domain} analysis.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
#                         You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
#                         Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
#                         Always respond with valid JSON format grounded in provided evidence.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=3000,  # Increased for comprehensive output including key dynamics
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

#     # UPDATE 4: Add new method for comprehensive text extraction
#     def extract_comprehensive_text(self, files_dict: Dict) -> str:
#         """Extract and combine text from all uploaded file types for comprehensive analysis."""
#         all_text_content = []
        
#         # Process domain map documents
#         if files_dict.get('documents'):
#             all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
#             for file in files_dict['documents']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Document: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process interview data
#         if files_dict.get('interviews'):
#             all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
#             for file in files_dict['interviews']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Interview Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process external signals
#         if files_dict.get('signals'):
#             all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
#             for file in files_dict['signals']:
#                 content = self.extract_text_from_file(file)
#                 all_text_content.append(f"Signal Source: {file.name}")
#                 all_text_content.append(content)
#                 all_text_content.append("---")
        
#         # Process domain map file separately if exists
#         if files_dict.get('domain_map'):
#             all_text_content.append("=== DOMAIN MAP REFERENCE ===")
#             content = self.extract_text_from_file(files_dict['domain_map'])
#             all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
#             all_text_content.append(content)
#             all_text_content.append("---")
        
#         return "\n".join(all_text_content)
    
#     def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
#         """Analyze interview data to extract challenges, opportunities, and visions."""
        
#         prompt = f"""
#         As an expert analyst, analyze the following interview data for the domain "{domain}".
        
#         Interview Content:
#         {interview_text[:4000]}  # Limit content to avoid token limits
        
#         Extract and categorize the key insights into:
#         1. Top Challenges - main obstacles, problems, or difficulties mentioned
#         2. Key Opportunities - opportunities, potential solutions, or positive developments
#         3. Future Visions - aspirations, goals, or desired future states mentioned
        
#         Format your response as JSON:
#         {{
#             "challenges": [
#                 "challenge 1",
#                 "challenge 2",
#                 "challenge 3",
#                 "challenge 4"
#             ],
#             "opportunities": [
#                 "opportunity 1",
#                 "opportunity 2", 
#                 "opportunity 3",
#                 "opportunity 4"
#             ],
#             "visions": [
#                 "vision 1",
#                 "vision 2",
#                 "vision 3",
#                 "vision 4"
#             ]
#         }}
        
#         Focus on the most significant and frequently mentioned themes.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format.Ensure that the json's keys are in english and the values of the keys are only in Lao language"
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             return self._parse_json_response(response_text)
                
#         except Exception as e:
#             return {"error": f"Failed to analyze interview data: {str(e)}"}

#     def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
#             """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
#             # Extract Phase 2 data
#             signals_data = phase2_data.get('signals_data', {})
#             steepv_data = phase2_data.get('steepv_data', {})
#             basic_triangle = phase2_data.get('futures_triangle_data', {})
            
#             # Format signals context
#             strong_signals = signals_data.get('strong_signals', [])
#             weak_signals = signals_data.get('weak_signals', [])
            
#             signals_context = ""
#             if strong_signals:
#                 signals_context += "STRONG SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
#                 ])
#             if weak_signals:
#                 signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
#                     f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
#                 ])
            
#             # Format STEEPV context
#             steepv_context = ""
#             for category, factors in steepv_data.items():
#                 if factors:
#                     steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
#             # Enhanced prompt for Futures Triangle 2.0
#             prompt = f"""
#             As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

#             CONTEXT FROM PREVIOUS PHASES:
#             Project: {phase1_data.get('project_name', domain)}
#             Domain Focus: {domain}
            
#             PHASE 2 ANALYSIS RESULTS:
#             {signals_context}
            
#             STEEPV ANALYSIS:
#             {steepv_context}
            
#             COMPREHENSIVE DOCUMENT CONTEXT:
#             {comprehensive_context[:8000]}
            
#             FUTURES TRIANGLE 2.0 METHODOLOGY:
#             This enhanced version extracts three key elements for scenario building:

#             1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
#             - Major forces creating change pressure
#             - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
#             - These will be "bent" to different archetypes in scenario planning

#             2. **UNCERTAINTIES** (Critical unknowns from analysis):
#             - High-impact variables that could go multiple directions
#             - Key pivot points that determine scenario outcomes
#             - Wild cards and game-changing possibilities

#             3. **NARRATIVES** (Stories shaping the domain):
#             - Dominant mental models currently operating
#             - Emerging alternative narratives from weak signals
#             - Competing storylines about the future

#             ENHANCED TRIANGLE STRUCTURE:
#             Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

#             FORMAT AS JSON:
#             {{
#                 "drivers": [
#                     {{
#                         "id": "D1",
#                         "name": "Driver name",
#                         "description": "Detailed description of the driving force",
#                         "category": "Technological/Economic/Social/Environmental/Political/Values",
#                         "impact_level": "High/Medium/Low",
#                         "certainty": "High/Medium/Low",
#                         "current_trajectory": "Current direction and momentum",
#                         "source_evidence": "Evidence from uploaded materials"
#                     }}
#                 ],
#                 "uncertainties": [
#                     {{
#                         "id": "U1",
#                         "name": "Uncertainty name",
#                         "description": "What is uncertain and why it matters",
#                         "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
#                         "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
#                         "impact_on_scenarios": "How this shapes different futures",
#                         "source_evidence": "Evidence from analysis"
#                     }}
#                 ],
#                 "narratives": [
#                     {{
#                         "id": "N1",
#                         "type": "Dominant/Emerging/Alternative",
#                         "name": "Narrative name",
#                         "description": "The story or mental model",
#                         "supporting_evidence": ["Evidence 1", "Evidence 2"],
#                         "influence_areas": ["Area 1", "Area 2"],
#                         "alternative_versions": ["Alternative view 1", "Alternative view 2"],
#                         "source_context": "Where this narrative appears in materials"
#                     }}
#                 ],
#                 "enhanced_triangle": {{
#                     "pull_of_future": {{
#                         "weak_signals": ["signal 1", "signal 2", "signal 3"],
#                         "emerging_issues": ["issue 1", "issue 2", "issue 3"],
#                         "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
#                     }},
#                     "push_of_present": {{
#                         "trends": ["trend 1", "trend 2", "trend 3"],
#                         "drivers": ["driver 1", "driver 2", "driver 3"]
#                     }},
#                     "weight_of_history": {{
#                         "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
#                         "values_to_maintain": ["value 1", "value 2", "value 3"]
#                     }},
#                     "key_dynamics": {{
#                         "primary_tensions": ["tension 1", "tension 2", "tension 3"],
#                         "alignment_opportunities": ["opportunity 1", "opportunity 2"],
#                         "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
#                     }}
#                 }},
#                 "strategic_insights": {{
#                     "leverage_points": ["point 1", "point 2", "point 3"],
#                     "signals_to_monitor": ["signal 1", "signal 2"],
#                     "values_to_protect": ["value 1", "value 2"]
#                 }}
#             }}

#             CRITICAL REQUIREMENTS:
#             - Extract 1-2 DRIVERS that will dominate the baseline scenario
#             - Identify 1-2 UNCERTAINTIES that are pivot points for different outcomes  
#             - Capture 1-2 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
#             - Ground all elements in the provided evidence from Phase 1 & 2
#             - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
#             """
            
#             try:
#                 chat_completion = self.client.chat.completions.create(
#                     messages=[
#                         {
#                             "role": "system",
#                             "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
#                             for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
#                             from comprehensive foresight analysis that can be adapted across different scenario archetypes.
#                             Always respond with valid, complete JSON.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                         },
#                         {"role": "user", "content": prompt}
#                     ],
#                     model=self.model,
#                     max_tokens=4000,
#                     temperature=0.7
#                 )
                
#                 response_text = chat_completion.choices[0].message.content
#                 parsed_result = self._parse_json_response(response_text)

                
#                 # Validate required sections exist
#                 required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
#                 for section in required_sections:
#                     if section not in parsed_result:
#                         parsed_result[section] = []
                
#                 return parsed_result
                    
#             except Exception as e:
#                 return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

# #new
#     def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate baseline scenario dominated by Push of Present and key Drivers (1-2 paragraphs)."""
        
#         # Extract key elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
#         push_of_present = enhanced_triangle.get('push_of_present', {})
        
#         # Format drivers context - focus on high certainty/high impact
#         high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
#         drivers_context = ""
#         for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
#             drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
#         # Format Push of Present context
#         trends = push_of_present.get('trends', [])
#         existing_drivers = push_of_present.get('drivers', [])
#         push_context = ""
#         if trends:
#             push_context += "Current Trends: " + ", ".join(trends[:4])
#         if existing_drivers:
#             push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         prompt = f"""
#         You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         BASELINE SCENARIO DEFINITION:
#         The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
#         1. **Push of the Present**: Current trends and momentum
#         2. **Key Drivers**: High-certainty forces shaping the future
        
#         PUSH OF THE PRESENT (Current Momentum):
#         {push_context}
        
#         KEY DRIVERS (High Certainty Forces):
#         {drivers_context}
        
#         BASELINE SCENARIO REQUIREMENTS:
        
#         **Structure (1-2 paragraphs, 50-60 words total):**
        
#         **Paragraph 1 - Present Momentum (10-15 words):**
#         - Describe the current state and ongoing trends
#         - Establish the "Push of the Present" foundation
#         - Set the context for continuation rather than transformation
        
#         **Paragraph 2 - Primary Drivers (10-15 words):**
#         - Focus on the highest certainty, highest impact drivers
#         - Explain how these forces reinforce current trajectories
#         - Show momentum building from existing patterns
        
#         **Paragraph 3 - Secondary Drivers & Evolution (10-15 words):**
#         - Include additional drivers that support the baseline path
#         - Show how the domain evolves within existing frameworks
#         - Demonstrate gradual rather than revolutionary change
        
#         **Paragraph 4 - Baseline Future State (10-15 words):**
#         - Synthesize into a coherent "most likely" future
#         - Emphasize continuation and extension of current trends
#         - Position as the foundation before exploring alternatives
        
#         **Writing Style:**
#         - Narrative and story-like, but grounded in evidence
#         - Confident but not overly optimistic
#         - Focus on "what's most likely" rather than "what's possible"
#         - Use concrete details from the domain context
        
#         **Critical Focus:**
#         - This is NOT about transformation or disruption
#         - This IS about logical extension of current momentum
#         - Emphasize high-certainty, predictable developments
#         - Set up the contrast for later alternative scenarios

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
        
#         Format your response as JSON:
#         {{
#             "scenario_title": "Descriptive title for the baseline scenario",
#             "timeframe": "2025-2030" or appropriate timeframe,
#             "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
#             "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
#             "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
#             "scenario_type": "Baseline/Continuation"
#         }}
        
#         Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
#                         You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
#                         high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
#                         and set the foundation for exploring alternative futures. Always respond with valid JSON.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.6  # Lower temperature for more consistent baseline scenarios
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)

            
#             # Validate required fields
#             required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Generated {field} for {domain}"
                            
#             # Ensure scenario_text exists and is reasonable length
#             if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
#                 parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
#             return parsed_result
                
#         except Exception as e:
#             return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
#     def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
#         """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
#         # Extract elements from Futures Triangle 2.0
#         drivers = triangle_2_0_data.get('drivers', [])
#         uncertainties = triangle_2_0_data.get('uncertainties', [])
#         narratives = triangle_2_0_data.get('narratives', [])
        
#         # Project context
#         project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
#         # Format baseline context
#         baseline_context = f"""
#         BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
#         Timeframe: {baseline_data.get('timeframe', '2025-2030')}
#         Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
#         """
        
#         prompt = f"""
#         You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

#         PROJECT CONTEXT:
#         Project: {project_name}
#         Domain: {domain}
        
#         {baseline_context}
        
#         DRIVER OUTCOMES METHODOLOGY:
#         Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
#         1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
#         2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
#         3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
#         ELEMENTS TO BEND:
        
#         DRIVERS (Major Forces):
#         {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
#         UNCERTAINTIES (Pivot Points):
#         {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
#         NARRATIVES (Stories):
#         {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
#         ARCHETYPE DEFINITIONS:
        
#         **COLLAPSE/DECLINE:**
#         - Systems fail, break down, or regress
#         - Negative feedback loops dominate
#         - Resources become scarce, trust erodes
#         - Institutions lose effectiveness
#         - Focus: "What goes wrong?"
        
#         **NEW EQUILIBRIUM:**
#         - Adaptive responses create stability
#         - Systems reform and find balance
#         - Gradual improvement within existing frameworks
#         - Incremental innovation and adjustment
#         - Focus: "How do we adapt?"
        
#         **TRANSFORMATION:**
#         - Breakthrough innovations emerge
#         - Fundamental paradigm shifts occur
#         - New systems replace old ones
#         - Exponential positive change
#         - Focus: "What becomes possible?"
        
#         OUTCOME REQUIREMENTS:
#         - Each element gets 1 outcomes (one per archetype)
#         - Outcomes should be 1-2 sentences each
#         - Stay grounded in the domain context
#         - Show how the same force creates different futures
#         - Make outcomes specific and plausible within each archetype
        
#         Format as JSON:
#         {{
#             "driver_outcomes": [
#                 {{
#                     "driver_id": "D1",
#                     "driver_name": "Driver name from Triangle 2.0",
#                     "baseline_trajectory": "How this plays out in baseline",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "1-2 sentence description of how this driver manifests in a collapse scenario",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "New Equilibrium", 
#                             "outcome_text": "1-2 sentence description of how this driver manifests in adaptive change",
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "1-2 sentence description of how this driver creates breakthrough change", 
#                             "key_impacts": ["impact 1", "impact 2", "impact 3"]
#                         }}
#                     ]
#                 }}
#             ],
#             "uncertainty_outcomes": [
#                 {{
#                     "uncertainty_id": "U1",
#                     "uncertainty_name": "Uncertainty name from Triangle 2.0",
#                     "key_variables": ["var1", "var2"],
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this uncertainty resolves in a collapse scenario",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this uncertainty resolves in adaptive change",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }},
#                         {{
#                             "archetype": "Transformation", 
#                             "outcome_text": "How this uncertainty resolves in transformation",
#                             "resolution_direction": "Which way the uncertainty tips"
#                         }}
#                     ]
#                 }}
#             ],
#             "narrative_outcomes": [
#                 {{
#                     "narrative_id": "N1",
#                     "narrative_name": "Narrative name from Triangle 2.0",
#                     "narrative_type": "Dominant/Emerging/Alternative",
#                     "outcomes": [
#                         {{
#                             "archetype": "Collapse/Decline",
#                             "outcome_text": "How this narrative evolves in collapse",
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "New Equilibrium",
#                             "outcome_text": "How this narrative evolves in adaptation", 
#                             "narrative_shift": "What story dominates"
#                         }},
#                         {{
#                             "archetype": "Transformation",
#                             "outcome_text": "How this narrative evolves in transformation",
#                             "narrative_shift": "What story dominates"
#                         }}
#                     ]
#                 }}
#             ],
#             "cross_archetype_insights": {{
#                 "collapse_patterns": ["Common themes across collapse outcomes"],
#                 "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
#                 "transformation_patterns": ["Common themes across transformation outcomes"],
#                 "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
#             }}
#         }}
        
#         CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
#                         You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
#                         differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
#                         specific outcomes that demonstrate how the same forces can lead to very different futures. 
#                         Always respond with valid, complete JSON.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=4000,
#                 temperature=0.7
#             )
            
#             response_text = chat_completion.choices[0].message.content
            
#             # Clean response - remove any markdown code blocks
#             response_text = response_text.strip()
#             if response_text.startswith('```json'):
#                 response_text = response_text.replace('```json', '').replace('```', '').strip()
#             elif response_text.startswith('```'):
#                 response_text = response_text.replace('```', '').strip()
                
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required sections exist
#             required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
#             for section in required_sections:
#                 if section not in parsed_result:
#                     parsed_result[section] = []
            
#             # Ensure we have cross-archetype insights
#             if 'cross_archetype_insights' not in parsed_result:
#                 parsed_result['cross_archetype_insights'] = {
#                     'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
#                     'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
#                     'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
#                     'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
#                 }
            
#             return parsed_result
            
#         except Exception as e:
#             return {"error": f"Failed to generate driver outcomes: {str(e)}"}


# #much better ----solved No more lazy #2 titles
#     def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
#         """Generate alternative scenarios based on selected archetypes."""
        
#         # Archetype definitions
#         archetype_definitions = {
#             "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
#             "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
#             "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
#         }
        
#         scenarios = []
        
#         for archetype, count in selected_archetypes.items():
#             if count > 0:
#                 for i in range(count):
#                     scenario = self._generate_single_scenario(
#                         domain=domain,
#                         archetype=archetype, 
#                         archetype_definition=archetype_definitions.get(archetype, ""),
#                         baseline_data=baseline_data,
#                         driver_outcomes=driver_outcomes,
#                         triangle_2_0_data=triangle_2_0_data,
#                         scenario_number=i+1
#                     )
#                     scenarios.append(scenario)
        
#         return {"scenarios": scenarios}

#     def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
#                                 baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
#                                 scenario_number: int = 1) -> Dict:
#         """Generate a single scenario narrative with improved diversity."""
        
#         # Extract key context
#         baseline_text = baseline_data.get('scenario_text', '')
#         baseline_title = baseline_data.get('scenario_title', '')
        
#         # Get driver outcomes for this archetype
#         relevant_outcomes = []
#         for driver in driver_outcomes.get('driver_outcomes', []):
#             for outcome in driver.get('outcomes', []):
#                 outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
#                 target_archetype = archetype.lower().replace(' ', '')
#                 if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
#         # If no relevant outcomes found, get first few driver outcomes
#         if not relevant_outcomes:
#             for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
#                 for outcome in driver.get('outcomes', [])[:1]:
#                     relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

#         # Create scenario-specific focus areas to ensure diversity
#         focus_areas = {
#             "Collapse": [
#                 "financial system breakdown and economic collapse",
#                 "institutional failure and governance breakdown", 
#                 "technological obsolescence and infrastructure decay",
#                 "social fragmentation and cultural alienation"
#             ],
#             "New Equilibrium": [
#                 "sustainable development and environmental stewardship",
#                 "inclusive governance and democratic reforms",
#                 "regional cooperation and diplomatic balance",
#                 "tradition preservation with selective innovation"
#             ],
#             "Transformation": [
#                 "breakthrough technological revolution and digitization",
#                 "global democratization and grassroots expansion",
#                 "radical business model innovation and new economics",
#                 "social impact revolution and cultural transformation"
#             ]
#         }

#         unique_drivers_per_scenario = {
#             "Collapse": [
#                 "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
#                 "regulatory conflicts, visa restrictions, political tensions between nations",
#                 "aging infrastructure, resistance to new technology, equipment failures",
#                 "generational disconnect, competing entertainment, loss of cultural relevance"
#             ],
#             "New Equilibrium": [
#                 "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
#                 "stakeholder representation, transparent governance, democratic decision-making",
#                 "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
#                 "heritage conservation, selective tech integration, cultural preservation"
#             ],
#             "Transformation": [
#                 "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
#                 "non-traditional markets, grassroots accessibility, global talent mobility",
#                 "subscription models, fan ownership, cryptocurrency integration, direct investment",
#                 "gender equality initiatives, community development, social change catalyst"
#             ]
#         }

#         # Select focus and unique drivers based on scenario number
#         focus_list = focus_areas.get(archetype, ["general system changes"])
#         selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

#         drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
#         unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

#         prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

#         ARCHETYPE: {archetype} - {archetype_definition}
#         UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
#         UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

#         BASELINE CONTEXT:
#         {baseline_text[:400]}

#         REQUIRED DRIVER OUTCOMES TO INTEGRATE:
#         {chr(10).join(relevant_outcomes[:4])}

#         CRITICAL DIVERSITY REQUIREMENTS:
#         - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
#         - Focus ONLY on {selected_focus} - do not mix with other focus areas
#         - Emphasize these unique drivers: {unique_drivers}
#         - Create a unique storyline with different triggers, progression, and outcomes
#         - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
#         - Probability assessment must vary and be justified
#         - All factors, assumptions, and indicators must be unique to this specific focus

#         STRUCTURE (EXACTLY 4 paragraphs, 50-100 words total):
#         1. Initial conditions specific to {selected_focus} (2025-2026) - 20-30 words
#         2. Key developments driven by {unique_drivers} (2027-2028) - 20-30 words
#         3. Full manifestation of {selected_focus} (2029-2030) - 20-30 words
#         4. Final system state shaped by {selected_focus} (2030) - 20-30 words

#         **CRITICAL FORMATTING RULES:**
#         - Return valid JSON with no markdown code blocks
#         - The scenario_text must be a single continuous string
#         - Replace all actual newlines in text with \\n\\n escape sequences
#         - Do NOT put line breaks immediately after opening quotes
#         - Keep total word count between 100-150 words
#         - Each paragraph should be 30-40 words maximum

#         Return ONLY valid JSON:
#         {{
#             "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
#             "archetype": "{archetype}",
#             "timeframe": "2025-2030", 
#             "scenario_text": "Four paragraphs separated by \\n\\n, each 20-30 words, total 100-150 words...",
#             "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
#             "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
#             "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
#             "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
#         }}

#         ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system", 
#                         "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
#                         Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
#                         Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
#                         and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1200,  # Reduced to encourage conciseness
#                 temperature=0.7,  # Reduced for better structure adherence
#                 # Remove response_format since you're handling JSON parsing manually
#             )
            
#             response_text = response.choices[0].message.content.strip()
            
#             # CRITICAL FIX: Use your robust parser instead of json.loads()
#             parsed_result = self._parse_json_response(response_text)
            
#             # Check if parsing failed (empty dict or error)
#             if not parsed_result or parsed_result.get('error'):
#                 raise ValueError("JSON parsing failed")
            
#             # Validate and ensure required fields
#             if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
#                 raise ValueError("Scenario text too short or missing")
            
#             # Keep the AI-generated title as-is (no numbering fallback)
#             title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
#             parsed_result['scenario_title'] = title
                
#             # Set proper defaults
#             parsed_result.setdefault('archetype', archetype)
#             parsed_result.setdefault('timeframe', '2025-2030')
#             parsed_result.setdefault('key_factors', [])
#             parsed_result.setdefault('critical_assumptions', [])
#             parsed_result.setdefault('probability_assessment', 'Medium')
#             parsed_result.setdefault('key_indicators', [])
            
#             return parsed_result
            
#         except Exception as e:
#             print(f"Scenario generation error: {str(e)}")
#             return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

#     def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
#         """Fallback simple scenario generation with focus area."""
        
#         simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

#     Focus on: {focus_area or archetype.lower()}

#     Write 3 paragraphs showing progression over time.

#     Return JSON:
#     {{
#         "scenario_title": "Unique title for scenario #{scenario_number}",
#         "archetype": "{archetype}",
#         "timeframe": "2025-2030",
#         "scenario_text": "3 paragraph narrative...",
#         "key_factors": ["factor1", "factor2", "factor3"],
#         "critical_assumptions": ["assumption1", "assumption2"], 
#         "probability_assessment": "Low/Medium/High",
#         "key_indicators": ["indicator1", "indicator2"]
#     }}"""
        
#         try:
#             response = self.client.chat.completions.create(
#                 messages=[
#                     {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
#                     {"role": "user", "content": simple_prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=1500,
#                 temperature=0.9,
#                 response_format={"type": "json_object"}
#             )
            
#             result = json.loads(response.choices[0].message.content.strip())
            
#             # Ensure unique title
#             title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
#             if scenario_number > 1:
#                 title = f"{title} #{scenario_number}"
#             result['scenario_title'] = title
            
#             return result
            
#         except Exception as e:
#             print(f"Simple scenario generation failed: {str(e)}")
#             return {
#                 "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
#                 "archetype": archetype,
#                 "timeframe": "2025-2030",
#                 "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
#                 "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
#                 "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
#                 "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
#                 "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
#             }



#     # Add this method to your DRIForesightProcessor class in main.py

#     def run_wind_tunnel_analysis(self, domain: str, policy_text: str, phase3_scenarios: Dict, project_name: str = "") -> Dict[str, Any]:
#         """
#         Run Wind Tunnel analysis - stress test policy against all Phase 3 scenarios.
        
#         Args:
#             domain: The project domain
#             policy_text: Extracted text from uploaded policy documents
#             phase3_scenarios: Dict containing baseline and alternative scenarios from Phase 3
#             project_name: Optional project name for context
        
#         Returns:
#             Dict with analysis for each scenario and cross-scenario insights
#         """
        
#         # Extract scenarios from Phase 3 data
#         baseline_scenario = phase3_scenarios.get('baseline_scenario', {})
#         alternative_scenarios = phase3_scenarios.get('alternative_scenarios', {}).get('scenarios', [])
        
#         # Organize scenarios by archetype
#         scenarios_to_analyze = {
#             'baseline': {
#                 'title': baseline_scenario.get('scenario_title', 'Baseline Scenario'),
#                 'text': baseline_scenario.get('scenario_text', ''),
#                 'type': 'Baseline'
#             }
#         }
        
#         # Add alternative scenarios
#         for scenario in alternative_scenarios:
#             archetype = scenario.get('archetype', '').lower().replace(' ', '_')
#             if archetype == 'collapse':
#                 scenarios_to_analyze['collapse'] = scenario
#             elif archetype == 'new_equilibrium':
#                 scenarios_to_analyze['equilibrium'] = scenario
#             elif archetype == 'transformation':
#                 scenarios_to_analyze['transformation'] = scenario
        
#         # Analyze each scenario
#         scenario_analyses = {}
        
#         for scenario_key, scenario_data in scenarios_to_analyze.items():
#             analysis = self._analyze_policy_against_scenario(
#                 domain=domain,
#                 policy_text=policy_text,
#                 scenario_data=scenario_data,
#                 project_name=project_name
#             )
#             scenario_analyses[scenario_key] = analysis
        
#         # Generate cross-scenario insights
#         cross_scenario_analysis = self._generate_cross_scenario_insights(
#             domain=domain,
#             policy_text=policy_text,
#             scenario_analyses=scenario_analyses,
#             project_name=project_name
#         )
        
#         return {
#             "scenarios": scenario_analyses,
#             "cross_scenario": cross_scenario_analysis
#         }

#     # def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
#     #     """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
#     #     scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
#     #     scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
#     #     scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
#     #     prompt = f"""
#     #     You are a senior policy analyst conducting a Wind Tunnel stress test analysis for "{project_name}" in the "{domain}" domain.

#     #     POLICY TO ANALYZE:
#     #     {policy_text[:4000]}  # Limit for token management

#     #     FUTURE SCENARIO TO TEST AGAINST:
#     #     Title: {scenario_title}
#     #     Type: {scenario_type}
#     #     Description: {scenario_text[:2000]}

#     #     WIND TUNNEL EVALUATION FRAMEWORK:
#     #     Conduct a comprehensive policy stress test using these four dimensions:

#     #     1. VIABILITY (Does the policy achieve its objectives?)
#     #     - Will the policy meet its stated goals in this future scenario?
#     #     - What aspects succeed or fail and why?
#     #     - Are underlying assumptions still valid?
#     #     - What unintended consequences emerge?

#     #     2. PROCESS (How does implementation change?)
#     #     - How do implementation timelines and milestones change?
#     #     - What new stakeholders or power dynamics emerge?
#     #     - What governance or decision-making challenges arise?
#     #     - How do approval and coordination processes adapt?

#     #     3. CAPABILITIES (Do we have what we need?)
#     #     - Are required human resources available and adequate?
#     #     - Are necessary technologies and infrastructure accessible?
#     #     - Is organizational culture helpful or problematic?
#     #     - What new competencies would be required?

#     #     4. ADAPTATIONS NEEDED (How should policy be modified?)
#     #     - What specific modifications would improve effectiveness?
#     #     - What contingencies or flexibility should be built in?
#     #     - What early warning indicators should be monitored?
#     #     - What alternative approaches might work better?

#     #     ANALYSIS REQUIREMENTS:
#     #     - Be specific and concrete rather than general
#     #     - Ground analysis in the scenario details
#     #     - Focus on actionable insights
#     #     - Consider both opportunities and risks
#     #     - Address the {scenario_type} scenario dynamics specifically

#     #     Format your response as JSON:
#     #     {{
#     #         "viability": "Detailed analysis of policy effectiveness in this scenario (4-6 sentences with specific examples)",
#     #         "process": "Analysis of implementation challenges and changes (4-6 sentences with specific examples)", 
#     #         "capabilities": "Assessment of resource and capability requirements (4-6 sentences with specific examples)",
#     #         "adaptations_needed": "Specific recommendations for policy modifications (4-6 sentences with concrete suggestions)"
#     #     }}

#     #     Focus on the unique challenges and opportunities this {scenario_type} scenario creates for the policy.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system",
#     #                     "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
#     #                     You excel at evaluating policy robustness across different future scenarios using the 
#     #                     VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework. You provide concrete, actionable insights 
#     #                     grounded in scenario specifics. Always respond with valid JSON format."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=2000,
#     #             temperature=0.6
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         parsed_result = self._parse_json_response(response_text)
            
#     #         # Validate required fields exist
#     #         required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
#     #         for field in required_fields:
#     #             if field not in parsed_result:
#     #                 parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         return {
#     #             "viability": f"Error analyzing viability: {str(e)}",
#     #             "process": f"Error analyzing process: {str(e)}",
#     #             "capabilities": f"Error analyzing capabilities: {str(e)}",
#     #             "adaptations_needed": f"Error generating adaptations: {str(e)}"
#     #         }

#     # def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
#     #     """Generate cross-scenario insights and policy robustness analysis."""
        
#     #     # Format scenario analyses for prompt
#     #     analyses_text = ""
#     #     for scenario_name, analysis in scenario_analyses.items():
#     #         analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
#     #         analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
#     #         analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
#     #         analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
#     #         analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
#     #         analyses_text += "---\n"
        
#     #     prompt = f"""
#     #     You are conducting cross-scenario analysis for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

#     #     POLICY ANALYZED:
#     #     {policy_text[:2000]}

#     #     INDIVIDUAL SCENARIO ANALYSES:
#     #     {analyses_text[:6000]}

#     #     CROSS-SCENARIO SYNTHESIS TASK:
#     #     Analyze the patterns across all scenario analyses to identify:

#     #     1. ROBUST ELEMENTS - Which policy aspects work well across ALL scenarios?
#     #     2. SCENARIO-SPECIFIC ELEMENTS - Which aspects only work in certain futures?
#     #     3. CRITICAL VULNERABILITIES - What are the biggest failure points and risks?
#     #     4. MONITORING INDICATORS - What early warning signs should be tracked?

#     #     SYNTHESIS REQUIREMENTS:
#     #     - Identify patterns and commonalities across scenarios
#     #     - Highlight the most critical insights for policy resilience
#     #     - Focus on actionable recommendations
#     #     - Be specific rather than generic

#     #     Format as JSON:
#     #     {{
#     #         "robust_elements": "Policy aspects that work across all scenarios (3-4 specific examples)",
#     #         "scenario_specific": "Elements that only work in certain scenarios (3-4 specific examples with scenario context)",
#     #         "critical_vulnerabilities": "Major failure points and risks (3-4 specific vulnerabilities with impact assessment)",
#     #         "monitoring_indicators": "Key early warning indicators to track (4-5 specific, measurable indicators)"
#     #     }}

#     #     Focus on the most strategically important insights for policy adaptation and resilience.
#     #     """
        
#     #     try:
#     #         chat_completion = self.client.chat.completions.create(
#     #             messages=[
#     #                 {
#     #                     "role": "system",
#     #                     "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
#     #                     and policy resilience assessment. You excel at identifying patterns across different future 
#     #                     scenarios and translating them into actionable policy insights. Always respond with valid JSON format."""
#     #                 },
#     #                 {"role": "user", "content": prompt}
#     #             ],
#     #             model=self.model,
#     #             max_tokens=1500,
#     #             temperature=0.6
#     #         )
            
#     #         response_text = chat_completion.choices[0].message.content
#     #         parsed_result = self._parse_json_response(response_text)
            
#     #         # Validate required fields exist
#     #         required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
#     #         for field in required_fields:
#     #             if field not in parsed_result:
#     #                 parsed_result[field] = f"Analysis pending for {field}"
            
#     #         return parsed_result
            
#     #     except Exception as e:
#     #         return {
#     #             "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
#     #             "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
#     #             "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
#     #             "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
#     #         }

#     def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
#         """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
#         scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
#         scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
#         scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
#         prompt = f"""
#         You are performing a **Wind Tunnel stress test** of the policy document for "{project_name}" in the "{domain}" domain.
        
#         POLICY TO ANALYZE:
#         {policy_text[:4000]}

#         FUTURE SCENARIO TO TEST AGAINST:
#         Title: {scenario_title}
#         Type: {scenario_type}
#         Description: {scenario_text[:2000]}

#         WIND TUNNEL EVALUATION FRAMEWORK:
#         Systematically evaluate this policy against the given scenario using four dimensions:

#         ### **1. VIABILITY** (Does the policy achieve its objectives?)
#         - Does the policy achieve its stated objectives in this future scenario?
#         - What aspects of the policy succeed or fail and why?
#         - Are the underlying assumptions still valid?
#         - What unintended consequences emerge?

#         ### **2. PROCESS** (How does implementation change?)
#         - How does the implementation process change in this scenario?
#         - What new stakeholders or power dynamics emerge?
#         - Are the planned timelines and milestones still realistic?
#         - What governance or decision-making challenges arise?

#         ### **3. CAPABILITIES** (Do we have what we need?)
#         - Do we have the necessary human resources in this future?
#         - Are required technologies and infrastructure available?
#         - Is organizational culture an asset or liability?
#         - What new competencies would be needed?

#         ### **4. ADAPTATIONS NEEDED** (How should policy be modified?)
#         - How should the policy be modified to remain effective?
#         - What contingencies or flexibility should be built in?
#         - What early warning indicators should be monitored?
#         - What alternative approaches might work better?

#         ANALYSIS REQUIREMENTS:
#         - Be specific and concrete with examples rather than general statements
#         - Ground analysis in the scenario details and policy specifics
#         - Focus on actionable insights for policy resilience
#         - Consider both opportunities and risks in the {scenario_type} scenario
#         - Each dimension should be 10-20 words of substantive analysis

#         Format your response as JSON:
#         {{
#             "viability": "Comprehensive analysis of policy effectiveness in this {scenario_type} scenario. Address objective achievement, success/failure factors, assumption validity, and unintended consequences with specific examples from the scenario context.",
#             "process": "Detailed analysis of implementation changes in this {scenario_type} scenario. Cover process modifications, stakeholder dynamics, timeline realism, and governance challenges with concrete examples.", 
#             "capabilities": "Thorough assessment of resource and capability requirements in this {scenario_type} scenario. Evaluate human resources, technology/infrastructure, organizational culture, and new competencies with specific details.",
#             "adaptations_needed": "Specific recommendations for policy modifications in this {scenario_type} scenario. Include effectiveness improvements, contingencies, monitoring indicators, and alternative approaches with actionable suggestions."
#         }}

#         Focus on how the unique characteristics of this {scenario_type} scenario create specific challenges and opportunities for the policy.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
#                         You excel at evaluating policy robustness across different future scenarios using concrete, specific analysis 
#                         grounded in scenario details. You provide actionable insights with examples rather than generic assessments. 
#                         Always respond with valid JSON format.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2500,  # Increased for more detailed responses
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "viability": f"Error analyzing viability: {str(e)}",
#                 "process": f"Error analyzing process: {str(e)}",
#                 "capabilities": f"Error analyzing capabilities: {str(e)}",
#                 "adaptations_needed": f"Error generating adaptations: {str(e)}"
#             }

#     def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
#         """Generate cross-scenario insights and policy robustness analysis."""
        
#         # Format scenario analyses for prompt
#         analyses_text = ""
#         for scenario_name, analysis in scenario_analyses.items():
#             analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
#             analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
#             analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
#             analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
#             analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
#             analyses_text += "---\n"
        
#         prompt = f"""
#         You are conducting **cross-scenario synthesis** for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

#         POLICY ANALYZED:
#         {policy_text[:2000]}

#         INDIVIDUAL SCENARIO ANALYSES:
#         {analyses_text[:6000]}

#         CROSS-SCENARIO SYNTHESIS TASK:
#         Compare across ALL scenarios together (not individually) to extract strategic insights:

#         ### **Task 1: ROBUST ELEMENTS**
#         Identify which elements of the policy are robust and work well across ALL scenarios.
#         Focus on specific policy components, mechanisms, or approaches that remain effective regardless of future conditions.

#         ### **Task 2: SCENARIO-SPECIFIC ELEMENTS** 
#         Note which aspects of the policy only work in specific futures or require different approaches in different scenarios.
#         Be specific about which elements work in which scenarios and why.

#         ### **Task 3: CRITICAL VULNERABILITIES**
#         Highlight the biggest failure points, risks, and vulnerabilities that emerge across scenarios.
#         Focus on systemic weaknesses that could undermine policy effectiveness.

#         ### **Task 4: MONITORING INDICATORS**
#         Suggest specific, measurable early warning indicators that should be tracked to anticipate which scenario is emerging.
#         Focus on concrete metrics that would signal the need for policy adaptation.

#         SYNTHESIS REQUIREMENTS:
#         - Compare patterns and commonalities across all scenario analyses
#         - Be concrete and specific with examples rather than generic statements  
#         - Focus on actionable recommendations for policy resilience
#         - Each response should be 10-20 words of substantive analysis
#         - Ground insights in the specific policy and scenario details provided

#         Format as JSON:
#         {{
#             "robust_elements": "Specific policy aspects and mechanisms that demonstrate effectiveness across all scenarios, with concrete examples of why these elements remain viable regardless of future conditions.",
#             "scenario_specific": "Detailed identification of policy elements that only work in certain scenarios, specifying which elements work in which futures and the underlying reasons for scenario dependency.",
#             "critical_vulnerabilities": "Major systemic failure points and risks identified across scenarios, with specific assessment of how these vulnerabilities could undermine policy effectiveness and their potential impact.",
#             "monitoring_indicators": "Concrete, measurable early warning indicators and metrics that should be tracked to anticipate scenario emergence and signal the need for policy adaptation, with specific measurement approaches."
#         }}

#         Focus on the most strategically important cross-scenario insights for policy adaptation and long-term resilience.
#         """
        
#         try:
#             chat_completion = self.client.chat.completions.create(
#                 messages=[
#                     {
#                         "role": "system",
#                         "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
#                         and policy resilience assessment. You excel at identifying concrete patterns across different future 
#                         scenarios and translating them into specific, actionable policy insights with examples and evidence. 
#                         Always respond with valid JSON format.Ensure that the json's keys are in english and the values of the keys are only in Lao language."""
#                     },
#                     {"role": "user", "content": prompt}
#                 ],
#                 model=self.model,
#                 max_tokens=2000,  # Increased for more detailed responses
#                 temperature=0.6
#             )
            
#             response_text = chat_completion.choices[0].message.content
#             parsed_result = self._parse_json_response(response_text)
            
#             # Validate required fields exist
#             required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
#             for field in required_fields:
#                 if field not in parsed_result:
#                     parsed_result[field] = f"Analysis pending for {field}"
            
#             return parsed_result
            
#         except Exception as e:
#             return {
#                 "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
#                 "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
#                 "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
#                 "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
#             }




# # Utility functions for Streamlit integration
# def get_api_key():
#     """Get Groq API key from environment or user input."""
#     return os.getenv('GROQ_API_KEY', '')

# def initialize_processor():
#     """Initialize the DRI Foresight processor."""
#     api_key = get_api_key()
#     if not api_key:
#         raise ValueError("GROQ_API_KEY environment variable not set")
#     return DRIForesightProcessor(api_key)















########################################################
#08-10-2025
#just a copy of original code before starting again
#starting again after the NATO PROJECT 
#in this code not reduce the output generation text--dont confuse

import json
import os
from groq import Groq
import PyPDF2
import io
from typing import List, Dict, Any
import re
from PIL import Image
import pytesseract
from docx import Document

class DRIForesightProcessor:
    def __init__(self, groq_api_key: str):
        """Initialize the DRI Foresight processor with Groq API."""
        self.client = Groq(api_key=groq_api_key)
        self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # Using available model
        
    def extract_text_from_pdf(self, pdf_file) -> str:
        """Extract text content from uploaded PDF file."""
        try:
            pdf_reader = PyPDF2.PdfReader(io.BytesIO(pdf_file.read()))
            text = ""
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
            return text.strip()
        except Exception as e:
            return f"Error extracting PDF text: {str(e)}"

    def extract_text_from_file(self, file) -> str:
        """Extract text content from uploaded file (supports multiple formats)."""
        try:
            file_extension = file.name.split('.')[-1].lower()
            
            if file_extension == 'pdf':
                return self.extract_text_from_pdf(file)
            elif file_extension in ['txt']:
                return file.read().decode('utf-8')
            elif file_extension in ['csv']:
                # Prefer pandas if available; fallback to Python csv if not
                try:
                    import pandas as pd  # type: ignore
                    df = pd.read_csv(file)
                    return df.to_string()
                except Exception:
                    try:
                        file.seek(0)
                        import csv as _csv
                        decoded_lines = file.read().decode('utf-8', 'ignore').splitlines()
                        reader = _csv.reader(decoded_lines)
                        rows = list(reader)
                        return "\n".join([", ".join(row) for row in rows])
                    except Exception as csv_err:
                        return f"Could not read CSV file: {csv_err}"
            #newly added from this 
            elif file_extension in ['docx']:
                doc = Document(file)
                text = ""
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                return text.strip()

            elif file_extension in ['doc']:
                # For .doc files, you might need python-docx2txt
                try:
                    import docx2txt
                    return docx2txt.process(file)
                except ImportError:
                    return "docx2txt library required for .doc files"

            elif file_extension in ['pptx']:
                from pptx import Presentation
                prs = Presentation(file)
                text = ""
                for slide in prs.slides:
                    for shape in slide.shapes:
                        if hasattr(shape, "text"):
                            text += shape.text + "\n"
                return text.strip()

            elif file_extension in ['ppt']:
                # For .ppt files, you might need additional libraries like python-pptx or comtypes
                return "PowerPoint .ppt format requires additional processing"

            elif file_extension in ['jpg', 'jpeg', 'png', 'bmp', 'gif']:
                # OCR for images
                image = Image.open(file)
                text = pytesseract.image_to_string(image)
                return text.strip()
            #to this 
            else:
                # For other formats, try to read as text
                try:
                    return file.read().decode('utf-8')
                except:
                    return f"Could not extract text from {file.name}"
        except Exception as e:
            return f"Error extracting text from {file.name}: {str(e)}"
        


    def generate_domain_map(self, domain: str, document_text: str, project_name: str) -> Dict[str, Any]:
        """Generate domain map based on the selected domain and document content."""
        
        # Check if we have substantial document content
        has_document_content = document_text and len(document_text.strip()) > 100
        
        if has_document_content:
            # Prioritize document content when available
            prompt = f"""
            You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}", 
            analyze the following document content to create a comprehensive domain map. The selected domain focus "{domain}" 
            should be used as context, but the domain map should primarily reflect the content and themes found in the uploaded document.
            Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.
            

            Document Content:
            {document_text[:3000]}

            Please analyze the document content thoroughly and generate a detailed domain map with 5-7 sub-domains that reflects the actual themes and topics discussed in the document.

            For each sub-domain:
            1. Provide a detailed description (2-3 sentences) that captures the specific aspects discussed in the document
            2. Identify 8-12 specific issue areas that are either mentioned in the document or are relevant challenges within that sub-domain
            3. Base the descriptions and issue areas on the actual content rather than generic knowledge

            Format your response as a JSON object with this structure:
            {{
                "central_domain": "Main focus area based on document content",
                "description": "Detailed description derived from the document content (2-3 sentences)",
                "sub_domains": [
                    {{
                        "name": "Sub-domain name from document themes",
                        "description": "Comprehensive description based on specific document content (2-3 sentences explaining what the document reveals about this area)",
                        "relevance": "High/Medium/Low",
                        "issue_areas": [
                            "Specific issue area 1 from document context",
                            "Specific issue area 2 from document context",
                            "Specific issue area 3 from document context",
                            "Specific issue area 4 from document context",
                            "Specific issue area 5 from document context",
                            "Specific issue area 6 from document context",
                            "Specific issue area 7 from document context",
                            "Specific issue area 8 from document context"
                        ]
                    }}
                ]
            }}

            Focus on what the document actually discusses in detail rather than providing generic overviews.
            """

        else:
            # Fall back to domain-based generation when no substantial document content
            prompt = f"""
            You are an expert in foresight analysis and strategic planning. Based on the project "{project_name}" focusing on the domain "{domain}", 
            create a comprehensive and detailed domain map for this specific focus area.
            Please generate exactly 5-7 sub-domains to ensure comprehensive coverage of the domain.

            Generate detailed analysis with:
            1. 5-7 comprehensive sub-domains with detailed descriptions (2-3 sentences each)
            2. Comprehensive sub-domain descriptions that explain the specific aspects and importance of each area
            3. 8-12 specific issue areas per sub-domain that represent real challenges, opportunities, or focus points

            Format your response as a JSON object with this structure:
            {{
                "central_domain": "Main focus area title",
                "description": "Detailed description of the central domain (2-3 sentences)",
                "sub_domains": [
                    {{
                        "name": "Sub-domain name",
                        "description": "Comprehensive description explaining the specific aspects, challenges, and importance of this sub-domain (2-3 sentences)",
                        "relevance": "High/Medium/Low",
                        "issue_areas": [
                            "Specific issue area 1 with clear focus",
                            "Specific issue area 2 with clear focus",
                            "Specific issue area 3 with clear focus",
                            "Specific issue area 4 with clear focus",
                            "Specific issue area 5 with clear focus",
                            "Specific issue area 6 with clear focus",
                            "Specific issue area 7 with clear focus",
                            "Specific issue area 8 with clear focus"
                        ]
                    }}
                ]
            }}

            Provide detailed, actionable descriptions and specific issue areas rather than generic summaries.
            """
                
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system", 
                        "content": "You are an expert foresight analyst specializing in domain mapping and strategic analysis. Always respond with valid JSON format."
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=1500,
                temperature=0.7
            )
            
            response_text = chat_completion.choices[0].message.content
            return self._parse_json_response(response_text)
                
        except Exception as e:
            return {"error": f"Failed to generate domain map: {str(e)}"}
   
    # UPDATE 1: In generate_signals method - around line 120
    def generate_signals(self, domain: str, document_text: str) -> Dict[str, List[Dict]]:
        """Generate strong and weak signals based on document analysis including interview insights."""
        
        # UPDATED: Enhanced prompt to better handle comprehensive document context
        prompt = f"""
        As a foresight expert analyzing the domain "{domain}", examine the following comprehensive content which includes:
        - Domain mapping documents and project materials
        - Interview transcripts and stakeholder insights  
        - External signals and trend data
        - Any additional research materials
        
        COMPREHENSIVE ANALYSIS TASK:
        1. STRONG SIGNALS: Clear, evident trends or changes that are already happening
        2. WEAK SIGNALS: Early indicators of potential future changes that might be emerging

        COMPREHENSIVE CONTENT (ALL SOURCES COMBINED):
        {document_text[:12000]}  # Increased limit to capture more content

        ANALYSIS INSTRUCTIONS:
        - Synthesize insights across ALL uploaded content types
        - Pay special attention to interview insights for stakeholder perspectives
        - Look for patterns and convergence across different data sources
        - Include signals that emerge from cross-referencing different document types
        - Clearly indicate source context in descriptions

        Please provide 5-7 strong signals and 5-7 weak signals in the following JSON format:
        {{
            "strong_signals": [
                {{
                    "title": "Signal title",
                    "description": "Detailed description synthesizing multiple sources where relevant",
                    "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
                    "impact": "Potential impact description",
                    "evidence_strength": "Evidence level from uploaded materials"
                }}
            ],
            "weak_signals": [
                {{
                    "title": "Signal title", 
                    "description": "Detailed description synthesizing multiple sources where relevant",
                    "source": "Primary source type (documents/interviews/signals/cross-source pattern)",
                    "potential": "Future potential or implications",
                    "evidence_strength": "Evidence level from uploaded materials"
                }}
            ]
        }}

        CRITICAL REQUIREMENTS:
        - Every signal must be grounded in the provided content
        - Prioritize signals that appear across multiple source types
        - Include stakeholder perspectives from interviews where available
        - Focus on domain-specific insights
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system", 
                        "content": """You are an expert in comprehensive signal detection and trend analysis for strategic foresight. 
                        You excel at synthesizing insights from multiple data sources including documents, interviews, 
                        external signals, and research materials. You always identify patterns across different source types.
                        Always respond with valid JSON format."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=2500,  # Increased for comprehensive analysis
                temperature=0.8
            )
            
            response_text = chat_completion.choices[0].message.content
            return self._parse_json_response(response_text)
                
        except Exception as e:
            return {"error": f"Failed to generate signals: {str(e)}"}


    # UPDATE 2: In generate_steepv_analysis method - around line 180
    def generate_steepv_analysis(self, domain: str, signals_data: Dict, document_text: str) -> Dict[str, List[str]]:
        """Generate comprehensive STEEPV analysis based on signals, domain, and all available context."""
        
        # UPDATED: Better signal extraction and handling
        strong_signals = signals_data.get('strong_signals', [])
        weak_signals = signals_data.get('weak_signals', [])
        
        # Enhanced signal processing
        if isinstance(signals_data, dict) and 'raw_response' in signals_data:
            try:
                import json
                import re
                raw_response = signals_data['raw_response']
                json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_response, re.DOTALL)
                if json_match:
                    parsed_signals = json.loads(json_match.group(1))
                    strong_signals = parsed_signals.get('strong_signals', [])
                    weak_signals = parsed_signals.get('weak_signals', [])
            except:
                pass
        
        # Create comprehensive signal descriptions
        signal_descriptions = []
        for signal in strong_signals:
            if isinstance(signal, dict):
                title = signal.get('title', 'Unknown')
                desc = signal.get('description', '')
                source = signal.get('source', '')
                signal_descriptions.append(f"STRONG: {title} - {desc} (Source: {source})")
            else:
                signal_descriptions.append(f"STRONG: {signal}")
        
        for signal in weak_signals:
            if isinstance(signal, dict):
                title = signal.get('title', 'Unknown')
                desc = signal.get('description', '')
                source = signal.get('source', '')
                signal_descriptions.append(f"WEAK: {title} - {desc} (Source: {source})")
            else:
                signal_descriptions.append(f"WEAK: {signal}")
        
        # UPDATED: Enhanced prompt with comprehensive context integration
        prompt = f"""
        You are conducting a comprehensive STEEPV analysis for the domain: "{domain}"

        ANALYSIS CONTEXT:
        - Domain Focus: {domain}
        - Identified Signals: {len(signal_descriptions)} signals from multiple sources
        - Comprehensive Context: Documents, interviews, external signals, research materials

        SIGNALS TO CATEGORIZE:
        {chr(10).join(signal_descriptions[:20])}  # Increased signal limit

        FULL INTEGRATED CONTEXT (All uploaded materials combined):
        {document_text[:12000] if document_text else "No additional context provided"}

        STEEPV ANALYSIS TASK:
        Analyze ALL available information and provide 4-6 specific factors for EACH STEEPV category.
        Synthesize insights from:
        - Domain mapping documents
        - Stakeholder interviews and perspectives  
        - External signals and trends
        - Research materials and data
        - Cross-source patterns and themes

        STEEPV FRAMEWORK (Enhanced Definitions):
        - Social: Demographics, cultural shifts, social movements, community behaviors, stakeholder perspectives, social challenges from interviews
        - Technological: Digital innovations, emerging technologies, automation, AI, technical barriers and opportunities from all sources
        - Economic: Market conditions, funding landscapes, costs, financial challenges/opportunities, economic trends from interviews and documents
        - Environmental: Climate factors, sustainability requirements, environmental concerns from stakeholder input and research
        - Political: Government policies, regulatory environment, political factors, governance challenges from comprehensive analysis
        - Values: Ethical frameworks, cultural values, stakeholder beliefs, value systems from interviews and cultural analysis

        COMPREHENSIVE ANALYSIS REQUIREMENTS:
        1. Each category must contain 4-6 specific, actionable factors
        2. Factors must be grounded in the provided materials (documents + interviews + signals)
        3. Prioritize factors that appear across multiple source types
        4. Include stakeholder perspectives from interviews where relevant
        5. Make factors specific to the "{domain}" domain context
        6. Ensure comprehensive coverage - NO category left empty
        7. Focus on factors that will impact future scenario development

        REQUIRED JSON FORMAT:
        {{
            "Social": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
            "Technological": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
            "Economic": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
            "Environmental": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
            "Political": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"],
            "Values": ["factor1 (source context)", "factor2 (source context)", "factor3 (source context)", "factor4 (source context)"]
        }}

        CRITICAL: Every category must be populated with content-grounded factors from the comprehensive materials provided.
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": """You are a senior strategic foresight analyst specializing in comprehensive STEEPV methodology. 
                        You excel at synthesizing multiple data sources (documents, interviews, signals, research) into structured analysis.
                        Your expertise is in ensuring complete coverage across all STEEPV dimensions using integrated evidence.
                        Always respond with valid, complete JSON containing well-grounded factors for all categories."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=3000,  # Increased for comprehensive analysis
                temperature=0.6
            )
            
            response_text = chat_completion.choices[0].message.content
            parsed_result = self._parse_json_response(response_text)
            
            # Enhanced validation with domain-specific fallbacks
            steepv_categories = ["Social", "Technological", "Economic", "Environmental", "Political", "Values"]
            
            for category in steepv_categories:
                if category not in parsed_result or not parsed_result[category]:
                    # Domain-specific fallbacks based on comprehensive analysis
                    parsed_result[category] = [
                        f"{category} factors identified in {domain} domain analysis",
                        f"{category} implications from stakeholder interviews", 
                        f"{category} trends affecting {domain} development",
                        f"{category} considerations from uploaded materials"
                    ]
            
            return parsed_result
                    
        except Exception as e:
            # Enhanced fallback with domain context
            return {
                "Social": [f"Social dynamics in {domain} from interviews", "Community engagement patterns from analysis", "Cultural factors from comprehensive review"],
                "Technological": [f"Technology adoption in {domain}", "Digital transformation patterns", "Innovation barriers from stakeholder input"],
                "Economic": [f"Economic conditions affecting {domain}", "Funding challenges from interviews", "Cost factors from document analysis"],
                "Environmental": [f"Environmental considerations in {domain}", "Sustainability requirements from research", "Climate impacts from comprehensive analysis"],
                "Political": [f"Policy environment for {domain}", "Regulatory factors from documents", "Governance challenges from interviews"],
                "Values": [f"Value systems in {domain} context", "Ethical frameworks from analysis", "Cultural alignment from stakeholder input"]
            }

    def _parse_json_response(self, response_text: str) -> Dict:
        """Enhanced JSON parsing with better error handling."""
        import json
        import re
        
        # def clean_json_string(json_str):
        #     """Clean up common JSON formatting issues"""
        #     # Fix newlines immediately after opening quotes
        #     json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
        #     # Fix multiple newlines within strings
        #     json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
        #     # Fix single newlines within strings (but preserve paragraph structure)
        #     json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

        #     # Remove markdown fences
        #     json_str = re.sub(r"```(?:json)?", "", json_str)
        #     json_str = json_str.replace("```", "")

        #     # Remove trailing commas before } or ]
        #     json_str = re.sub(r",\s*([\]}])", r"\1", json_str)

        #     # Normalize multiple spaces/newlines
        #     json_str = re.sub(r"\s+\n", " ", json_str)
        #     json_str = re.sub(r"\n+", " ", json_str)

        #     # return json_str
        #     return json_str.strip()

        def clean_json_string(json_str):
            """Clean up common JSON formatting issues"""
            # Fix newlines immediately after opening quotes
            json_str = re.sub(r':\s*"\s*\n\s*', ': "', json_str)
            # Fix multiple newlines within strings
            json_str = re.sub(r'\n\s*\n', '\\n\\n', json_str)
            # Fix single newlines within strings
            json_str = re.sub(r'(?<!\\)(?<!\\n)\n(?!\s*[}\]",])', ' ', json_str)

            # Remove markdown fences
            json_str = re.sub(r"```(?:json)?", "", json_str)
            json_str = json_str.replace("```", "")

            # Fix missing commas between objects
            json_str = re.sub(r'\}\s*\{', '}, {', json_str)

            # Remove dangling/trailing commas
            json_str = re.sub(r",\s*([\]}])", r"\1", json_str)
            json_str = re.sub(r',\s*,+', ',', json_str)

            # Escape unescaped quotes inside values
            json_str = re.sub(
                r'(?<=:\s")([^"]*?)"(?=\s*[,}])',
                lambda m: m.group(1).replace('"', '\\"'),
                json_str
            )

            # Normalize multiple spaces/newlines
            json_str = re.sub(r"\s+\n", " ", json_str)
            json_str = re.sub(r"\n+", " ", json_str)

            return json_str.strip()

        
        try:
            # First try direct JSON parsing
            return json.loads(response_text)
        except:
            try:
                # Look for JSON in code blocks - more flexible pattern
                json_match = re.search(r'```(?:json)?\s*\n?(.*?)\n?\s*```', response_text, re.DOTALL)
                if json_match:
                    extracted_json = json_match.group(1).strip()
                    # Try to clean up formatting issues
                    cleaned_json = clean_json_string(extracted_json)
                    try:
                        return json.loads(cleaned_json)
                    except:
                        # If cleaning didn't work, try original
                        return json.loads(extracted_json)
                
                # Look for JSON-like structure without code blocks
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    extracted_json = json_match.group(0)
                    cleaned_json = clean_json_string(extracted_json)
                    try:
                        return json.loads(cleaned_json)
                    except:
                        return json.loads(extracted_json)
                    
            except Exception as e:
                print(f"JSON parsing error: {e}")
                print(f"Problematic JSON snippet: {response_text[:500]}...")
                
            # Return empty dict if all parsing fails
            return {}

    def generate_ai_suggestions(self, domain: str, signals_data: Dict) -> List[Dict]:
        """Generate AI-powered suggestions for additional signals to consider."""
        
        existing_signals = []
        for signal in signals_data.get('strong_signals', []) + signals_data.get('weak_signals', []):
            existing_signals.append(signal.get('title', ''))
        
        prompt = f"""
        Given the domain "{domain}" and the following existing signals, suggest 3-5 additional signals 
        that should be monitored for comprehensive foresight analysis.

        Existing Signals:
        {chr(10).join(existing_signals)}

        Provide suggestions for signals that:
        1. Are not already covered
        2. Are relevant to the domain
        3. Could significantly impact future scenarios
        4. Come from different perspectives or sectors

        Format as JSON:
        {{
            "suggestions": [
                {{
                    "title": "Suggested signal title",
                    "description": "Why this signal is important to monitor",
                    "category": "Strong/Weak",
                    "rationale": "Why this wasn't covered in existing signals"
                }}
            ]
        }}
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert in signal detection and strategic foresight analysis. Always respond with valid JSON format."
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=1000,
                temperature=0.8
            )
            
            response_text = chat_completion.choices[0].message.content
            parsed_response = self._parse_json_response(response_text)
            
            if 'error' in parsed_response:
                return [{"error": parsed_response['error'], "raw_response": parsed_response.get('raw_response', '')}]
            
            return parsed_response.get('suggestions', [])
                
        except Exception as e:
            return [{"error": f"Failed to generate suggestions: {str(e)}"}]

    # UPDATE 3: In generate_futures_triangle method - around line 320
    def generate_futures_triangle(self, domain: str, signals_data: Dict, steepv_data: Dict, interview_context: str = "") -> Dict[str, Any]:
        """Generate comprehensive Futures Triangle analysis based on all available data sources."""
        
        # Extract signals for context
        strong_signals = signals_data.get('strong_signals', [])
        weak_signals = signals_data.get('weak_signals', [])
        
        # Enhanced signal formatting with source context
        strong_signals_text = "\n".join([
            f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
            for signal in strong_signals
        ])
        weak_signals_text = "\n".join([
            f"- {signal.get('title', '')}: {signal.get('description', '')} (Source: {signal.get('source', 'Analysis')})" 
            for signal in weak_signals
        ])
        
        # Enhanced STEEPV formatting
        steepv_text = ""
        for category, factors in steepv_data.items():
            if factors:
                steepv_text += f"\n{category}: {', '.join(factors[:4])}"
        
        # UPDATED: Comprehensive interview and document integration
        comprehensive_context = ""
        if interview_context:
            comprehensive_context = f"""
            
            COMPREHENSIVE DOCUMENT CONTEXT (All Sources):
            {interview_context[:8000]}  # Increased limit for full context
            """
        
        # UPDATED: Enhanced prompt for comprehensive analysis with Key Dynamics
        prompt = f"""
        As a strategic foresight analyst, create a comprehensive Futures Triangle analysis for the domain "{domain}".

        INTEGRATED ANALYSIS BASE:

        STRONG SIGNALS (from comprehensive analysis):
        {strong_signals_text}

        WEAK SIGNALS (from comprehensive analysis):
        {weak_signals_text}

        STEEPV ANALYSIS SUMMARY:
        {steepv_text}
        {comprehensive_context}

        FUTURES TRIANGLE METHODOLOGY:
        Create a comprehensive analysis integrating ALL uploaded materials (domain documents, interviews, signals, research) into the three temporal forces:

        1. PULL OF THE FUTURE (Emerging Issues & Aspirations):
        - Weak Signals: Early indicators of possible change (experiments, anomalies, fringe innovations)
        - Emerging Issues: New challenges or opportunities just becoming visible
        - Visions & Aspirations: Images of preferred futures and goals pulling society forward

        2. PUSH OF THE PRESENT (Current Momentum & Drivers):
        - Current Trends: Observable patterns of change with clear direction
        - Strong Drivers: Active forces creating pressure for change

        3. WEIGHT OF HISTORY (Historical Constraints & Values):
        - Barriers & Inertia: Structures and systems resisting change + tendency to continue current patterns (e.g., laws, infrastructure gaps, financial limits, institutional routines, cultural habits, organizational momentum)
        - Values to Preserve: Elements worth preserving through change (e.g., democratic principles, cultural heritage)

        4. KEY DYNAMICS & STRATEGIC INSIGHTS:
        - Primary Tensions: Main conflicts between the three forces
        - Alignment Opportunities: Where forces work together effectively
        - Critical Uncertainties: What remains unknown or unpredictable

        COMPREHENSIVE INTEGRATION REQUIREMENTS:
        - Synthesize insights from domain documents, stakeholder interviews, external signals, and research materials
        - Ensure each force reflects evidence from multiple source types
        - Include stakeholder perspectives prominently in future visions
        - Ground all factors in the comprehensive materials provided
        - Focus on domain-specific temporal dynamics

        FORMAT YOUR RESPONSE AS JSON:
        {{
            "pull_of_future": {{
                "weak_signals": [
                    "weak signal 1 (source context)",
                    "weak signal 2 (source context)",
                    "weak signal 3 (source context)"
                ],
                "emerging_issues": [
                    "emerging issue 1 (source context)",
                    "emerging issue 2 (source context)",
                    "emerging issue 3 (source context)"
                ],
                "visions_and_aspirations": [
                    "vision/aspiration 1 (source context)",
                    "vision/aspiration 2 (source context)",
                    "vision/aspiration 3 (source context)",
                    "vision/aspiration 4 (source context)"
                ]

            }},
            "push_of_present": {{
                "current_trends": [
                    "current trend 1 (source context)",
                    "current trend 2 (source context)",
                    "current trend 3 (source context)"
                ],
                "strong_drivers": [
                    "strong driver 1 (source context)",
                    "strong driver 2 (source context)",
                    "strong driver 3 (source context)"
                ]
            }},
            "weight_of_history": {{
                "barriers_and_inertia": [
                    "barrier/inertia 1 (source context)",
                    "barrier/inertia 2 (source context)",
                    "barrier/inertia 3 (source context)",
                    "barrier/inertia 4 (source context)"
                ],
                "values_to_preserve": [
                    "value to preserve 1 (source context)",
                    "value to preserve 2 (source context)",
                    "value to preserve 3 (source context)"
                ]
            }},
            "key_dynamics": {{
                "primary_tensions": [
                    "primary tension 1 (source context)",
                    "primary tension 2 (source context)",
                    "primary tension 3 (source context)"
                ],
                "alignment_opportunities": [
                    "alignment opportunity 1 (source context)",
                    "alignment opportunity 2 (source context)",
                    "alignment opportunity 3 (source context)"
                ],
                "critical_uncertainties": [
                    "critical uncertainty 1 (source context)",
                    "critical uncertainty 2 (source context)",
                    "critical uncertainty 3 (source context)"
                ]
            }}
        }}

        Ensure each subcategory has 3-4 specific factors grounded in the comprehensive {domain} analysis.
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": """You are an expert in comprehensive futures studies and the Futures Triangle methodology. 
                        You excel at integrating multiple data sources (documents, interviews, signals, research) into temporal analysis.
                        Your expertise is in synthesizing diverse materials into coherent past-present-future dynamics with strategic insights.
                        Always respond with valid JSON format grounded in provided evidence."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=3000,  # Increased for comprehensive output including key dynamics
                temperature=0.7
            )
            
            response_text = chat_completion.choices[0].message.content
            return self._parse_json_response(response_text)
                
        except Exception as e:
            return {"error": f"Failed to generate comprehensive futures triangle: {str(e)}"}

    # UPDATE 4: Add new method for comprehensive text extraction
    def extract_comprehensive_text(self, files_dict: Dict) -> str:
        """Extract and combine text from all uploaded file types for comprehensive analysis."""
        all_text_content = []
        
        # Process domain map documents
        if files_dict.get('documents'):
            all_text_content.append("=== DOMAIN MAPPING DOCUMENTS ===")
            for file in files_dict['documents']:
                content = self.extract_text_from_file(file)
                all_text_content.append(f"Document: {file.name}")
                all_text_content.append(content)
                all_text_content.append("---")
        
        # Process interview data
        if files_dict.get('interviews'):
            all_text_content.append("=== INTERVIEW DATA & STAKEHOLDER INSIGHTS ===")
            for file in files_dict['interviews']:
                content = self.extract_text_from_file(file)
                all_text_content.append(f"Interview Source: {file.name}")
                all_text_content.append(content)
                all_text_content.append("---")
        
        # Process external signals
        if files_dict.get('signals'):
            all_text_content.append("=== EXTERNAL SIGNALS & TREND DATA ===")
            for file in files_dict['signals']:
                content = self.extract_text_from_file(file)
                all_text_content.append(f"Signal Source: {file.name}")
                all_text_content.append(content)
                all_text_content.append("---")
        
        # Process domain map file separately if exists
        if files_dict.get('domain_map'):
            all_text_content.append("=== DOMAIN MAP REFERENCE ===")
            content = self.extract_text_from_file(files_dict['domain_map'])
            all_text_content.append(f"Domain Map: {files_dict['domain_map'].name}")
            all_text_content.append(content)
            all_text_content.append("---")
        
        return "\n".join(all_text_content)
    
    def analyze_interview_data(self, domain: str, interview_text: str) -> Dict[str, Any]:
        """Analyze interview data to extract challenges, opportunities, and visions."""
        
        prompt = f"""
        As an expert analyst, analyze the following interview data for the domain "{domain}".
        
        Interview Content:
        {interview_text[:4000]}  # Limit content to avoid token limits
        
        Extract and categorize the key insights into:
        1. Top Challenges - main obstacles, problems, or difficulties mentioned
        2. Key Opportunities - opportunities, potential solutions, or positive developments
        3. Future Visions - aspirations, goals, or desired future states mentioned
        
        Format your response as JSON:
        {{
            "challenges": [
                "challenge 1",
                "challenge 2",
                "challenge 3",
                "challenge 4"
            ],
            "opportunities": [
                "opportunity 1",
                "opportunity 2", 
                "opportunity 3",
                "opportunity 4"
            ],
            "visions": [
                "vision 1",
                "vision 2",
                "vision 3",
                "vision 4"
            ]
        }}
        
        Focus on the most significant and frequently mentioned themes.
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert qualitative data analyst specializing in interview analysis and thematic extraction. Always respond with valid JSON format."
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=1500,
                temperature=0.6
            )
            
            response_text = chat_completion.choices[0].message.content
            return self._parse_json_response(response_text)
                
        except Exception as e:
            return {"error": f"Failed to analyze interview data: {str(e)}"}

    def generate_futures_triangle_2_0(self, domain: str, phase1_data: Dict, phase2_data: Dict, comprehensive_context: str = "") -> Dict[str, Any]:
            """Generate enhanced Futures Triangle 2.0 analysis for Phase 3 scenario planning."""
            
            # Extract Phase 2 data
            signals_data = phase2_data.get('signals_data', {})
            steepv_data = phase2_data.get('steepv_data', {})
            basic_triangle = phase2_data.get('futures_triangle_data', {})
            
            # Format signals context
            strong_signals = signals_data.get('strong_signals', [])
            weak_signals = signals_data.get('weak_signals', [])
            
            signals_context = ""
            if strong_signals:
                signals_context += "STRONG SIGNALS:\n" + "\n".join([
                    f"- {s.get('title', '')}: {s.get('description', '')}" for s in strong_signals
                ])
            if weak_signals:
                signals_context += "\n\nWEAK SIGNALS:\n" + "\n".join([
                    f"- {s.get('title', '')}: {s.get('description', '')}" for s in weak_signals
                ])
            
            # Format STEEPV context
            steepv_context = ""
            for category, factors in steepv_data.items():
                if factors:
                    steepv_context += f"\n{category.upper()}: {', '.join(factors[:4])}"
            
            # Enhanced prompt for Futures Triangle 2.0
            prompt = f"""
            As a strategic foresight expert, create a comprehensive Futures Triangle 2.0 Analysis for "{domain}" that will directly feed into scenario planning.

            CONTEXT FROM PREVIOUS PHASES:
            Project: {phase1_data.get('project_name', domain)}
            Domain Focus: {domain}
            
            PHASE 2 ANALYSIS RESULTS:
            {signals_context}
            
            STEEPV ANALYSIS:
            {steepv_context}
            
            COMPREHENSIVE DOCUMENT CONTEXT:
            {comprehensive_context[:8000]}
            
            FUTURES TRIANGLE 2.0 METHODOLOGY:
            This enhanced version extracts three key elements for scenario building:

            1. **DRIVERS** (Enhanced from Push of Present + STEEPV):
            - Major forces creating change pressure
            - Rate each by impact level (High/Medium/Low) and certainty (High/Medium/Low)
            - These will be "bent" to different archetypes in scenario planning

            2. **UNCERTAINTIES** (Critical unknowns from analysis):
            - High-impact variables that could go multiple directions
            - Key pivot points that determine scenario outcomes
            - Wild cards and game-changing possibilities

            3. **NARRATIVES** (Stories shaping the domain):
            - Dominant mental models currently operating
            - Emerging alternative narratives from weak signals
            - Competing storylines about the future

            ENHANCED TRIANGLE STRUCTURE:
            Also provide the expanded traditional triangle with Key Dynamics for strategic insights.

            FORMAT AS JSON:
            {{
                "drivers": [
                    {{
                        "id": "D1",
                        "name": "Driver name",
                        "description": "Detailed description of the driving force",
                        "category": "Technological/Economic/Social/Environmental/Political/Values",
                        "impact_level": "High/Medium/Low",
                        "certainty": "High/Medium/Low",
                        "current_trajectory": "Current direction and momentum",
                        "source_evidence": "Evidence from uploaded materials"
                    }}
                ],
                "uncertainties": [
                    {{
                        "id": "U1",
                        "name": "Uncertainty name",
                        "description": "What is uncertain and why it matters",
                        "key_variables": ["Variable 1", "Variable 2", "Variable 3"],
                        "possible_outcomes": ["Outcome A", "Outcome B", "Outcome C"],
                        "impact_on_scenarios": "How this shapes different futures",
                        "source_evidence": "Evidence from analysis"
                    }}
                ],
                "narratives": [
                    {{
                        "id": "N1",
                        "type": "Dominant/Emerging/Alternative",
                        "name": "Narrative name",
                        "description": "The story or mental model",
                        "supporting_evidence": ["Evidence 1", "Evidence 2"],
                        "influence_areas": ["Area 1", "Area 2"],
                        "alternative_versions": ["Alternative view 1", "Alternative view 2"],
                        "source_context": "Where this narrative appears in materials"
                    }}
                ],
                "enhanced_triangle": {{
                    "pull_of_future": {{
                        "weak_signals": ["signal 1", "signal 2", "signal 3"],
                        "emerging_issues": ["issue 1", "issue 2", "issue 3"],
                        "visions_aspirations": ["vision 1", "vision 2", "vision 3"]
                    }},
                    "push_of_present": {{
                        "trends": ["trend 1", "trend 2", "trend 3"],
                        "drivers": ["driver 1", "driver 2", "driver 3"]
                    }},
                    "weight_of_history": {{
                        "barriers_inertia": ["barrier 1", "barrier 2", "barrier 3"],
                        "values_to_maintain": ["value 1", "value 2", "value 3"]
                    }},
                    "key_dynamics": {{
                        "primary_tensions": ["tension 1", "tension 2", "tension 3"],
                        "alignment_opportunities": ["opportunity 1", "opportunity 2"],
                        "critical_uncertainties": ["uncertainty 1", "uncertainty 2"]
                    }}
                }},
                "strategic_insights": {{
                    "leverage_points": ["point 1", "point 2", "point 3"],
                    "signals_to_monitor": ["signal 1", "signal 2"],
                    "values_to_protect": ["value 1", "value 2"]
                }}
            }}

            CRITICAL REQUIREMENTS:
            - Extract 4-6 DRIVERS that will dominate the baseline scenario
            - Identify 3-5 UNCERTAINTIES that are pivot points for different outcomes  
            - Capture 3-4 NARRATIVES (mix of dominant and emerging) that frame stakeholder thinking
            - Ground all elements in the provided evidence from Phase 1 & 2
            - Ensure drivers/uncertainties/narratives can be "bent" to collapse/new equilibrium/transformation archetypes
            """
            
            try:
                chat_completion = self.client.chat.completions.create(
                    messages=[
                        {
                            "role": "system",
                            "content": """You are a senior strategic foresight analyst specializing in Futures Triangle 2.0 methodology 
                            for scenario planning. You excel at extracting manipulable elements (drivers, uncertainties, narratives) 
                            from comprehensive foresight analysis that can be adapted across different scenario archetypes.
                            Always respond with valid, complete JSON."""
                        },
                        {"role": "user", "content": prompt}
                    ],
                    model=self.model,
                    max_tokens=4000,
                    temperature=0.7
                )
                
                response_text = chat_completion.choices[0].message.content
                parsed_result = self._parse_json_response(response_text)

                
                # Validate required sections exist
                required_sections = ['drivers', 'uncertainties', 'narratives', 'enhanced_triangle']
                for section in required_sections:
                    if section not in parsed_result:
                        parsed_result[section] = []
                
                return parsed_result
                    
            except Exception as e:
                return {"error": f"Failed to generate Futures Triangle 2.0: {str(e)}"}

#new
    def generate_baseline_scenario(self, domain: str, triangle_2_0_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
        """Generate baseline scenario dominated by Push of Present and key Drivers (3-4 paragraphs)."""
        
        # Extract key elements from Futures Triangle 2.0
        drivers = triangle_2_0_data.get('drivers', [])
        enhanced_triangle = triangle_2_0_data.get('enhanced_triangle', {})
        push_of_present = enhanced_triangle.get('push_of_present', {})
        
        # Format drivers context - focus on high certainty/high impact
        high_certainty_drivers = [d for d in drivers if d.get('certainty', '').lower() in ['high', 'medium']]
        drivers_context = ""
        for driver in high_certainty_drivers[:5]:  # Limit to top 5 drivers
            drivers_context += f"- {driver.get('name', '')}: {driver.get('description', '')} (Impact: {driver.get('impact_level', '')}, Certainty: {driver.get('certainty', '')})\n"
        
        # Format Push of Present context
        trends = push_of_present.get('trends', [])
        existing_drivers = push_of_present.get('drivers', [])
        push_context = ""
        if trends:
            push_context += "Current Trends: " + ", ".join(trends[:4])
        if existing_drivers:
            push_context += "\nExisting Momentum: " + ", ".join(existing_drivers[:4])
        
        # Project context
        project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
        prompt = f"""
        You are a strategic foresight expert creating a Baseline Scenario for "{domain}".

        PROJECT CONTEXT:
        Project: {project_name}
        Domain: {domain}
        
        BASELINE SCENARIO DEFINITION:
        The baseline represents the "business-as-usual" future - what happens if current momentum continues without major surprises, disruptions, or transformative changes. This is dominated by:
        1. **Push of the Present**: Current trends and momentum
        2. **Key Drivers**: High-certainty forces shaping the future
        
        PUSH OF THE PRESENT (Current Momentum):
        {push_context}
        
        KEY DRIVERS (High Certainty Forces):
        {drivers_context}
        
        BASELINE SCENARIO REQUIREMENTS:
        
        **Structure (3-4 paragraphs, 400-450 words total):**
        
        **Paragraph 1 - Present Momentum (100-150 words):**
        - Describe the current state and ongoing trends
        - Establish the "Push of the Present" foundation
        - Set the context for continuation rather than transformation
        
        **Paragraph 2 - Primary Drivers (100-140 words):**
        - Focus on the highest certainty, highest impact drivers
        - Explain how these forces reinforce current trajectories
        - Show momentum building from existing patterns
        
        **Paragraph 3 - Secondary Drivers & Evolution (100-130 words):**
        - Include additional drivers that support the baseline path
        - Show how the domain evolves within existing frameworks
        - Demonstrate gradual rather than revolutionary change
        
        **Paragraph 4 - Baseline Future State (100-120 words):**
        - Synthesize into a coherent "most likely" future
        - Emphasize continuation and extension of current trends
        - Position as the foundation before exploring alternatives
        
        **Writing Style:**
        - Narrative and story-like, but grounded in evidence
        - Confident but not overly optimistic
        - Focus on "what's most likely" rather than "what's possible"
        - Use concrete details from the domain context
        
        **Critical Focus:**
        - This is NOT about transformation or disruption
        - This IS about logical extension of current momentum
        - Emphasize high-certainty, predictable developments
        - Set up the contrast for later alternative scenarios

        **CRITICAL FORMATTING RULES:**
        - Return valid JSON with no markdown code blocks
        - The scenario_text must be a single continuous string
        - Replace all actual newlines in text with \\n escape sequences
        - Do NOT put line breaks immediately after opening quotes
        
        Format your response as JSON:
        {{
            "scenario_title": "Descriptive title for the baseline scenario",
            "timeframe": "2025-2030" or appropriate timeframe,
            "scenario_text": "Paragraph 1 content here.\\n\\nParagraph 2 content here.\\n\\nParagraph 3 content here.",
            "key_assumptions": ["assumption 1", "assumption 2", "assumption 3"],
            "dominant_drivers": ["driver 1", "driver 2", "driver 3"],
            "scenario_type": "Baseline/Continuation"
        }}
        
        Ensure the scenario text is exactly 3-4 paragraphs with natural narrative flow.
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": """You are a senior strategic foresight analyst specializing in baseline scenario development. 
                        You excel at creating compelling "business-as-usual" narratives that extrapolate current trends and 
                        high-certainty drivers into plausible continuation scenarios. Your scenarios are grounded, realistic, 
                        and set the foundation for exploring alternative futures. Always respond with valid JSON."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=1500,
                temperature=0.6  # Lower temperature for more consistent baseline scenarios
            )
            
            response_text = chat_completion.choices[0].message.content
            parsed_result = self._parse_json_response(response_text)

            
            # Validate required fields
            required_fields = ['scenario_title', 'scenario_text', 'key_assumptions', 'scenario_type']
            for field in required_fields:
                if field not in parsed_result:
                    parsed_result[field] = f"Generated {field} for {domain}"
                            
            # Ensure scenario_text exists and is reasonable length
            if not parsed_result.get('scenario_text') or len(parsed_result['scenario_text']) < 100:
                parsed_result['scenario_text'] = f"Baseline scenario for {domain} continues current trends with gradual evolution driven by existing momentum and high-certainty factors."
            
            return parsed_result
                
        except Exception as e:
            return {"error": f"Failed to generate baseline scenario: {str(e)}"}
            
    def generate_driver_outcomes(self, domain: str, triangle_2_0_data: Dict, baseline_data: Dict, phase1_data: Dict = None) -> Dict[str, Any]:
        """Generate Driver Outcomes by 'bending' each driver, uncertainty, and narrative to archetypal scenarios."""
        
        # Extract elements from Futures Triangle 2.0
        drivers = triangle_2_0_data.get('drivers', [])
        uncertainties = triangle_2_0_data.get('uncertainties', [])
        narratives = triangle_2_0_data.get('narratives', [])
        
        # Project context
        project_name = phase1_data.get('project_name', domain) if phase1_data else domain
        
        # Format baseline context
        baseline_context = f"""
        BASELINE SCENARIO: {baseline_data.get('scenario_title', '')}
        Timeframe: {baseline_data.get('timeframe', '2025-2030')}
        Key Assumptions: {', '.join(baseline_data.get('key_assumptions', []))}
        """
        
        prompt = f"""
        You are a strategic foresight expert creating Driver Outcomes for "{domain}" by "bending" elements from Futures Triangle 2.0 analysis into different archetypal scenarios.

        PROJECT CONTEXT:
        Project: {project_name}
        Domain: {domain}
        
        {baseline_context}
        
        DRIVER OUTCOMES METHODOLOGY:
        Take each Driver, Uncertainty, and Narrative and "bend" them into 3 archetypal futures:
        
        1. **COLLAPSE/DECLINE** - Systems break down, failures cascade, things get worse
        2. **NEW EQUILIBRIUM** - Adaptive change, new stable patterns, reformed systems  
        3. **TRANSFORMATION** - Breakthrough innovation, paradigm shifts, fundamental change
        
        ELEMENTS TO BEND:
        
        DRIVERS (Major Forces):
        {chr(10).join([f"- {d.get('name', '')}: {d.get('description', '')} (Impact: {d.get('impact_level', '')}, Certainty: {d.get('certainty', '')})" for d in drivers[:6]])}
        
        UNCERTAINTIES (Pivot Points):
        {chr(10).join([f"- {u.get('name', '')}: {u.get('description', '')}" for u in uncertainties[:5]])}
        
        NARRATIVES (Stories):
        {chr(10).join([f"- {n.get('name', '')} ({n.get('type', '')}): {n.get('description', '')}" for n in narratives[:4]])}
        
        ARCHETYPE DEFINITIONS:
        
        **COLLAPSE/DECLINE:**
        - Systems fail, break down, or regress
        - Negative feedback loops dominate
        - Resources become scarce, trust erodes
        - Institutions lose effectiveness
        - Focus: "What goes wrong?"
        
        **NEW EQUILIBRIUM:**
        - Adaptive responses create stability
        - Systems reform and find balance
        - Gradual improvement within existing frameworks
        - Incremental innovation and adjustment
        - Focus: "How do we adapt?"
        
        **TRANSFORMATION:**
        - Breakthrough innovations emerge
        - Fundamental paradigm shifts occur
        - New systems replace old ones
        - Exponential positive change
        - Focus: "What becomes possible?"
        
        OUTCOME REQUIREMENTS:
        - Each element gets 3 outcomes (one per archetype)
        - Outcomes should be 2-3 sentences each
        - Stay grounded in the domain context
        - Show how the same force creates different futures
        - Make outcomes specific and plausible within each archetype
        
        Format as JSON:
        {{
            "driver_outcomes": [
                {{
                    "driver_id": "D1",
                    "driver_name": "Driver name from Triangle 2.0",
                    "baseline_trajectory": "How this plays out in baseline",
                    "outcomes": [
                        {{
                            "archetype": "Collapse/Decline",
                            "outcome_text": "2-3 sentence description of how this driver manifests in a collapse scenario",
                            "key_impacts": ["impact 1", "impact 2", "impact 3"]
                        }},
                        {{
                            "archetype": "New Equilibrium", 
                            "outcome_text": "2-3 sentence description of how this driver manifests in adaptive change",
                            "key_impacts": ["impact 1", "impact 2", "impact 3"]
                        }},
                        {{
                            "archetype": "Transformation",
                            "outcome_text": "2-3 sentence description of how this driver creates breakthrough change", 
                            "key_impacts": ["impact 1", "impact 2", "impact 3"]
                        }}
                    ]
                }}
            ],
            "uncertainty_outcomes": [
                {{
                    "uncertainty_id": "U1",
                    "uncertainty_name": "Uncertainty name from Triangle 2.0",
                    "key_variables": ["var1", "var2"],
                    "outcomes": [
                        {{
                            "archetype": "Collapse/Decline",
                            "outcome_text": "How this uncertainty resolves in a collapse scenario",
                            "resolution_direction": "Which way the uncertainty tips"
                        }},
                        {{
                            "archetype": "New Equilibrium",
                            "outcome_text": "How this uncertainty resolves in adaptive change",
                            "resolution_direction": "Which way the uncertainty tips"
                        }},
                        {{
                            "archetype": "Transformation", 
                            "outcome_text": "How this uncertainty resolves in transformation",
                            "resolution_direction": "Which way the uncertainty tips"
                        }}
                    ]
                }}
            ],
            "narrative_outcomes": [
                {{
                    "narrative_id": "N1",
                    "narrative_name": "Narrative name from Triangle 2.0",
                    "narrative_type": "Dominant/Emerging/Alternative",
                    "outcomes": [
                        {{
                            "archetype": "Collapse/Decline",
                            "outcome_text": "How this narrative evolves in collapse",
                            "narrative_shift": "What story dominates"
                        }},
                        {{
                            "archetype": "New Equilibrium",
                            "outcome_text": "How this narrative evolves in adaptation", 
                            "narrative_shift": "What story dominates"
                        }},
                        {{
                            "archetype": "Transformation",
                            "outcome_text": "How this narrative evolves in transformation",
                            "narrative_shift": "What story dominates"
                        }}
                    ]
                }}
            ],
            "cross_archetype_insights": {{
                "collapse_patterns": ["Common themes across collapse outcomes"],
                "equilibrium_patterns": ["Common themes across equilibrium outcomes"], 
                "transformation_patterns": ["Common themes across transformation outcomes"],
                "leverage_points": ["Key intervention points that could shift outcomes between archetypes"]
            }}
        }}
        
        CRITICAL: Ensure each element from Triangle 2.0 is "bent" to show how the SAME force creates different futures under different conditions.
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system", 
                        "content": """You are a senior strategic foresight analyst specializing in archetypal scenario development. 
                        You excel at taking identified drivers, uncertainties, and narratives and showing how they manifest 
                        differently across collapse, equilibrium, and transformation archetypes. You create plausible, 
                        specific outcomes that demonstrate how the same forces can lead to very different futures. 
                        Always respond with valid, complete JSON."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=4000,
                temperature=0.7
            )
            
            response_text = chat_completion.choices[0].message.content
            
            # Clean response - remove any markdown code blocks
            response_text = response_text.strip()
            if response_text.startswith('```json'):
                response_text = response_text.replace('```json', '').replace('```', '').strip()
            elif response_text.startswith('```'):
                response_text = response_text.replace('```', '').strip()
                
            parsed_result = self._parse_json_response(response_text)
            
            # Validate required sections exist
            required_sections = ['driver_outcomes', 'uncertainty_outcomes', 'narrative_outcomes']
            for section in required_sections:
                if section not in parsed_result:
                    parsed_result[section] = []
            
            # Ensure we have cross-archetype insights
            if 'cross_archetype_insights' not in parsed_result:
                parsed_result['cross_archetype_insights'] = {
                    'collapse_patterns': ['System failures', 'Resource scarcity', 'Trust erosion'],
                    'equilibrium_patterns': ['Adaptive responses', 'Gradual reform', 'Balanced solutions'],
                    'transformation_patterns': ['Breakthrough innovation', 'Paradigm shifts', 'Exponential change'],
                    'leverage_points': ['Policy interventions', 'Technology adoption', 'Cultural shifts']
                }
            
            return parsed_result
            
        except Exception as e:
            return {"error": f"Failed to generate driver outcomes: {str(e)}"}


#much better ----solved No more lazy #2 titles
    def generate_alternative_scenarios(self, domain: str, selected_archetypes: Dict, baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None) -> Dict[str, Any]:
        """Generate alternative scenarios based on selected archetypes."""
        
        # Archetype definitions
        archetype_definitions = {
            "Collapse": "System breakdown, failures cascade, institutions lose effectiveness, negative feedback loops dominate, resources become scarce, trust erodes",
            "New Equilibrium": "Adaptive responses create stability, systems reform and find balance, gradual improvement within existing frameworks, incremental innovation and adjustment", 
            "Transformation": "Breakthrough innovations emerge, fundamental paradigm shifts occur, new systems replace old ones, exponential positive change"
        }
        
        scenarios = []
        
        for archetype, count in selected_archetypes.items():
            if count > 0:
                for i in range(count):
                    scenario = self._generate_single_scenario(
                        domain=domain,
                        archetype=archetype, 
                        archetype_definition=archetype_definitions.get(archetype, ""),
                        baseline_data=baseline_data,
                        driver_outcomes=driver_outcomes,
                        triangle_2_0_data=triangle_2_0_data,
                        scenario_number=i+1
                    )
                    scenarios.append(scenario)
        
        return {"scenarios": scenarios}

    def _generate_single_scenario(self, domain: str, archetype: str, archetype_definition: str, 
                                baseline_data: Dict, driver_outcomes: Dict, triangle_2_0_data: Dict = None, 
                                scenario_number: int = 1) -> Dict:
        """Generate a single scenario narrative with improved diversity."""
        
        # Extract key context
        baseline_text = baseline_data.get('scenario_text', '')
        baseline_title = baseline_data.get('scenario_title', '')
        
        # Get driver outcomes for this archetype
        relevant_outcomes = []
        for driver in driver_outcomes.get('driver_outcomes', []):
            for outcome in driver.get('outcomes', []):
                outcome_archetype = outcome.get('archetype', '').lower().replace(' ', '')
                target_archetype = archetype.lower().replace(' ', '')
                if target_archetype in outcome_archetype or outcome_archetype in target_archetype:
                    relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")
        
        # If no relevant outcomes found, get first few driver outcomes
        if not relevant_outcomes:
            for driver in driver_outcomes.get('driver_outcomes', [])[:3]:
                for outcome in driver.get('outcomes', [])[:1]:
                    relevant_outcomes.append(f" {driver.get('driver_name', '')}: {outcome.get('outcome_text', '')}")

        # Create scenario-specific focus areas to ensure diversity
        focus_areas = {
            "Collapse": [
                "financial system breakdown and economic collapse",
                "institutional failure and governance breakdown", 
                "technological obsolescence and infrastructure decay",
                "social fragmentation and cultural alienation"
            ],
            "New Equilibrium": [
                "sustainable development and environmental stewardship",
                "inclusive governance and democratic reforms",
                "regional cooperation and diplomatic balance",
                "tradition preservation with selective innovation"
            ],
            "Transformation": [
                "breakthrough technological revolution and digitization",
                "global democratization and grassroots expansion",
                "radical business model innovation and new economics",
                "social impact revolution and cultural transformation"
            ]
        }

        unique_drivers_per_scenario = {
            "Collapse": [
                "sponsorship withdrawal, broadcasting revenue collapse, financial mismanagement",
                "regulatory conflicts, visa restrictions, political tensions between nations",
                "aging infrastructure, resistance to new technology, equipment failures",
                "generational disconnect, competing entertainment, loss of cultural relevance"
            ],
            "New Equilibrium": [
                "carbon-neutral stadiums, renewable energy adoption, environmental regulations",
                "stakeholder representation, transparent governance, democratic decision-making",
                "cross-border partnerships, measured expansion, diplomatic cricket initiatives", 
                "heritage conservation, selective tech integration, cultural preservation"
            ],
            "Transformation": [
                "AI analytics, VR experiences, blockchain ticketing, digital fan engagement",
                "non-traditional markets, grassroots accessibility, global talent mobility",
                "subscription models, fan ownership, cryptocurrency integration, direct investment",
                "gender equality initiatives, community development, social change catalyst"
            ]
        }

        # Select focus and unique drivers based on scenario number
        focus_list = focus_areas.get(archetype, ["general system changes"])
        selected_focus = focus_list[(scenario_number - 1) % len(focus_list)]

        drivers_list = unique_drivers_per_scenario.get(archetype, ["general drivers"])
        unique_drivers = drivers_list[(scenario_number - 1) % len(drivers_list)]

        prompt = f"""Create scenario #{scenario_number} for {archetype} archetype in {domain}.

        ARCHETYPE: {archetype} - {archetype_definition}
        UNIQUE FOCUS: This scenario must focus EXCLUSIVELY on {selected_focus}
        UNIQUE DRIVERS TO EMPHASIZE: {unique_drivers}

        BASELINE CONTEXT:
        {baseline_text[:400]}

        REQUIRED DRIVER OUTCOMES TO INTEGRATE:
        {chr(10).join(relevant_outcomes[:4])}

        CRITICAL DIVERSITY REQUIREMENTS:
        - This scenario must be COMPLETELY DIFFERENT from other {archetype} scenarios
        - Focus ONLY on {selected_focus} - do not mix with other focus areas
        - Emphasize these unique drivers: {unique_drivers}
        - Create a unique storyline with different triggers, progression, and outcomes
        - The scenario title must be creative and reflect {selected_focus} (no generic numbering)
        - Probability assessment must vary and be justified
        - All factors, assumptions, and indicators must be unique to this specific focus

        STRUCTURE (EXACTLY 4 paragraphs, 300-400 words total):
        1. Initial conditions specific to {selected_focus} (2025-2026) - 75-100 words
        2. Key developments driven by {unique_drivers} (2027-2028) - 75-100 words
        3. Full manifestation of {selected_focus} (2029-2030) - 75-100 words
        4. Final system state shaped by {selected_focus} (2030) - 75-100 words

        **CRITICAL FORMATTING RULES:**
        - Return valid JSON with no markdown code blocks
        - The scenario_text must be a single continuous string
        - Replace all actual newlines in text with \\n\\n escape sequences
        - Do NOT put line breaks immediately after opening quotes
        - Keep total word count between 300-400 words
        - Each paragraph should be 75-100 words maximum

        Return ONLY valid JSON:
        {{
            "scenario_title": "Creative title reflecting {selected_focus} (no numbering)",
            "archetype": "{archetype}",
            "timeframe": "2025-2030", 
            "scenario_text": "Four paragraphs separated by \\n\\n, each 75-100 words, total 300-400 words...",
            "key_factors": ["factor specific to {selected_focus}", "factor related to {unique_drivers}", "factor 3", "factor 4", "factor 5"],
            "critical_assumptions": ["assumption about {unique_drivers}", "assumption about {selected_focus}", "third unique assumption"],
            "probability_assessment": "Low/Medium/High - [JUSTIFY WHY based on {unique_drivers}]",
            "key_indicators": ["early warning for {unique_drivers}", "indicator for {selected_focus}", "third specific indicator"]
        }}

        ENSURE: Everything must be unique to {selected_focus} and driven by {unique_drivers}. No overlap with other scenarios."""

        try:
            response = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system", 
                        "content": f"""Create a completely unique {archetype} scenario focused ONLY on {selected_focus}. 
                        Emphasize these unique drivers: {unique_drivers}. Generate a creative, metaphorical title (no numbering). 
                        Vary probability assessment (Low/Medium/High) with detailed justification. Make all factors, assumptions, 
                        and indicators scenario-specific. Always respond with valid JSON only. Never use markdown code blocks."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=1200,  # Reduced to encourage conciseness
                temperature=0.7,  # Reduced for better structure adherence
                # Remove response_format since you're handling JSON parsing manually
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # CRITICAL FIX: Use your robust parser instead of json.loads()
            parsed_result = self._parse_json_response(response_text)
            
            # Check if parsing failed (empty dict or error)
            if not parsed_result or parsed_result.get('error'):
                raise ValueError("JSON parsing failed")
            
            # Validate and ensure required fields
            if not parsed_result.get('scenario_text') or len(parsed_result.get('scenario_text', '')) < 200:
                raise ValueError("Scenario text too short or missing")
            
            # Keep the AI-generated title as-is (no numbering fallback)
            title = parsed_result.get('scenario_title', f"Untitled {archetype} Scenario")
            parsed_result['scenario_title'] = title
                
            # Set proper defaults
            parsed_result.setdefault('archetype', archetype)
            parsed_result.setdefault('timeframe', '2025-2030')
            parsed_result.setdefault('key_factors', [])
            parsed_result.setdefault('critical_assumptions', [])
            parsed_result.setdefault('probability_assessment', 'Medium')
            parsed_result.setdefault('key_indicators', [])
            
            return parsed_result
            
        except Exception as e:
            print(f"Scenario generation error: {str(e)}")
            return self._generate_simple_scenario(domain, archetype, scenario_number, selected_focus)

    def _generate_simple_scenario(self, domain: str, archetype: str, scenario_number: int, focus_area: str = "") -> Dict:
        """Fallback simple scenario generation with focus area."""
        
        simple_prompt = f"""Create {archetype} scenario #{scenario_number} for {domain} (2025-2030).

    Focus on: {focus_area or archetype.lower()}

    Write 3 paragraphs showing progression over time.

    Return JSON:
    {{
        "scenario_title": "Unique title for scenario #{scenario_number}",
        "archetype": "{archetype}",
        "timeframe": "2025-2030",
        "scenario_text": "3 paragraph narrative...",
        "key_factors": ["factor1", "factor2", "factor3"],
        "critical_assumptions": ["assumption1", "assumption2"], 
        "probability_assessment": "Low/Medium/High",
        "key_indicators": ["indicator1", "indicator2"]
    }}"""
        
        try:
            response = self.client.chat.completions.create(
                messages=[
                    {"role": "system", "content": f"Create unique scenario focusing on {focus_area}. Generate creative title (no numbering). Vary probability assessment with justification."},
                    {"role": "user", "content": simple_prompt}
                ],
                model=self.model,
                max_tokens=1500,
                temperature=0.9,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content.strip())
            
            # Ensure unique title
            title = result.get('scenario_title', f"{archetype} Scenario {scenario_number}")
            if scenario_number > 1:
                title = f"{title} #{scenario_number}"
            result['scenario_title'] = title
            
            return result
            
        except Exception as e:
            print(f"Simple scenario generation failed: {str(e)}")
            return {
                "scenario_title": f"{archetype} Focus: {focus_area} #{scenario_number}",
                "archetype": archetype,
                "timeframe": "2025-2030",
                "scenario_text": f"This {archetype.lower()} scenario explores how {domain} evolves through {focus_area} from 2025 to 2030. Early indicators emerge by 2026, with key developments unfolding through 2027-2028. By 2030, the {archetype.lower()} pattern is fully established, demonstrating the impact of {focus_area} on the system's evolution.",
                "key_factors": [f"{focus_area}", f"{domain} dynamics", "System responses"],
                "critical_assumptions": [f"{focus_area} continues as expected", "Key stakeholders adapt accordingly"],
                "probability_assessment": ["Low", "Medium", "High"][scenario_number % 3],
                "key_indicators": [f"Signs of {focus_area}", "System metric changes"]
            }



    # Add this method to your DRIForesightProcessor class in main.py

    def run_wind_tunnel_analysis(self, domain: str, policy_text: str, phase3_scenarios: Dict, project_name: str = "") -> Dict[str, Any]:
        """
        Run Wind Tunnel analysis - stress test policy against all Phase 3 scenarios.
        
        Args:
            domain: The project domain
            policy_text: Extracted text from uploaded policy documents
            phase3_scenarios: Dict containing baseline and alternative scenarios from Phase 3
            project_name: Optional project name for context
        
        Returns:
            Dict with analysis for each scenario and cross-scenario insights
        """
        
        # Extract scenarios from Phase 3 data
        baseline_scenario = phase3_scenarios.get('baseline_scenario', {})
        alternative_scenarios = phase3_scenarios.get('alternative_scenarios', {}).get('scenarios', [])
        
        # Organize scenarios by archetype
        scenarios_to_analyze = {
            'baseline': {
                'title': baseline_scenario.get('scenario_title', 'Baseline Scenario'),
                'text': baseline_scenario.get('scenario_text', ''),
                'type': 'Baseline'
            }
        }
        
        # Add alternative scenarios
        for scenario in alternative_scenarios:
            archetype = scenario.get('archetype', '').lower().replace(' ', '_')
            if archetype == 'collapse':
                scenarios_to_analyze['collapse'] = scenario
            elif archetype == 'new_equilibrium':
                scenarios_to_analyze['equilibrium'] = scenario
            elif archetype == 'transformation':
                scenarios_to_analyze['transformation'] = scenario
        
        # Analyze each scenario
        scenario_analyses = {}
        
        for scenario_key, scenario_data in scenarios_to_analyze.items():
            analysis = self._analyze_policy_against_scenario(
                domain=domain,
                policy_text=policy_text,
                scenario_data=scenario_data,
                project_name=project_name
            )
            scenario_analyses[scenario_key] = analysis
        
        # Generate cross-scenario insights
        cross_scenario_analysis = self._generate_cross_scenario_insights(
            domain=domain,
            policy_text=policy_text,
            scenario_analyses=scenario_analyses,
            project_name=project_name
        )
        
        return {
            "scenarios": scenario_analyses,
            "cross_scenario": cross_scenario_analysis
        }

    def _analyze_policy_against_scenario(self, domain: str, policy_text: str, scenario_data: Dict, project_name: str = "") -> Dict[str, str]:
        """Analyze policy against a single scenario using VIABILITY-PROCESS-CAPABILITIES-ADAPTATIONS framework."""
        
        scenario_title = scenario_data.get('scenario_title', scenario_data.get('title', 'Scenario'))
        scenario_text = scenario_data.get('scenario_text', scenario_data.get('text', ''))
        scenario_type = scenario_data.get('archetype', scenario_data.get('type', 'Unknown'))
        
        prompt = f"""
        You are performing a **Wind Tunnel stress test** of the policy document for "{project_name}" in the "{domain}" domain.
        
        POLICY TO ANALYZE:
        {policy_text[:4000]}

        FUTURE SCENARIO TO TEST AGAINST:
        Title: {scenario_title}
        Type: {scenario_type}
        Description: {scenario_text[:2000]}

        WIND TUNNEL EVALUATION FRAMEWORK:
        Systematically evaluate this policy against the given scenario using four dimensions:

        ### **1. VIABILITY** (Does the policy achieve its objectives?)
        - Does the policy achieve its stated objectives in this future scenario?
        - What aspects of the policy succeed or fail and why?
        - Are the underlying assumptions still valid?
        - What unintended consequences emerge?

        ### **2. PROCESS** (How does implementation change?)
        - How does the implementation process change in this scenario?
        - What new stakeholders or power dynamics emerge?
        - Are the planned timelines and milestones still realistic?
        - What governance or decision-making challenges arise?

        ### **3. CAPABILITIES** (Do we have what we need?)
        - Do we have the necessary human resources in this future?
        - Are required technologies and infrastructure available?
        - Is organizational culture an asset or liability?
        - What new competencies would be needed?

        ### **4. ADAPTATIONS NEEDED** (How should policy be modified?)
        - How should the policy be modified to remain effective?
        - What contingencies or flexibility should be built in?
        - What early warning indicators should be monitored?
        - What alternative approaches might work better?

        ANALYSIS REQUIREMENTS:
        - Be specific and concrete with examples rather than general statements
        - Ground analysis in the scenario details and policy specifics
        - Focus on actionable insights for policy resilience
        - Consider both opportunities and risks in the {scenario_type} scenario
        - Each dimension should be 80-120 words of substantive analysis

        Format your response as JSON:
        {{
            "viability": "Comprehensive analysis of policy effectiveness in this {scenario_type} scenario. Address objective achievement, success/failure factors, assumption validity, and unintended consequences with specific examples from the scenario context.",
            "process": "Detailed analysis of implementation changes in this {scenario_type} scenario. Cover process modifications, stakeholder dynamics, timeline realism, and governance challenges with concrete examples.", 
            "capabilities": "Thorough assessment of resource and capability requirements in this {scenario_type} scenario. Evaluate human resources, technology/infrastructure, organizational culture, and new competencies with specific details.",
            "adaptations_needed": "Specific recommendations for policy modifications in this {scenario_type} scenario. Include effectiveness improvements, contingencies, monitoring indicators, and alternative approaches with actionable suggestions."
        }}

        Focus on how the unique characteristics of this {scenario_type} scenario create specific challenges and opportunities for the policy.
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": f"""You are an expert policy analyst specializing in Wind Tunnel stress testing methodology. 
                        You excel at evaluating policy robustness across different future scenarios using concrete, specific analysis 
                        grounded in scenario details. You provide actionable insights with examples rather than generic assessments. 
                        Always respond with valid JSON format."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=2500,  # Increased for more detailed responses
                temperature=0.6
            )
            
            response_text = chat_completion.choices[0].message.content
            parsed_result = self._parse_json_response(response_text)
            
            # Validate required fields exist
            required_fields = ['viability', 'process', 'capabilities', 'adaptations_needed']
            for field in required_fields:
                if field not in parsed_result:
                    parsed_result[field] = f"Analysis pending for {field} in {scenario_type} scenario"
            
            return parsed_result
            
        except Exception as e:
            return {
                "viability": f"Error analyzing viability: {str(e)}",
                "process": f"Error analyzing process: {str(e)}",
                "capabilities": f"Error analyzing capabilities: {str(e)}",
                "adaptations_needed": f"Error generating adaptations: {str(e)}"
            }

    def _generate_cross_scenario_insights(self, domain: str, policy_text: str, scenario_analyses: Dict, project_name: str = "") -> Dict[str, str]:
        """Generate cross-scenario insights and policy robustness analysis."""
        
        # Format scenario analyses for prompt
        analyses_text = ""
        for scenario_name, analysis in scenario_analyses.items():
            analyses_text += f"\n{scenario_name.upper()} SCENARIO ANALYSIS:\n"
            analyses_text += f"Viability: {analysis.get('viability', 'N/A')}\n"
            analyses_text += f"Process: {analysis.get('process', 'N/A')}\n"
            analyses_text += f"Capabilities: {analysis.get('capabilities', 'N/A')}\n"
            analyses_text += f"Adaptations: {analysis.get('adaptations_needed', 'N/A')}\n"
            analyses_text += "---\n"
        
        prompt = f"""
        You are conducting **cross-scenario synthesis** for Wind Tunnel policy stress testing for "{project_name}" in "{domain}".

        POLICY ANALYZED:
        {policy_text[:2000]}

        INDIVIDUAL SCENARIO ANALYSES:
        {analyses_text[:6000]}

        CROSS-SCENARIO SYNTHESIS TASK:
        Compare across ALL scenarios together (not individually) to extract strategic insights:

        ### **Task 1: ROBUST ELEMENTS**
        Identify which elements of the policy are robust and work well across ALL scenarios.
        Focus on specific policy components, mechanisms, or approaches that remain effective regardless of future conditions.

        ### **Task 2: SCENARIO-SPECIFIC ELEMENTS** 
        Note which aspects of the policy only work in specific futures or require different approaches in different scenarios.
        Be specific about which elements work in which scenarios and why.

        ### **Task 3: CRITICAL VULNERABILITIES**
        Highlight the biggest failure points, risks, and vulnerabilities that emerge across scenarios.
        Focus on systemic weaknesses that could undermine policy effectiveness.

        ### **Task 4: MONITORING INDICATORS**
        Suggest specific, measurable early warning indicators that should be tracked to anticipate which scenario is emerging.
        Focus on concrete metrics that would signal the need for policy adaptation.

        SYNTHESIS REQUIREMENTS:
        - Compare patterns and commonalities across all scenario analyses
        - Be concrete and specific with examples rather than generic statements  
        - Focus on actionable recommendations for policy resilience
        - Each response should be 80-120 words of substantive analysis
        - Ground insights in the specific policy and scenario details provided

        Format as JSON:
        {{
            "robust_elements": "Specific policy aspects and mechanisms that demonstrate effectiveness across all scenarios, with concrete examples of why these elements remain viable regardless of future conditions.",
            "scenario_specific": "Detailed identification of policy elements that only work in certain scenarios, specifying which elements work in which futures and the underlying reasons for scenario dependency.",
            "critical_vulnerabilities": "Major systemic failure points and risks identified across scenarios, with specific assessment of how these vulnerabilities could undermine policy effectiveness and their potential impact.",
            "monitoring_indicators": "Concrete, measurable early warning indicators and metrics that should be tracked to anticipate scenario emergence and signal the need for policy adaptation, with specific measurement approaches."
        }}

        Focus on the most strategically important cross-scenario insights for policy adaptation and long-term resilience.
        """
        
        try:
            chat_completion = self.client.chat.completions.create(
                messages=[
                    {
                        "role": "system",
                        "content": """You are a senior strategic policy analyst specializing in cross-scenario synthesis 
                        and policy resilience assessment. You excel at identifying concrete patterns across different future 
                        scenarios and translating them into specific, actionable policy insights with examples and evidence. 
                        Always respond with valid JSON format."""
                    },
                    {"role": "user", "content": prompt}
                ],
                model=self.model,
                max_tokens=2000,  # Increased for more detailed responses
                temperature=0.6
            )
            
            response_text = chat_completion.choices[0].message.content
            parsed_result = self._parse_json_response(response_text)
            
            # Validate required fields exist
            required_fields = ['robust_elements', 'scenario_specific', 'critical_vulnerabilities', 'monitoring_indicators']
            for field in required_fields:
                if field not in parsed_result:
                    parsed_result[field] = f"Analysis pending for {field}"
            
            return parsed_result
            
        except Exception as e:
            return {
                "robust_elements": f"Error in cross-scenario analysis: {str(e)}",
                "scenario_specific": f"Error in scenario-specific analysis: {str(e)}",
                "critical_vulnerabilities": f"Error in vulnerability analysis: {str(e)}",
                "monitoring_indicators": f"Error in indicators analysis: {str(e)}"
            }




# Utility functions for Streamlit integration
def get_api_key():
    """Get Groq API key from environment or user input."""
    return os.getenv('GROQ_API_KEY', '')

def initialize_processor():
    """Initialize the DRI Foresight processor."""
    api_key = get_api_key()
    if not api_key:
        raise ValueError("GROQ_API_KEY environment variable not set")
    return DRIForesightProcessor(api_key)















































































